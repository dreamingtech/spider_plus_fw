2019-04-24 17:47:11 engine.py[line:36] INFO: 爬虫启动: 2019-04-24 17:47:11.244948
2019-04-24 17:47:11 engine.py[line:39] INFO: 爬虫结束: 2019-04-24 17:47:11.388947
2019-04-24 17:47:11 engine.py[line:40] INFO: 爬虫运行时间: 0.143999
2019-04-24 17:49:52 engine.py[line:36] INFO: 爬虫启动: 2019-04-24 17:49:52.512946
2019-04-24 17:49:52 connectionpool.py[line:208] DEBUG: Starting new HTTP connection (1): www.baidu.com
2019-04-24 17:49:52 connectionpool.py[line:396] DEBUG: http://www.baidu.com:80 "GET / HTTP/1.1" 200 None
2019-04-24 17:49:52 engine.py[line:39] INFO: 爬虫结束: 2019-04-24 17:49:52.624943
2019-04-24 17:49:52 engine.py[line:40] INFO: 爬虫运行时间: 0.111997
2019-04-25 08:55:20 engine.py[line:36] INFO: 爬虫启动: 2019-04-25 08:55:20.485003
2019-04-25 08:55:20 connectionpool.py[line:208] DEBUG: Starting new HTTP connection (1): www.baidu.com
2019-04-25 08:55:20 connectionpool.py[line:396] DEBUG: http://www.baidu.com:80 "GET / HTTP/1.1" 200 None
2019-04-25 08:55:20 engine.py[line:39] INFO: 爬虫结束: 2019-04-25 08:55:20.590003
2019-04-25 08:55:20 engine.py[line:40] INFO: 爬虫运行时间: 0.105
2019-04-25 08:56:13 engine.py[line:36] INFO: 爬虫启动: 2019-04-25 08:56:13.720996
2019-04-25 08:56:13 engine.py[line:39] INFO: 爬虫结束: 2019-04-25 08:56:13.830998
2019-04-25 08:56:13 engine.py[line:40] INFO: 爬虫运行时间: 0.110002
2019-04-25 08:59:43 engine.py[line:36] INFO: 爬虫启动: 2019-04-25 08:59:43.520046
2019-04-25 08:59:43 downloader.py[line:26] INFO: <200 http://www.baidu.com/>
2019-04-25 08:59:43 engine.py[line:39] INFO: 爬虫结束: 2019-04-25 08:59:43.626051
2019-04-25 08:59:43 engine.py[line:40] INFO: 爬虫运行时间: 0.106005
2019-04-25 09:02:25 engine.py[line:36] INFO: 爬虫启动: 2019-04-25 09:02:25.494640
2019-04-25 09:02:26 downloader.py[line:26] INFO: <200 https://www.douban.com/>
2019-04-25 09:02:26 engine.py[line:39] INFO: 爬虫结束: 2019-04-25 09:02:26.049640
2019-04-25 09:02:26 engine.py[line:40] INFO: 爬虫运行时间: 0.555
2019-04-25 09:57:20 engine.py[line:39] INFO: 爬虫启动: 2019-04-25 09:57:20.750848
2019-04-25 09:57:21 downloader.py[line:26] INFO: <200 https://www.douban.com/>
2019-04-25 09:57:21 engine.py[line:42] INFO: 爬虫结束: 2019-04-25 09:57:21.298830
2019-04-25 09:57:21 engine.py[line:43] INFO: 爬虫运行时间: 0.547982
2019-04-25 09:57:21 engine.py[line:45] INFO: 总的请求数量: 1个
2019-04-25 09:57:21 engine.py[line:46] INFO: 总的响应数量: 1个
2019-04-25 09:59:10 engine.py[line:39] INFO: 爬虫启动: 2019-04-25 09:59:10.813828
2019-04-25 09:59:11 downloader.py[line:26] INFO: <200 https://www.douban.com/>
2019-04-25 09:59:12 downloader.py[line:26] INFO: <200 https://www.douban.com/>
2019-04-25 09:59:12 downloader.py[line:26] INFO: <200 http://www.baidu.com/>
2019-04-25 09:59:12 engine.py[line:42] INFO: 爬虫结束: 2019-04-25 09:59:12.190838
2019-04-25 09:59:12 engine.py[line:43] INFO: 爬虫运行时间: 1.37701
2019-04-25 09:59:12 engine.py[line:45] INFO: 总的请求数量: 3个
2019-04-25 09:59:12 engine.py[line:46] INFO: 总的响应数量: 3个
2019-04-25 10:49:34 engine.py[line:39] INFO: 爬虫启动: 2019-04-25 10:49:34.332425
2019-04-25 10:49:34 downloader.py[line:26] INFO: <200 https://www.douban.com/>
2019-04-25 10:49:35 downloader.py[line:26] INFO: <200 https://www.douban.com/>
2019-04-25 10:49:35 downloader.py[line:26] INFO: <200 http://www.baidu.com/>
2019-04-25 10:49:35 engine.py[line:42] INFO: 爬虫结束: 2019-04-25 10:49:35.722427
2019-04-25 10:49:35 engine.py[line:43] INFO: 爬虫运行时间: 1.390002
2019-04-25 10:49:35 engine.py[line:45] INFO: 总的请求数量: 3个
2019-04-25 10:49:35 engine.py[line:46] INFO: 总的响应数量: 3个
2019-04-25 11:22:19 engine.py[line:39] INFO: 爬虫启动: 2019-04-25 11:22:19.715435
2019-04-25 11:23:08 engine.py[line:39] INFO: 爬虫启动: 2019-04-25 11:23:08.501432
2019-04-25 11:23:59 engine.py[line:39] INFO: 爬虫启动: 2019-04-25 11:23:59.302427
2019-04-25 11:23:59 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/1/>
2019-04-25 11:23:59 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/2/>
2019-04-25 11:24:00 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/3/>
2019-04-25 11:24:00 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/4/>
2019-04-25 11:24:00 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/5/>
2019-04-25 11:24:00 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/6/>
2019-04-25 11:24:01 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/7/>
2019-04-25 11:24:01 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/8/>
2019-04-25 11:24:01 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/9/>
2019-04-25 11:24:01 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/10/>
2019-04-25 11:24:02 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/11/>
2019-04-25 11:24:02 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/12/>
2019-04-25 11:24:02 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/13/>
2019-04-25 11:24:02 engine.py[line:42] INFO: 爬虫结束: 2019-04-25 11:24:02.492426
2019-04-25 11:24:02 engine.py[line:43] INFO: 爬虫运行时间: 3.189999
2019-04-25 11:24:02 engine.py[line:45] INFO: 总的请求数量: 13个
2019-04-25 11:24:02 engine.py[line:46] INFO: 总的响应数量: 13个
2019-04-25 11:25:12 engine.py[line:39] INFO: 爬虫启动: 2019-04-25 11:25:12.608659
2019-04-25 11:25:12 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/1/>
2019-04-25 11:25:13 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/2/>
2019-04-25 11:25:13 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/3/>
2019-04-25 11:25:16 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/4/>
2019-04-25 11:25:16 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/5/>
2019-04-25 11:25:17 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/6/>
2019-04-25 11:25:17 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/7/>
2019-04-25 11:25:17 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/8/>
2019-04-25 11:25:17 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/9/>
2019-04-25 11:25:18 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/10/>
2019-04-25 11:25:18 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/11/>
2019-04-25 11:25:18 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/12/>
2019-04-25 11:25:18 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/13/>
2019-04-25 11:25:18 engine.py[line:42] INFO: 爬虫结束: 2019-04-25 11:25:18.871655
2019-04-25 11:25:18 engine.py[line:43] INFO: 爬虫运行时间: 6.262996
2019-04-25 11:25:18 engine.py[line:45] INFO: 总的请求数量: 13个
2019-04-25 11:25:18 engine.py[line:46] INFO: 总的响应数量: 13个
2019-04-25 11:29:43 engine.py[line:39] INFO: 爬虫启动: 2019-04-25 11:29:43.197874
2019-04-25 11:29:43 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/1/>
2019-04-25 11:29:43 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/2/>
2019-04-25 11:29:43 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/3/>
2019-04-25 11:29:44 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/4/>
2019-04-25 11:29:44 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/5/>
2019-04-25 11:29:44 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/6/>
2019-04-25 11:29:44 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/7/>
2019-04-25 11:29:45 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/8/>
2019-04-25 11:29:45 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/9/>
2019-04-25 11:29:45 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/10/>
2019-04-25 11:29:45 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/11/>
2019-04-25 11:29:46 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/12/>
2019-04-25 11:29:46 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/13/>
2019-04-25 11:29:46 engine.py[line:42] INFO: 爬虫结束: 2019-04-25 11:29:46.276866
2019-04-25 11:29:46 engine.py[line:43] INFO: 爬虫运行时间: 3.078992
2019-04-25 11:29:46 engine.py[line:45] INFO: 总的请求数量: 13个
2019-04-25 11:29:46 engine.py[line:46] INFO: 总的响应数量: 13个
2019-04-25 11:30:00 engine.py[line:39] INFO: 爬虫启动: 2019-04-25 11:30:00.535876
2019-04-25 11:30:01 downloader.py[line:26] INFO: <200 https://www.douban.com/>
2019-04-25 11:30:01 downloader.py[line:26] INFO: <200 https://www.douban.com/>
2019-04-25 11:30:01 downloader.py[line:26] INFO: <200 http://www.baidu.com/>
2019-04-25 11:30:01 engine.py[line:42] INFO: 爬虫结束: 2019-04-25 11:30:01.643872
2019-04-25 11:30:01 engine.py[line:43] INFO: 爬虫运行时间: 1.107996
2019-04-25 11:30:01 engine.py[line:45] INFO: 总的请求数量: 3个
2019-04-25 11:30:01 engine.py[line:46] INFO: 总的响应数量: 3个
2019-04-25 11:30:22 engine.py[line:39] INFO: 爬虫启动: 2019-04-25 11:30:22.706870
2019-04-25 11:30:23 downloader.py[line:26] INFO: <200 https://www.douban.com/>
2019-04-25 11:30:23 downloader.py[line:26] INFO: <200 https://www.douban.com/>
2019-04-25 11:30:23 downloader.py[line:26] INFO: <200 http://www.baidu.com/>
2019-04-25 11:30:23 engine.py[line:42] INFO: 爬虫结束: 2019-04-25 11:30:23.805869
2019-04-25 11:30:23 engine.py[line:43] INFO: 爬虫运行时间: 1.098999
2019-04-25 11:30:23 engine.py[line:45] INFO: 总的请求数量: 3个
2019-04-25 11:30:23 engine.py[line:46] INFO: 总的响应数量: 3个
2019-04-25 11:30:31 engine.py[line:39] INFO: 爬虫启动: 2019-04-25 11:30:31.295866
2019-04-25 11:30:31 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/1/>
2019-04-25 11:30:31 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/2/>
2019-04-25 11:30:32 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/3/>
2019-04-25 11:30:32 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/4/>
2019-04-25 11:30:32 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/5/>
2019-04-25 11:30:32 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/6/>
2019-04-25 11:30:33 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/7/>
2019-04-25 11:30:33 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/8/>
2019-04-25 11:30:33 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/9/>
2019-04-25 11:30:33 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/10/>
2019-04-25 11:30:33 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/11/>
2019-04-25 11:30:34 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/12/>
2019-04-25 11:30:34 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/13/>
2019-04-25 11:30:34 engine.py[line:42] INFO: 爬虫结束: 2019-04-25 11:30:34.481866
2019-04-25 11:30:34 engine.py[line:43] INFO: 爬虫运行时间: 3.186
2019-04-25 11:30:34 engine.py[line:45] INFO: 总的请求数量: 13个
2019-04-25 11:30:34 engine.py[line:46] INFO: 总的响应数量: 13个
2019-04-25 11:31:49 engine.py[line:39] INFO: 爬虫启动: 2019-04-25 11:31:49.765871
2019-04-25 11:31:50 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/1/>
2019-04-25 11:31:50 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/2/>
2019-04-25 11:31:50 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/3/>
2019-04-25 11:31:50 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/4/>
2019-04-25 11:31:51 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/5/>
2019-04-25 11:31:51 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/6/>
2019-04-25 11:31:51 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/7/>
2019-04-25 11:31:51 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/8/>
2019-04-25 11:31:51 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/9/>
2019-04-25 11:31:52 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/10/>
2019-04-25 11:31:52 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/11/>
2019-04-25 11:31:52 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/12/>
2019-04-25 11:31:52 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/13/>
2019-04-25 11:31:52 engine.py[line:42] INFO: 爬虫结束: 2019-04-25 11:31:52.947868
2019-04-25 11:31:52 engine.py[line:43] INFO: 爬虫运行时间: 3.181997
2019-04-25 11:31:52 engine.py[line:45] INFO: 总的请求数量: 13个
2019-04-25 11:31:52 engine.py[line:46] INFO: 总的响应数量: 13个
2019-04-25 11:33:02 engine.py[line:39] INFO: 爬虫启动: 2019-04-25 11:33:02.455864
2019-04-25 11:33:02 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/1/>
2019-04-25 11:33:03 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/2/>
2019-04-25 11:33:03 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/3/>
2019-04-25 11:33:03 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/4/>
2019-04-25 11:33:03 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/5/>
2019-04-25 11:33:04 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/6/>
2019-04-25 11:33:04 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/7/>
2019-04-25 11:33:04 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/8/>
2019-04-25 11:33:04 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/9/>
2019-04-25 11:33:04 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/10/>
2019-04-25 11:33:05 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/11/>
2019-04-25 11:33:05 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/12/>
2019-04-25 11:33:05 engine.py[line:42] INFO: 爬虫结束: 2019-04-25 11:33:05.463866
2019-04-25 11:33:05 engine.py[line:43] INFO: 爬虫运行时间: 3.008002
2019-04-25 11:33:05 engine.py[line:45] INFO: 总的请求数量: 12个
2019-04-25 11:33:05 engine.py[line:46] INFO: 总的响应数量: 12个
2019-04-25 11:33:55 engine.py[line:39] INFO: 爬虫启动: 2019-04-25 11:33:55.836865
2019-04-25 11:33:56 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/1/>
2019-04-25 11:33:56 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/2/>
2019-04-25 11:33:56 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/3/>
2019-04-25 11:33:56 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/4/>
2019-04-25 11:33:57 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/5/>
2019-04-25 11:33:57 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/6/>
2019-04-25 11:33:57 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/7/>
2019-04-25 11:33:57 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/8/>
2019-04-25 11:33:58 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/9/>
2019-04-25 11:33:58 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/10/>
2019-04-25 11:33:58 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/11/>
2019-04-25 11:33:58 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/12/>
2019-04-25 11:33:59 engine.py[line:42] INFO: 爬虫结束: 2019-04-25 11:33:59.003868
2019-04-25 11:33:59 engine.py[line:43] INFO: 爬虫运行时间: 3.167003
2019-04-25 11:33:59 engine.py[line:45] INFO: 总的请求数量: 12个
2019-04-25 11:33:59 engine.py[line:46] INFO: 总的响应数量: 12个
2019-04-25 11:35:22 engine.py[line:39] INFO: 爬虫启动: 2019-04-25 11:35:22.905875
2019-04-25 11:35:23 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/1/>
2019-04-25 11:35:23 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/2/>
2019-04-25 11:35:23 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/3/>
2019-04-25 11:35:23 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/4/>
2019-04-25 11:35:24 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/5/>
2019-04-25 11:35:24 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/6/>
2019-04-25 11:35:24 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/7/>
2019-04-25 11:35:24 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/8/>
2019-04-25 11:35:25 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/9/>
2019-04-25 11:35:25 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/10/>
2019-04-25 11:35:25 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/11/>
2019-04-25 11:35:25 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/12/>
2019-04-25 11:35:25 engine.py[line:42] INFO: 爬虫结束: 2019-04-25 11:35:25.788866
2019-04-25 11:35:25 engine.py[line:43] INFO: 爬虫运行时间: 2.882991
2019-04-25 11:35:25 engine.py[line:45] INFO: 总的请求数量: 12个
2019-04-25 11:35:25 engine.py[line:46] INFO: 总的响应数量: 12个
2019-04-25 11:37:17 engine.py[line:39] INFO: 爬虫启动: 2019-04-25 11:37:17.683866
2019-04-25 11:37:17 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/1/>
2019-04-25 11:37:18 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/2/>
2019-04-25 11:37:18 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/3/>
2019-04-25 11:37:18 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/4/>
2019-04-25 11:37:18 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/5/>
2019-04-25 11:37:19 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/6/>
2019-04-25 11:37:19 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/7/>
2019-04-25 11:37:19 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/8/>
2019-04-25 11:37:19 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/9/>
2019-04-25 11:37:20 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/10/>
2019-04-25 11:37:20 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/11/>
2019-04-25 11:37:20 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/12/>
2019-04-25 11:37:20 engine.py[line:42] INFO: 爬虫结束: 2019-04-25 11:37:20.698867
2019-04-25 11:37:20 engine.py[line:43] INFO: 爬虫运行时间: 3.015001
2019-04-25 11:37:20 engine.py[line:45] INFO: 总的请求数量: 12个
2019-04-25 11:37:20 engine.py[line:46] INFO: 总的响应数量: 12个
2019-04-25 11:39:42 engine.py[line:39] INFO: 爬虫启动: 2019-04-25 11:39:42.255867
2019-04-25 11:39:42 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/1/>
2019-04-25 11:39:42 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/2/>
2019-04-25 11:39:43 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/3/>
2019-04-25 11:39:43 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/4/>
2019-04-25 11:39:43 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/5/>
2019-04-25 11:39:43 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/6/>
2019-04-25 11:39:43 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/7/>
2019-04-25 11:39:44 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/8/>
2019-04-25 11:39:44 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/9/>
2019-04-25 11:39:44 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/10/>
2019-04-25 11:39:45 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/11/>
2019-04-25 11:39:45 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/12/>
2019-04-25 11:39:45 engine.py[line:42] INFO: 爬虫结束: 2019-04-25 11:39:45.393866
2019-04-25 11:39:45 engine.py[line:43] INFO: 爬虫运行时间: 3.137999
2019-04-25 11:39:45 engine.py[line:45] INFO: 总的请求数量: 12个
2019-04-25 11:39:45 engine.py[line:46] INFO: 总的响应数量: 12个
2019-04-25 11:40:19 engine.py[line:39] INFO: 爬虫启动: 2019-04-25 11:40:19.181874
2019-04-25 11:40:19 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/1/>
2019-04-25 11:40:19 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/2/>
2019-04-25 11:40:19 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/3/>
2019-04-25 11:40:20 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/4/>
2019-04-25 11:40:20 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/5/>
2019-04-25 11:40:20 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/6/>
2019-04-25 11:40:20 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/7/>
2019-04-25 11:40:21 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/8/>
2019-04-25 11:40:21 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/9/>
2019-04-25 11:40:21 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/10/>
2019-04-25 11:40:21 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/11/>
2019-04-25 11:40:22 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/12/>
2019-04-25 11:40:22 engine.py[line:42] INFO: 爬虫结束: 2019-04-25 11:40:22.062866
2019-04-25 11:40:22 engine.py[line:43] INFO: 爬虫运行时间: 2.880992
2019-04-25 11:40:22 engine.py[line:45] INFO: 总的请求数量: 12个
2019-04-25 11:40:22 engine.py[line:46] INFO: 总的响应数量: 12个
2019-04-25 11:40:59 engine.py[line:39] INFO: 爬虫启动: 2019-04-25 11:40:59.507867
2019-04-25 11:40:59 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/1/>
2019-04-25 11:42:16 engine.py[line:39] INFO: 爬虫启动: 2019-04-25 11:42:16.146866
2019-04-25 11:42:16 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/1/>
2019-04-25 11:42:16 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/2/>
2019-04-25 11:42:16 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/3/>
2019-04-25 11:42:17 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/4/>
2019-04-25 11:42:17 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/5/>
2019-04-25 11:42:17 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/6/>
2019-04-25 11:42:17 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/7/>
2019-04-25 11:42:18 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/8/>
2019-04-25 11:42:18 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/9/>
2019-04-25 11:42:18 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/10/>
2019-04-25 11:42:18 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/11/>
2019-04-25 11:42:19 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/12/>
2019-04-25 11:42:19 engine.py[line:42] INFO: 爬虫结束: 2019-04-25 11:42:19.112865
2019-04-25 11:42:19 engine.py[line:43] INFO: 爬虫运行时间: 2.965999
2019-04-25 11:42:19 engine.py[line:45] INFO: 总的请求数量: 12个
2019-04-25 11:42:19 engine.py[line:46] INFO: 总的响应数量: 12个
2019-04-25 11:43:29 engine.py[line:39] INFO: 爬虫启动: 2019-04-25 11:43:29.093869
2019-04-25 11:43:29 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/1/>
2019-04-25 11:43:29 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/2/>
2019-04-25 11:43:29 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/3/>
2019-04-25 11:43:30 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/4/>
2019-04-25 11:43:30 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/5/>
2019-04-25 11:43:30 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/6/>
2019-04-25 11:43:30 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/7/>
2019-04-25 11:43:31 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/8/>
2019-04-25 11:43:31 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/9/>
2019-04-25 11:43:31 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/10/>
2019-04-25 11:43:31 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/11/>
2019-04-25 11:43:32 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/12/>
2019-04-25 11:43:32 engine.py[line:42] INFO: 爬虫结束: 2019-04-25 11:43:32.114869
2019-04-25 11:43:32 engine.py[line:43] INFO: 爬虫运行时间: 3.021
2019-04-25 11:43:32 engine.py[line:45] INFO: 总的请求数量: 12个
2019-04-25 11:43:32 engine.py[line:46] INFO: 总的响应数量: 12个
2019-04-25 11:51:57 engine.py[line:39] INFO: 爬虫启动: 2019-04-25 11:51:57.105874
2019-04-25 11:51:57 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/1/>
2019-04-25 11:51:57 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/2/>
2019-04-25 11:51:57 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/3/>
2019-04-25 11:51:58 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/4/>
2019-04-25 11:51:58 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/5/>
2019-04-25 11:51:58 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/6/>
2019-04-25 11:51:58 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/7/>
2019-04-25 11:51:59 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/8/>
2019-04-25 11:51:59 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/9/>
2019-04-25 11:51:59 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/10/>
2019-04-25 11:51:59 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/11/>
2019-04-25 11:52:00 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/12/>
2019-04-25 11:52:00 engine.py[line:42] INFO: 爬虫结束: 2019-04-25 11:52:00.044866
2019-04-25 11:52:00 engine.py[line:43] INFO: 爬虫运行时间: 2.938992
2019-04-25 11:52:00 engine.py[line:45] INFO: 总的请求数量: 12个
2019-04-25 11:52:00 engine.py[line:46] INFO: 总的响应数量: 12个
2019-04-25 11:52:30 engine.py[line:39] INFO: 爬虫启动: 2019-04-25 11:52:30.673866
2019-04-25 11:52:30 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/1/>
2019-04-25 11:52:31 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/2/>
2019-04-25 11:52:31 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/3/>
2019-04-25 11:52:31 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/4/>
2019-04-25 11:52:32 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/5/>
2019-04-25 11:52:32 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/6/>
2019-04-25 11:52:32 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/7/>
2019-04-25 11:52:32 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/8/>
2019-04-25 11:52:33 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/9/>
2019-04-25 11:52:33 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/10/>
2019-04-25 11:52:33 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/11/>
2019-04-25 11:52:33 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/12/>
2019-04-25 11:52:33 engine.py[line:42] INFO: 爬虫结束: 2019-04-25 11:52:33.877868
2019-04-25 11:52:33 engine.py[line:43] INFO: 爬虫运行时间: 3.204002
2019-04-25 11:52:33 engine.py[line:45] INFO: 总的请求数量: 12个
2019-04-25 11:52:33 engine.py[line:46] INFO: 总的响应数量: 12个
2019-04-25 11:53:10 engine.py[line:39] INFO: 爬虫启动: 2019-04-25 11:53:10.865868
2019-04-25 11:53:11 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/1/>
2019-04-25 11:53:11 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/2/>
2019-04-25 11:53:11 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/3/>
2019-04-25 11:53:11 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/4/>
2019-04-25 11:53:12 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/5/>
2019-04-25 11:53:12 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/6/>
2019-04-25 11:53:12 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/7/>
2019-04-25 11:53:12 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/8/>
2019-04-25 11:53:12 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/9/>
2019-04-25 11:53:13 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/10/>
2019-04-25 11:53:13 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/11/>
2019-04-25 11:53:13 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/12/>
2019-04-25 11:53:13 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/13/>
2019-04-25 11:53:13 engine.py[line:42] INFO: 爬虫结束: 2019-04-25 11:53:13.968866
2019-04-25 11:53:13 engine.py[line:43] INFO: 爬虫运行时间: 3.102998
2019-04-25 11:53:13 engine.py[line:45] INFO: 总的请求数量: 13个
2019-04-25 11:53:13 engine.py[line:46] INFO: 总的响应数量: 13个
2019-04-25 11:57:49 engine.py[line:39] INFO: 爬虫启动: 2019-04-25 11:57:49.846139
2019-04-25 11:57:50 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/1/>
2019-04-25 11:57:50 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/2/>
2019-04-25 11:57:50 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/3/>
2019-04-25 11:57:50 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/4/>
2019-04-25 11:57:51 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/5/>
2019-04-25 11:57:51 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/6/>
2019-04-25 11:57:52 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/7/>
2019-04-25 11:57:52 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/8/>
2019-04-25 11:57:53 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/9/>
2019-04-25 11:57:53 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/10/>
2019-04-25 11:57:53 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/11/>
2019-04-25 11:57:53 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/12/>
2019-04-25 11:57:54 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/13/>
2019-04-25 11:57:54 engine.py[line:42] INFO: 爬虫结束: 2019-04-25 11:57:54.176137
2019-04-25 11:57:54 engine.py[line:43] INFO: 爬虫运行时间: 4.329998
2019-04-25 11:57:54 engine.py[line:45] INFO: 总的请求数量: 13个
2019-04-25 11:57:54 engine.py[line:46] INFO: 总的响应数量: 13个
2019-04-25 11:58:46 engine.py[line:39] INFO: 爬虫启动: 2019-04-25 11:58:46.743133
2019-04-25 11:58:47 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/1/>
2019-04-25 11:58:47 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/2/>
2019-04-25 11:58:47 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/3/>
2019-04-25 11:58:47 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/4/>
2019-04-25 11:58:47 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/5/>
2019-04-25 11:58:48 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/6/>
2019-04-25 11:58:48 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/7/>
2019-04-25 11:58:48 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/8/>
2019-04-25 11:58:48 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/9/>
2019-04-25 11:58:49 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/10/>
2019-04-25 11:58:49 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/11/>
2019-04-25 11:58:49 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/12/>
2019-04-25 11:58:49 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/13/>
2019-04-25 11:58:49 engine.py[line:42] INFO: 爬虫结束: 2019-04-25 11:58:49.909137
2019-04-25 11:58:49 engine.py[line:43] INFO: 爬虫运行时间: 3.166004
2019-04-25 11:58:49 engine.py[line:45] INFO: 总的请求数量: 13个
2019-04-25 11:58:49 engine.py[line:46] INFO: 总的响应数量: 13个
2019-04-25 13:14:04 engine.py[line:39] INFO: 爬虫启动: 2019-04-25 13:14:04.406886
2019-04-25 13:14:04 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/1/>
2019-04-25 13:14:05 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/2/>
2019-04-25 13:14:05 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/3/>
2019-04-25 13:14:05 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/4/>
2019-04-25 13:14:05 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/5/>
2019-04-25 13:21:11 engine.py[line:39] INFO: 爬虫启动: 2019-04-25 13:21:11.740890
2019-04-25 13:21:12 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/1/>
2019-04-25 13:21:12 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/2/>
2019-04-25 13:21:12 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/3/>
2019-04-25 13:21:12 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/4/>
2019-04-25 13:21:13 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/5/>
2019-04-25 13:21:13 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/6/>
2019-04-25 13:22:36 engine.py[line:39] INFO: 爬虫启动: 2019-04-25 13:22:36.149586
2019-04-25 13:22:36 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/1/>
2019-04-25 13:22:36 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/2/>
2019-04-25 13:22:37 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/3/>
2019-04-25 13:22:37 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/4/>
2019-04-25 13:22:37 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/5/>
2019-04-25 13:22:37 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/6/>
2019-04-25 13:23:26 engine.py[line:39] INFO: 爬虫启动: 2019-04-25 13:23:26.708856
2019-04-25 13:23:26 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/1/>
2019-04-25 13:23:27 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/2/>
2019-04-25 13:23:27 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/3/>
2019-04-25 13:23:27 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/4/>
2019-04-25 13:23:27 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/5/>
2019-04-25 13:23:28 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/6/>
2019-04-25 13:25:30 engine.py[line:39] INFO: 爬虫启动: 2019-04-25 13:25:30.129855
2019-04-25 13:25:30 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/1/>
2019-04-25 13:25:30 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/2/>
2019-04-25 13:25:30 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/3/>
2019-04-25 13:25:31 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/4/>
2019-04-25 13:25:31 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/5/>
2019-04-25 13:25:31 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/6/>
2019-04-25 13:25:31 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/7/>
2019-04-25 13:25:32 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/8/>
2019-04-25 13:25:32 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/9/>
2019-04-25 13:25:32 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/10/>
2019-04-25 13:25:32 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/11/>
2019-04-25 13:25:33 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/12/>
2019-04-25 13:25:33 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/13/>
2019-04-25 13:25:33 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121189814>
2019-04-25 13:26:04 engine.py[line:39] INFO: 爬虫启动: 2019-04-25 13:26:04.685856
2019-04-25 13:26:04 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/1/>
2019-04-25 13:26:05 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/2/>
2019-04-25 13:26:05 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/3/>
2019-04-25 13:26:05 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/4/>
2019-04-25 13:26:05 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/5/>
2019-04-25 13:26:06 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/6/>
2019-04-25 13:26:06 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/7/>
2019-04-25 13:26:06 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/8/>
2019-04-25 13:26:06 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/9/>
2019-04-25 13:26:07 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/10/>
2019-04-25 13:26:07 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/11/>
2019-04-25 13:26:07 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/12/>
2019-04-25 13:26:07 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/13/>
2019-04-25 13:26:08 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121189814>
2019-04-25 13:26:08 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121164556>
2019-04-25 13:26:08 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121173723>
2019-04-25 13:26:08 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121142421>
2019-04-25 13:26:09 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121163715>
2019-04-25 13:26:09 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121158440>
2019-04-25 13:26:09 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121221603>
2019-04-25 13:26:09 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121146050>
2019-04-25 13:26:10 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121214608>
2019-04-25 13:26:10 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121179854>
2019-04-25 13:26:10 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121129864>
2019-04-25 13:26:10 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121204574>
2019-04-25 13:26:11 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121171153>
2019-04-25 13:26:11 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121196360>
2019-04-25 13:26:11 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121195793>
2019-04-25 13:26:12 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121192378>
2019-04-25 13:26:12 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121157853>
2019-04-25 13:26:12 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121152013>
2019-04-25 13:26:12 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121205315>
2019-04-25 13:26:13 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121209084>
2019-04-25 13:26:13 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121184699>
2019-04-25 13:26:13 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121162042>
2019-04-25 13:26:14 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121141450>
2019-04-25 13:26:14 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121210297>
2019-04-25 13:26:14 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121171410>
2019-04-25 13:26:14 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121218072>
2019-04-25 13:26:15 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121148078>
2019-04-25 13:26:15 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121209838>
2019-04-25 13:26:15 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121213114>
2019-04-25 13:26:15 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121222721>
2019-04-25 13:26:16 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121164180>
2019-04-25 13:26:16 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121152533>
2019-04-25 13:26:16 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121130200>
2019-04-25 13:26:17 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121202989>
2019-04-25 13:26:17 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121210981>
2019-04-25 13:26:17 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121214054>
2019-04-25 13:26:17 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121182657>
2019-04-25 13:26:18 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121223825>
2019-04-25 13:26:19 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121122328>
2019-04-25 13:26:20 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121198308>
2019-04-25 13:26:20 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121166083>
2019-04-25 13:26:20 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121209253>
2019-04-25 13:26:20 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121211781>
2019-04-25 13:26:21 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121132556>
2019-04-25 13:26:21 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121191077>
2019-04-25 13:26:21 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121203534>
2019-04-25 13:26:21 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121153039>
2019-04-25 13:26:22 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121202268>
2019-04-25 13:26:22 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121170925>
2019-04-25 13:26:22 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121161499>
2019-04-25 13:26:22 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121165570>
2019-04-25 13:26:23 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121166299>
2019-04-25 13:26:23 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121224096>
2019-04-25 13:26:23 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121169435>
2019-04-25 13:26:24 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121177141>
2019-04-25 13:26:24 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121167968>
2019-04-25 13:26:24 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121145221>
2019-04-25 13:26:24 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121222218>
2019-04-25 13:26:25 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121218226>
2019-04-25 13:26:25 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121182624>
2019-04-25 13:26:25 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121127416>
2019-04-25 13:26:25 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121166010>
2019-04-25 13:26:26 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121150481>
2019-04-25 13:26:26 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121207213>
2019-04-25 13:26:26 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121136304>
2019-04-25 13:26:27 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121190909>
2019-04-25 13:26:27 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121194372>
2019-04-25 13:26:27 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121181787>
2019-04-25 13:26:27 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121191143>
2019-04-25 13:26:28 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121175793>
2019-04-25 13:26:28 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121200346>
2019-04-25 13:26:28 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121149468>
2019-04-25 13:26:29 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121222607>
2019-04-25 13:26:29 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121154003>
2019-04-25 13:26:29 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121186275>
2019-04-25 13:26:29 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121216385>
2019-04-25 13:26:30 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121181719>
2019-04-25 13:26:30 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121174922>
2019-04-25 13:26:30 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121162246>
2019-04-25 13:26:31 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121133480>
2019-04-25 13:26:31 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121169557>
2019-04-25 13:26:31 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121208601>
2019-04-25 13:26:32 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121162980>
2019-04-25 13:26:32 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121225672>
2019-04-25 13:26:32 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121187525>
2019-04-25 13:26:32 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121192545>
2019-04-25 13:26:33 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121170454>
2019-04-25 13:26:33 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121203157>
2019-04-25 13:26:33 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121167979>
2019-04-25 13:26:33 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121172328>
2019-04-25 13:26:34 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121194384>
2019-04-25 13:26:34 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121151552>
2019-04-25 13:26:34 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121174795>
2019-04-25 13:26:34 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121170020>
2019-04-25 13:32:05 engine.py[line:39] INFO: 爬虫启动: 2019-04-25 13:32:05.803765
2019-04-25 13:32:06 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/1/>
2019-04-25 13:32:06 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/2/>
2019-04-25 13:32:06 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/3/>
2019-04-25 13:32:06 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/4/>
2019-04-25 13:32:07 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/5/>
2019-04-25 13:32:07 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/6/>
2019-04-25 13:32:07 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/7/>
2019-04-25 13:32:07 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/8/>
2019-04-25 13:32:08 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/9/>
2019-04-25 13:32:08 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/10/>
2019-04-25 13:32:08 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/11/>
2019-04-25 13:32:08 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/12/>
2019-04-25 13:32:09 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/13/>
2019-04-25 13:32:09 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121194743>
2019-04-25 13:32:09 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121165834>
2019-04-25 13:32:09 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121128965>
2019-04-25 13:32:10 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121216939>
2019-04-25 13:32:10 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121163312>
2019-04-25 13:32:10 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121183973>
2019-04-25 13:32:10 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121193241>
2019-04-25 13:32:11 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121218992>
2019-04-25 13:32:12 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121193354>
2019-04-25 13:32:12 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121198415>
2019-04-25 13:32:12 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121204443>
2019-04-25 13:32:13 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121225215>
2019-04-25 13:32:13 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121195465>
2019-04-25 13:32:13 engine.py[line:42] INFO: 爬虫结束: 2019-04-25 13:32:13.299762
2019-04-25 13:32:13 engine.py[line:43] INFO: 爬虫运行时间: 7.495997
2019-04-25 13:32:13 engine.py[line:45] INFO: 总的请求数量: 26个
2019-04-25 13:32:13 engine.py[line:46] INFO: 总的响应数量: 26个
2019-04-25 13:33:33 engine.py[line:39] INFO: 爬虫启动: 2019-04-25 13:33:33.397764
2019-04-25 13:33:33 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/1/>
2019-04-25 13:33:33 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/2/>
2019-04-25 13:33:34 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/3/>
2019-04-25 13:33:34 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/4/>
2019-04-25 13:33:34 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/5/>
2019-04-25 13:33:34 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/6/>
2019-04-25 13:33:35 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/7/>
2019-04-25 13:33:35 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/8/>
2019-04-25 13:33:35 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/9/>
2019-04-25 13:33:35 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/10/>
2019-04-25 13:33:36 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/11/>
2019-04-25 13:33:36 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/12/>
2019-04-25 13:33:36 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/13/>
2019-04-25 13:33:36 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121194743>
2019-04-25 13:33:37 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121165834>
2019-04-25 13:33:37 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121128965>
2019-04-25 13:33:37 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121216939>
2019-04-25 13:33:37 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121163312>
2019-04-25 13:33:38 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121183973>
2019-04-25 13:33:38 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121193241>
2019-04-25 13:33:38 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121218992>
2019-04-25 13:33:38 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121193354>
2019-04-25 13:33:39 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121198415>
2019-04-25 13:33:39 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121204443>
2019-04-25 13:33:39 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121225215>
2019-04-25 13:33:40 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121195465>
2019-04-25 13:33:40 engine.py[line:42] INFO: 爬虫结束: 2019-04-25 13:33:40.245768
2019-04-25 13:33:40 engine.py[line:43] INFO: 爬虫运行时间: 6.848004
2019-04-25 13:33:40 engine.py[line:45] INFO: 总的请求数量: 26个
2019-04-25 13:33:40 engine.py[line:46] INFO: 总的响应数量: 26个
2019-04-26 10:02:06 engine.py[line:39] INFO: 爬虫启动: 2019-04-26 10:02:06.153993
2019-04-26 10:02:06 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/1/>
2019-04-26 10:02:06 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/2/>
2019-04-26 10:02:06 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/3/>
2019-04-26 10:02:07 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/4/>
2019-04-26 10:02:07 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/5/>
2019-04-26 10:02:07 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/6/>
2019-04-26 10:02:07 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/7/>
2019-04-26 10:02:08 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/8/>
2019-04-26 10:02:08 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/9/>
2019-04-26 10:02:08 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/10/>
2019-04-26 10:02:08 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/11/>
2019-04-26 10:02:09 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/12/>
2019-04-26 10:02:09 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/13/>
2019-04-26 10:02:09 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121174663>
2019-04-26 10:02:09 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121152438>
2019-04-26 10:02:10 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121141628>
2019-04-26 10:02:10 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121150757>
2019-04-26 10:02:10 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121145955>
2019-04-26 10:02:11 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121226469>
2019-04-26 10:02:11 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121173839>
2019-04-26 10:02:11 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121128862>
2019-04-26 10:02:11 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121170548>
2019-04-26 10:02:12 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121204998>
2019-04-26 10:02:12 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121213470>
2019-04-26 10:02:12 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121138026>
2019-04-26 10:02:13 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121212639>
2019-04-26 10:02:13 engine.py[line:42] INFO: 爬虫结束: 2019-04-26 10:02:13.081989
2019-04-26 10:02:13 engine.py[line:43] INFO: 爬虫运行时间: 6.927996
2019-04-26 10:02:13 engine.py[line:45] INFO: 总的请求数量: 26个
2019-04-26 10:02:13 engine.py[line:46] INFO: 总的响应数量: 26个
2019-04-26 10:18:28 engine.py[line:39] INFO: 爬虫启动: 2019-04-26 10:18:28.596465
2019-04-26 10:18:29 downloader.py[line:26] INFO: <200 https://www.douban.com/>
2019-04-26 10:18:29 downloader.py[line:26] INFO: <200 https://www.douban.com/>
2019-04-26 10:18:29 downloader.py[line:26] INFO: <200 http://www.baidu.com/>
2019-04-26 10:18:29 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/1/>
2019-04-26 10:18:30 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/2/>
2019-04-26 10:18:30 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/3/>
2019-04-26 10:18:30 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/4/>
2019-04-26 10:18:30 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/5/>
2019-04-26 10:18:31 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/6/>
2019-04-26 10:18:31 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/7/>
2019-04-26 10:18:31 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/8/>
2019-04-26 10:18:31 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/9/>
2019-04-26 10:18:32 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/10/>
2019-04-26 10:18:32 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/11/>
2019-04-26 10:18:32 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/12/>
2019-04-26 10:18:32 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/13/>
2019-04-26 10:18:33 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121179372>
2019-04-26 10:18:33 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121165507>
2019-04-26 10:18:33 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121171826>
2019-04-26 10:18:33 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121213461>
2019-04-26 10:18:34 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121177161>
2019-04-26 10:18:34 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121226419>
2019-04-26 10:18:34 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121161394>
2019-04-26 10:18:35 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121204543>
2019-04-26 10:18:35 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121154377>
2019-04-26 10:18:35 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121199246>
2019-04-26 10:18:35 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121195855>
2019-04-26 10:18:36 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121190879>
2019-04-26 10:18:36 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121210886>
2019-04-26 10:18:36 engine.py[line:42] INFO: 爬虫结束: 2019-04-26 10:18:36.548467
2019-04-26 10:18:36 engine.py[line:43] INFO: 爬虫运行时间: 7.952002
2019-04-26 10:18:36 engine.py[line:45] INFO: 总的请求数量: 29个
2019-04-26 10:18:36 engine.py[line:46] INFO: 总的响应数量: 29个
2019-04-26 10:19:54 engine.py[line:39] INFO: 爬虫启动: 2019-04-26 10:19:54.659223
2019-04-26 10:19:55 downloader.py[line:26] INFO: <200 https://www.douban.com/>
2019-04-26 10:20:23 engine.py[line:39] INFO: 爬虫启动: 2019-04-26 10:20:23.068211
2019-04-26 10:20:23 downloader.py[line:26] INFO: <200 https://www.douban.com/>
2019-04-26 10:20:24 downloader.py[line:26] INFO: <200 https://www.douban.com/>
2019-04-26 10:20:24 downloader.py[line:26] INFO: <200 http://www.baidu.com/>
2019-04-26 10:20:24 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/1/>
2019-04-26 10:20:24 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/2/>
2019-04-26 10:20:24 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/3/>
2019-04-26 10:20:25 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/4/>
2019-04-26 10:20:25 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/5/>
2019-04-26 10:20:25 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/6/>
2019-04-26 10:20:25 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/7/>
2019-04-26 10:20:26 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/8/>
2019-04-26 10:20:26 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/9/>
2019-04-26 10:20:26 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/10/>
2019-04-26 10:20:26 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/11/>
2019-04-26 10:20:27 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/12/>
2019-04-26 10:20:27 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/13/>
2019-04-26 10:20:27 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121135268>
2019-04-26 10:20:27 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121183436>
2019-04-26 10:20:28 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121218596>
2019-04-26 10:20:28 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121174737>
2019-04-26 10:20:28 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121182049>
2019-04-26 10:20:29 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121154977>
2019-04-26 10:20:29 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121172284>
2019-04-26 10:20:29 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121191782>
2019-04-26 10:20:30 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121164203>
2019-04-26 10:20:30 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121218991>
2019-04-26 10:20:30 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121166396>
2019-04-26 10:20:30 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121194280>
2019-04-26 10:20:31 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121169644>
2019-04-26 10:20:31 engine.py[line:42] INFO: 爬虫结束: 2019-04-26 10:20:31.222851
2019-04-26 10:20:31 engine.py[line:43] INFO: 爬虫运行时间: 8.15464
2019-04-26 10:20:31 engine.py[line:45] INFO: 总的请求数量: 29个
2019-04-26 10:20:31 engine.py[line:46] INFO: 总的响应数量: 29个
2019-04-26 10:23:30 engine.py[line:39] INFO: 爬虫启动: 2019-04-26 10:23:30.182874
2019-04-26 10:23:30 downloader.py[line:26] INFO: <200 https://www.douban.com/>
2019-04-26 10:23:31 downloader.py[line:26] INFO: <200 https://www.douban.com/>
2019-04-26 10:23:31 downloader.py[line:26] INFO: <200 http://www.baidu.com/>
2019-04-26 10:23:31 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/1/>
2019-04-26 10:23:31 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/2/>
2019-04-26 10:23:32 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/3/>
2019-04-26 10:23:32 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/4/>
2019-04-26 10:23:32 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/5/>
2019-04-26 10:23:32 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/6/>
2019-04-26 10:23:32 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/7/>
2019-04-26 10:23:33 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/8/>
2019-04-26 10:23:33 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/9/>
2019-04-26 10:23:33 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/10/>
2019-04-26 10:23:33 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/11/>
2019-04-26 10:23:34 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/12/>
2019-04-26 10:23:34 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/13/>
2019-04-26 10:23:34 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121135268>
2019-04-26 10:23:34 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121183436>
2019-04-26 10:23:35 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121218596>
2019-04-26 10:23:35 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121174737>
2019-04-26 10:23:35 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121182049>
2019-04-26 10:23:35 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121154977>
2019-04-26 10:23:36 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121172284>
2019-04-26 10:23:36 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121191782>
2019-04-26 10:23:36 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121164203>
2019-04-26 10:23:36 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121218991>
2019-04-26 10:23:37 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121166396>
2019-04-26 10:23:37 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121194280>
2019-04-26 10:23:37 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121169644>
2019-04-26 10:23:37 engine.py[line:42] INFO: 爬虫结束: 2019-04-26 10:23:37.683885
2019-04-26 10:23:37 engine.py[line:43] INFO: 爬虫运行时间: 7.501011
2019-04-26 10:23:37 engine.py[line:45] INFO: 总的请求数量: 29个
2019-04-26 10:23:37 engine.py[line:46] INFO: 总的响应数量: 29个
2019-04-26 10:44:52 engine.py[line:39] INFO: 爬虫启动: 2019-04-26 10:44:52.634106
2019-04-26 10:44:53 downloader.py[line:26] INFO: <200 https://www.douban.com/>
2019-04-26 10:45:54 engine.py[line:39] INFO: 爬虫启动: 2019-04-26 10:45:54.895364
2019-04-26 10:45:55 downloader.py[line:26] INFO: <200 https://www.douban.com/>
2019-04-26 10:45:55 downloader.py[line:26] INFO: <200 https://www.douban.com/>
2019-04-26 10:45:55 downloader.py[line:26] INFO: <200 http://www.baidu.com/>
2019-04-26 10:45:56 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/1/>
2019-04-26 10:45:56 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/2/>
2019-04-26 10:45:56 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/3/>
2019-04-26 10:45:56 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/4/>
2019-04-26 10:45:57 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/5/>
2019-04-26 10:45:57 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/6/>
2019-04-26 10:45:57 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/7/>
2019-04-26 10:45:57 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/8/>
2019-04-26 10:45:58 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/9/>
2019-04-26 10:45:58 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/10/>
2019-04-26 10:45:58 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/11/>
2019-04-26 10:45:58 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/12/>
2019-04-26 10:45:59 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/13/>
2019-04-26 10:45:59 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121152760>
2019-04-26 10:45:59 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121170538>
2019-04-26 10:45:59 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121159164>
2019-04-26 10:46:00 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121181376>
2019-04-26 10:46:00 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121200287>
2019-04-26 10:46:00 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121198724>
2019-04-26 10:46:01 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121128170>
2019-04-26 10:46:01 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121182863>
2019-04-26 10:46:01 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121130446>
2019-04-26 10:46:01 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121136820>
2019-04-26 10:46:02 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121188132>
2019-04-26 10:46:02 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121143631>
2019-04-26 10:46:02 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121222598>
2019-04-26 10:46:02 engine.py[line:42] INFO: 爬虫结束: 2019-04-26 10:46:02.876363
2019-04-26 10:46:02 engine.py[line:43] INFO: 爬虫运行时间: 7.980999
2019-04-26 10:46:02 engine.py[line:45] INFO: 总的请求数量: 29个
2019-04-26 10:46:02 engine.py[line:46] INFO: 总的响应数量: 29个
2019-04-26 10:46:56 engine.py[line:39] INFO: 爬虫启动: 2019-04-26 10:46:56.641362
2019-04-26 10:46:57 downloader.py[line:26] INFO: <200 https://www.douban.com/>
2019-04-26 10:46:57 downloader.py[line:26] INFO: <200 https://www.douban.com/>
2019-04-26 10:46:57 downloader.py[line:26] INFO: <200 http://www.baidu.com/>
2019-04-26 10:46:58 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/1/>
2019-04-26 10:46:58 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/2/>
2019-04-26 10:46:58 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/3/>
2019-04-26 10:46:58 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/4/>
2019-04-26 10:46:58 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/5/>
2019-04-26 10:46:59 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/6/>
2019-04-26 10:46:59 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/7/>
2019-04-26 10:46:59 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/8/>
2019-04-26 10:46:59 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/9/>
2019-04-26 10:47:00 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/10/>
2019-04-26 10:47:00 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/11/>
2019-04-26 10:47:00 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/12/>
2019-04-26 10:47:00 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/13/>
2019-04-26 10:47:01 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121152760>
2019-04-26 10:47:01 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121170538>
2019-04-26 10:47:01 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121159164>
2019-04-26 10:47:01 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121181376>
2019-04-26 10:47:02 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121200287>
2019-04-26 10:47:02 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121198724>
2019-04-26 10:47:02 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121128170>
2019-04-26 10:47:02 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121182863>
2019-04-26 10:47:03 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121130446>
2019-04-26 10:47:03 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121136820>
2019-04-26 10:47:04 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121188132>
2019-04-26 10:47:04 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121143631>
2019-04-26 10:47:04 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121222598>
2019-04-26 10:47:04 engine.py[line:42] INFO: 爬虫结束: 2019-04-26 10:47:04.561364
2019-04-26 10:47:04 engine.py[line:43] INFO: 爬虫运行时间: 7.920002
2019-04-26 10:47:04 engine.py[line:45] INFO: 总的请求数量: 29个
2019-04-26 10:47:04 engine.py[line:46] INFO: 总的响应数量: 29个
2019-04-26 10:51:49 engine.py[line:39] INFO: 爬虫启动: 2019-04-26 10:51:49.907364
2019-04-26 10:51:50 downloader.py[line:26] INFO: <200 https://www.douban.com/>
2019-04-26 10:51:50 downloader.py[line:26] INFO: <200 https://www.douban.com/>
2019-04-26 10:51:51 downloader.py[line:26] INFO: <200 http://www.baidu.com/>
2019-04-26 10:51:51 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/1/>
2019-04-26 10:51:51 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/2/>
2019-04-26 10:51:51 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/3/>
2019-04-26 10:51:51 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/4/>
2019-04-26 10:51:52 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/5/>
2019-04-26 10:51:52 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/6/>
2019-04-26 10:51:52 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/7/>
2019-04-26 10:51:52 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/8/>
2019-04-26 10:51:53 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/9/>
2019-04-26 10:51:53 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/10/>
2019-04-26 10:51:53 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/11/>
2019-04-26 10:51:53 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/12/>
2019-04-26 10:51:54 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/13/>
2019-04-26 10:51:54 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121180425>
2019-04-26 10:51:54 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121208222>
2019-04-26 10:51:55 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121199348>
2019-04-26 10:51:55 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121172073>
2019-04-26 10:51:55 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121217241>
2019-04-26 10:51:55 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121179898>
2019-04-26 10:51:56 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121126636>
2019-04-26 10:51:56 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121192504>
2019-04-26 10:51:56 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121225381>
2019-04-26 10:51:57 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121148033>
2019-04-26 10:51:57 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121207938>
2019-04-26 10:51:57 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121166452>
2019-04-26 10:51:58 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121214682>
2019-04-26 10:51:58 engine.py[line:42] INFO: 爬虫结束: 2019-04-26 10:51:58.014371
2019-04-26 10:51:58 engine.py[line:43] INFO: 爬虫运行时间: 8.107007
2019-04-26 10:51:58 engine.py[line:45] INFO: 总的请求数量: 29个
2019-04-26 10:51:58 engine.py[line:46] INFO: 总的响应数量: 29个
2019-04-26 11:12:14 engine.py[line:39] INFO: 爬虫启动: 2019-04-26 11:12:14.180477
2019-04-26 11:12:14 downloader.py[line:26] INFO: <200 https://www.douban.com/>
2019-04-26 11:12:15 downloader.py[line:26] INFO: <200 https://www.douban.com/>
2019-04-26 11:12:15 downloader.py[line:26] INFO: <200 http://www.baidu.com/>
2019-04-26 11:12:15 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/1/>
2019-04-26 11:12:15 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/2/>
2019-04-26 11:12:16 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/3/>
2019-04-26 11:12:16 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/4/>
2019-04-26 11:12:16 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/5/>
2019-04-26 11:12:16 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/6/>
2019-04-26 11:12:16 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/7/>
2019-04-26 11:12:17 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/8/>
2019-04-26 11:12:17 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/9/>
2019-04-26 11:12:17 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/10/>
2019-04-26 11:12:17 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/11/>
2019-04-26 11:12:18 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/12/>
2019-04-26 11:12:18 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/13/>
2019-04-26 11:12:18 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121149997>
2019-04-26 11:12:18 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121157658>
2019-04-26 11:12:19 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121175883>
2019-04-26 11:12:19 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121183392>
2019-04-26 11:12:19 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121222892>
2019-04-26 11:12:20 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121166037>
2019-04-26 11:12:20 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121218196>
2019-04-26 11:12:20 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121140722>
2019-04-26 11:12:20 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121122606>
2019-04-26 11:12:21 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121226469>
2019-04-26 11:12:21 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121207816>
2019-04-26 11:12:21 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121147831>
2019-04-26 11:12:21 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121192791>
2019-04-26 11:12:22 engine.py[line:42] INFO: 爬虫结束: 2019-04-26 11:12:22.002463
2019-04-26 11:12:22 engine.py[line:43] INFO: 爬虫运行时间: 7.821986
2019-04-26 11:12:22 engine.py[line:45] INFO: 总的请求数量: 29个
2019-04-26 11:12:22 engine.py[line:46] INFO: 总的响应数量: 29个
2019-04-26 12:34:38 engine.py[line:67] INFO: 爬虫启动: 2019-04-26 12:34:38.512765
2019-04-26 12:34:39 downloader.py[line:26] INFO: <200 https://www.douban.com/>
2019-04-26 12:34:39 downloader.py[line:26] INFO: <200 https://www.douban.com/>
2019-04-26 12:34:39 downloader.py[line:26] INFO: <200 http://www.baidu.com/>
2019-04-26 12:34:39 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/1/>
2019-04-26 12:34:40 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/2/>
2019-04-26 12:34:40 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/3/>
2019-04-26 12:34:40 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/4/>
2019-04-26 12:34:40 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/5/>
2019-04-26 12:34:41 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/6/>
2019-04-26 12:34:41 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/7/>
2019-04-26 12:34:41 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/8/>
2019-04-26 12:34:41 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/9/>
2019-04-26 12:34:41 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/10/>
2019-04-26 12:34:42 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/11/>
2019-04-26 12:34:42 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/12/>
2019-04-26 12:34:42 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/13/>
2019-04-26 12:34:42 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121217335>
2019-04-26 12:34:43 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121219219>
2019-04-26 12:34:43 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121178488>
2019-04-26 12:34:43 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121165974>
2019-04-26 12:34:43 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121169635>
2019-04-26 12:34:44 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121157726>
2019-04-26 12:34:44 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121175851>
2019-04-26 12:34:44 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121159562>
2019-04-26 12:34:45 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121140696>
2019-04-26 12:34:45 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121147570>
2019-04-26 12:34:45 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121177112>
2019-04-26 12:34:45 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121212488>
2019-04-26 12:34:46 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121214382>
2019-04-26 12:34:46 engine.py[line:70] INFO: 爬虫结束: 2019-04-26 12:34:46.263765
2019-04-26 12:34:46 engine.py[line:71] INFO: 爬虫运行时间: 7.751
2019-04-26 12:34:46 engine.py[line:73] INFO: 总的请求数量: 29个
2019-04-26 12:34:46 engine.py[line:74] INFO: 总的响应数量: 29个
2019-04-26 14:58:30 engine.py[line:63] INFO: 爬虫启动: 2019-04-26 14:58:30.436915
2019-04-26 14:58:31 downloader.py[line:26] INFO: <200 https://www.douban.com/>
2019-04-26 14:58:31 downloader.py[line:26] INFO: <200 https://www.douban.com/>
2019-04-26 14:58:31 downloader.py[line:26] INFO: <200 http://www.baidu.com/>
2019-04-26 14:58:31 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/1/>
2019-04-26 14:58:32 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/2/>
2019-04-26 14:58:32 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/3/>
2019-04-26 14:58:32 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/4/>
2019-04-26 14:58:32 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/5/>
2019-04-26 14:58:33 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/6/>
2019-04-26 14:58:33 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/7/>
2019-04-26 14:58:33 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/8/>
2019-04-26 14:58:33 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/9/>
2019-04-26 14:58:34 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/10/>
2019-04-26 14:58:34 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/11/>
2019-04-26 14:58:34 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/12/>
2019-04-26 14:58:34 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/13/>
2019-04-26 14:58:35 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121184753>
2019-04-26 14:58:35 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121178016>
2019-04-26 14:58:35 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121171937>
2019-04-26 14:58:35 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121204909>
2019-04-26 14:58:36 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121216417>
2019-04-26 14:58:36 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121189022>
2019-04-26 14:58:36 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121184386>
2019-04-26 14:58:37 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121225443>
2019-04-26 14:58:37 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121143806>
2019-04-26 14:58:37 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121214929>
2019-04-26 14:58:37 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121221069>
2019-04-26 14:58:38 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121208136>
2019-04-26 14:58:38 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121210931>
2019-04-26 14:58:38 engine.py[line:66] INFO: 爬虫结束: 2019-04-26 14:58:38.401913
2019-04-26 14:58:38 engine.py[line:67] INFO: 爬虫运行时间: 7.964998
2019-04-26 14:58:38 engine.py[line:69] INFO: 总的请求数量: 29个
2019-04-26 14:58:38 engine.py[line:70] INFO: 总的响应数量: 29个
2019-04-26 14:59:27 engine.py[line:63] INFO: 爬虫启动: 2019-04-26 14:59:27.726923
2019-04-26 14:59:28 downloader.py[line:26] INFO: <200 https://www.douban.com/>
2019-04-26 14:59:28 downloader.py[line:26] INFO: <200 https://www.douban.com/>
2019-04-26 14:59:28 downloader.py[line:26] INFO: <200 http://www.baidu.com/>
2019-04-26 14:59:28 engine.py[line:66] INFO: 爬虫结束: 2019-04-26 14:59:28.864926
2019-04-26 14:59:28 engine.py[line:67] INFO: 爬虫运行时间: 1.138003
2019-04-26 14:59:28 engine.py[line:69] INFO: 总的请求数量: 3个
2019-04-26 14:59:28 engine.py[line:70] INFO: 总的响应数量: 3个
2019-04-26 15:02:07 engine.py[line:63] INFO: 爬虫启动: 2019-04-26 15:02:07.648035
2019-04-26 15:02:07 scheduler.py[line:59] INFO: 添加新的请求: <http://www.douban.com>
2019-04-26 15:02:24 engine.py[line:63] INFO: 爬虫启动: 2019-04-26 15:02:24.891599
2019-04-26 15:02:24 scheduler.py[line:59] INFO: 添加新的请求: <http://www.douban.com>
2019-04-26 15:02:24 scheduler.py[line:63] INFO: 发现重复的请求：<GET http://www.douban.com>
2019-04-26 15:02:24 scheduler.py[line:59] INFO: 添加新的请求: <http://www.baidu.com>
2019-04-26 15:02:25 downloader.py[line:26] INFO: <200 https://www.douban.com/>
2019-04-26 15:02:25 downloader.py[line:26] INFO: <200 http://www.baidu.com/>
2019-04-26 15:02:25 engine.py[line:66] INFO: 爬虫结束: 2019-04-26 15:02:25.496526
2019-04-26 15:02:25 engine.py[line:67] INFO: 爬虫运行时间: 0.604927
2019-04-26 15:02:25 engine.py[line:69] INFO: 总的请求数量: 3个
2019-04-26 15:02:25 engine.py[line:70] INFO: 总的响应数量: 2个
2019-04-26 15:03:58 engine.py[line:63] INFO: 爬虫启动: 2019-04-26 15:03:58.149455
2019-04-26 15:03:58 scheduler.py[line:59] INFO: 添加新的请求: <http://www.douban.com>
2019-04-26 15:03:58 scheduler.py[line:63] INFO: 发现重复的请求：<GET http://www.douban.com>
2019-04-26 15:03:58 scheduler.py[line:59] INFO: 添加新的请求: <http://www.baidu.com>
2019-04-26 15:03:58 downloader.py[line:26] INFO: <200 https://www.douban.com/>
2019-04-26 15:03:58 downloader.py[line:26] INFO: <200 http://www.baidu.com/>
2019-04-26 15:03:58 engine.py[line:66] INFO: 爬虫结束: 2019-04-26 15:03:58.781455
2019-04-26 15:03:58 engine.py[line:67] INFO: 爬虫运行时间: 0.632
2019-04-26 15:03:58 engine.py[line:69] INFO: 总的请求数量: 3个
2019-04-26 15:03:58 engine.py[line:70] INFO: 总的响应数量: 2个
2019-04-26 15:03:58 engine.py[line:71] INFO: 总的重复数量: 1个
2019-04-26 15:12:07 engine.py[line:63] INFO: 爬虫启动: 2019-04-26 15:12:07.720457
2019-04-26 15:12:07 scheduler.py[line:59] INFO: 添加新的请求: <http://www.douban.com>
2019-04-26 15:12:07 scheduler.py[line:63] INFO: 发现重复的请求：<GET http://www.douban.com>
2019-04-26 15:12:07 scheduler.py[line:59] INFO: 添加新的请求: <http://www.baidu.com>
2019-04-26 15:12:08 downloader.py[line:26] INFO: <200 https://www.douban.com/>
2019-04-26 15:12:08 downloader.py[line:26] INFO: <200 http://www.baidu.com/>
2019-04-26 15:12:08 engine.py[line:66] INFO: 爬虫结束: 2019-04-26 15:12:08.360455
2019-04-26 15:12:08 engine.py[line:67] INFO: 爬虫运行时间: 0.639998
2019-04-26 15:12:08 engine.py[line:69] INFO: 总的请求数量: 3个
2019-04-26 15:12:08 engine.py[line:70] INFO: 总的响应数量: 2个
2019-04-26 15:12:08 engine.py[line:71] INFO: 总的重复数量: 1个
2019-04-26 15:15:54 engine.py[line:63] INFO: 爬虫启动: 2019-04-26 15:15:54.838816
2019-04-26 15:15:54 engine.py[line:64] INFO: 当前启动的爬虫: ['spiders.baidu.BaiduSpider']
2019-04-26 15:15:54 engine.py[line:65] INFO: 当前开启的管道: ['pipelines.BaiduPipeline', 'pipelines.QiubaiPipeline']
2019-04-26 15:15:54 engine.py[line:66] INFO: 当前开启的下载器中间件: ['spider_middlewares.TestSpiderMiddleware1']
2019-04-26 15:15:54 engine.py[line:67] INFO: 当前开启的爬虫中间件: ['downloader_middlewares.TestDownloaderMiddleware2']
2019-04-26 15:15:54 scheduler.py[line:59] INFO: 添加新的请求: <http://www.douban.com>
2019-04-26 15:15:54 scheduler.py[line:63] INFO: 发现重复的请求：<GET http://www.douban.com>
2019-04-26 15:15:54 scheduler.py[line:59] INFO: 添加新的请求: <http://www.baidu.com>
2019-04-26 15:15:55 downloader.py[line:26] INFO: <200 https://www.douban.com/>
2019-04-26 15:15:55 downloader.py[line:26] INFO: <200 http://www.baidu.com/>
2019-04-26 15:15:55 engine.py[line:70] INFO: 爬虫结束: 2019-04-26 15:15:55.491820
2019-04-26 15:15:55 engine.py[line:71] INFO: 爬虫运行时间: 0.653004
2019-04-26 15:15:55 engine.py[line:73] INFO: 总的请求数量: 3个
2019-04-26 15:15:55 engine.py[line:74] INFO: 总的响应数量: 2个
2019-04-26 15:15:55 engine.py[line:75] INFO: 总的重复数量: 1个
2019-04-26 16:36:50 engine.py[line:68] INFO: 爬虫启动: 2019-04-26 16:36:50.132483
2019-04-26 16:36:50 engine.py[line:69] INFO: 当前启动的爬虫: ['spiders.baidu.BaiduSpider']
2019-04-26 16:36:50 engine.py[line:70] INFO: 当前开启的管道: ['pipelines.BaiduPipeline', 'pipelines.QiubaiPipeline']
2019-04-26 16:36:50 engine.py[line:71] INFO: 当前开启的下载器中间件: ['spider_middlewares.TestSpiderMiddleware1']
2019-04-26 16:36:50 engine.py[line:72] INFO: 当前开启的爬虫中间件: ['downloader_middlewares.TestDownloaderMiddleware2']
2019-04-26 16:36:50 scheduler.py[line:59] INFO: 添加新的请求: <http://www.douban.com>
2019-04-26 16:36:50 scheduler.py[line:63] INFO: 发现重复的请求：<GET http://www.douban.com>
2019-04-26 16:36:50 scheduler.py[line:59] INFO: 添加新的请求: <http://www.baidu.com>
2019-04-26 16:36:50 engine.py[line:75] INFO: 爬虫结束: 2019-04-26 16:36:50.136486
2019-04-26 16:36:50 engine.py[line:76] INFO: 爬虫运行时间: 0.004003
2019-04-26 16:36:50 engine.py[line:78] INFO: 总的请求数量: 3个
2019-04-26 16:36:50 engine.py[line:79] INFO: 总的响应数量: 0个
2019-04-26 16:36:50 engine.py[line:80] INFO: 总的重复数量: 1个
2019-04-26 16:37:08 engine.py[line:68] INFO: 爬虫启动: 2019-04-26 16:37:08.911483
2019-04-26 16:37:08 engine.py[line:69] INFO: 当前启动的爬虫: ['spiders.baidu.BaiduSpider', 'spiders.qiubai.QiubaiSpider']
2019-04-26 16:37:08 engine.py[line:70] INFO: 当前开启的管道: ['pipelines.BaiduPipeline', 'pipelines.QiubaiPipeline']
2019-04-26 16:37:08 engine.py[line:71] INFO: 当前开启的下载器中间件: ['spider_middlewares.TestSpiderMiddleware1']
2019-04-26 16:37:08 engine.py[line:72] INFO: 当前开启的爬虫中间件: ['downloader_middlewares.TestDownloaderMiddleware2']
2019-04-26 16:37:08 scheduler.py[line:59] INFO: 添加新的请求: <http://www.douban.com>
2019-04-26 16:37:08 scheduler.py[line:63] INFO: 发现重复的请求：<GET http://www.douban.com>
2019-04-26 16:37:08 scheduler.py[line:59] INFO: 添加新的请求: <http://www.baidu.com>
2019-04-26 16:37:08 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/1/>
2019-04-26 16:37:08 engine.py[line:75] INFO: 爬虫结束: 2019-04-26 16:37:08.914483
2019-04-26 16:37:08 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/2/>
2019-04-26 16:37:08 engine.py[line:76] INFO: 爬虫运行时间: 0.003
2019-04-26 16:37:08 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/3/>
2019-04-26 16:37:08 engine.py[line:78] INFO: 总的请求数量: 5个
2019-04-26 16:37:08 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/4/>
2019-04-26 16:37:08 engine.py[line:79] INFO: 总的响应数量: 0个
2019-04-26 16:37:08 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/5/>
2019-04-26 16:37:08 engine.py[line:80] INFO: 总的重复数量: 1个
2019-04-26 16:37:08 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/6/>
2019-04-26 16:37:08 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/7/>
2019-04-26 16:37:08 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/8/>
2019-04-26 16:37:08 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/9/>
2019-04-26 16:37:08 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/10/>
2019-04-26 16:37:08 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/11/>
2019-04-26 16:37:08 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/12/>
2019-04-26 16:37:08 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/13/>
2019-04-26 16:38:01 engine.py[line:68] INFO: 爬虫启动: 2019-04-26 16:38:01.912487
2019-04-26 16:38:01 engine.py[line:69] INFO: 当前启动的爬虫: ['spiders.baidu.BaiduSpider', 'spiders.qiubai.QiubaiSpider']
2019-04-26 16:38:01 engine.py[line:70] INFO: 当前开启的管道: ['pipelines.BaiduPipeline', 'pipelines.QiubaiPipeline']
2019-04-26 16:38:01 engine.py[line:71] INFO: 当前开启的下载器中间件: ['spider_middlewares.TestSpiderMiddleware1']
2019-04-26 16:38:01 engine.py[line:72] INFO: 当前开启的爬虫中间件: ['downloader_middlewares.TestDownloaderMiddleware2']
2019-04-26 16:38:01 scheduler.py[line:59] INFO: 添加新的请求: <http://www.douban.com>
2019-04-26 16:38:01 scheduler.py[line:63] INFO: 发现重复的请求：<GET http://www.douban.com>
2019-04-26 16:38:01 engine.py[line:75] INFO: 爬虫结束: 2019-04-26 16:38:01.915492
2019-04-26 16:38:01 scheduler.py[line:59] INFO: 添加新的请求: <http://www.baidu.com>
2019-04-26 16:38:01 engine.py[line:76] INFO: 爬虫运行时间: 0.003005
2019-04-26 16:38:01 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/1/>
2019-04-26 16:38:01 engine.py[line:78] INFO: 总的请求数量: 3个
2019-04-26 16:38:01 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/2/>
2019-04-26 16:38:01 engine.py[line:79] INFO: 总的响应数量: 0个
2019-04-26 16:38:01 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/3/>
2019-04-26 16:38:01 engine.py[line:80] INFO: 总的重复数量: 1个
2019-04-26 16:38:01 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/4/>
2019-04-26 16:38:01 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/5/>
2019-04-26 16:38:01 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/6/>
2019-04-26 16:38:01 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/7/>
2019-04-26 16:38:01 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/8/>
2019-04-26 16:38:01 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/9/>
2019-04-26 16:38:01 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/10/>
2019-04-26 16:38:01 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/11/>
2019-04-26 16:38:01 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/12/>
2019-04-26 16:38:01 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/13/>
2019-04-26 16:38:15 engine.py[line:68] INFO: 爬虫启动: 2019-04-26 16:38:15.048512
2019-04-26 16:38:15 engine.py[line:69] INFO: 当前启动的爬虫: ['spiders.baidu.BaiduSpider', 'spiders.qiubai.QiubaiSpider']
2019-04-26 16:38:15 engine.py[line:70] INFO: 当前开启的管道: ['pipelines.BaiduPipeline', 'pipelines.QiubaiPipeline']
2019-04-26 16:38:15 engine.py[line:71] INFO: 当前开启的下载器中间件: ['spider_middlewares.TestSpiderMiddleware1']
2019-04-26 16:38:15 engine.py[line:72] INFO: 当前开启的爬虫中间件: ['downloader_middlewares.TestDownloaderMiddleware2']
2019-04-26 16:38:15 scheduler.py[line:59] INFO: 添加新的请求: <http://www.douban.com>
2019-04-26 16:38:15 scheduler.py[line:63] INFO: 发现重复的请求：<GET http://www.douban.com>
2019-04-26 16:38:15 scheduler.py[line:59] INFO: 添加新的请求: <http://www.baidu.com>
2019-04-26 16:38:15 engine.py[line:75] INFO: 爬虫结束: 2019-04-26 16:38:15.051507
2019-04-26 16:38:15 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/1/>
2019-04-26 16:38:15 engine.py[line:76] INFO: 爬虫运行时间: 0.002995
2019-04-26 16:38:15 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/2/>
2019-04-26 16:38:15 engine.py[line:78] INFO: 总的请求数量: 4个
2019-04-26 16:38:15 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/3/>
2019-04-26 16:38:15 engine.py[line:79] INFO: 总的响应数量: 0个
2019-04-26 16:38:15 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/4/>
2019-04-26 16:38:15 engine.py[line:80] INFO: 总的重复数量: 1个
2019-04-26 16:38:15 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/5/>
2019-04-26 16:38:15 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/6/>
2019-04-26 16:38:15 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/7/>
2019-04-26 16:38:15 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/8/>
2019-04-26 16:38:15 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/9/>
2019-04-26 16:38:15 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/10/>
2019-04-26 16:38:15 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/11/>
2019-04-26 16:38:15 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/12/>
2019-04-26 16:38:15 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/13/>
2019-04-26 16:39:28 engine.py[line:68] INFO: 爬虫启动: 2019-04-26 16:39:28.422505
2019-04-26 16:39:28 engine.py[line:69] INFO: 当前启动的爬虫: ['spiders.baidu.BaiduSpider', 'spiders.qiubai.QiubaiSpider']
2019-04-26 16:39:28 engine.py[line:70] INFO: 当前开启的管道: ['pipelines.BaiduPipeline', 'pipelines.QiubaiPipeline']
2019-04-26 16:39:28 engine.py[line:71] INFO: 当前开启的下载器中间件: ['spider_middlewares.TestSpiderMiddleware1']
2019-04-26 16:39:28 engine.py[line:72] INFO: 当前开启的爬虫中间件: ['downloader_middlewares.TestDownloaderMiddleware2']
2019-04-26 16:39:28 scheduler.py[line:59] INFO: 添加新的请求: <http://www.douban.com>
2019-04-26 16:39:28 scheduler.py[line:63] INFO: 发现重复的请求：<GET http://www.douban.com>
2019-04-26 16:39:28 scheduler.py[line:59] INFO: 添加新的请求: <http://www.baidu.com>
2019-04-26 16:39:28 engine.py[line:75] INFO: 爬虫结束: 2019-04-26 16:39:28.425505
2019-04-26 16:39:28 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/1/>
2019-04-26 16:39:28 engine.py[line:76] INFO: 爬虫运行时间: 0.003
2019-04-26 16:39:28 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/2/>
2019-04-26 16:39:28 engine.py[line:78] INFO: 总的请求数量: 4个
2019-04-26 16:39:28 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/3/>
2019-04-26 16:39:28 engine.py[line:79] INFO: 总的响应数量: 0个
2019-04-26 16:39:28 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/4/>
2019-04-26 16:39:28 engine.py[line:80] INFO: 总的重复数量: 1个
2019-04-26 16:39:28 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/5/>
2019-04-26 16:39:28 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/6/>
2019-04-26 16:39:28 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/7/>
2019-04-26 16:39:28 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/8/>
2019-04-26 16:39:28 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/9/>
2019-04-26 16:39:28 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/10/>
2019-04-26 16:39:28 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/11/>
2019-04-26 16:39:28 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/12/>
2019-04-26 16:39:28 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/13/>
2019-04-26 16:40:38 engine.py[line:68] INFO: 爬虫启动: 2019-04-26 16:40:38.100514
2019-04-26 16:40:38 engine.py[line:69] INFO: 当前启动的爬虫: ['spiders.baidu.BaiduSpider', 'spiders.qiubai.QiubaiSpider']
2019-04-26 16:40:38 engine.py[line:70] INFO: 当前开启的管道: ['pipelines.BaiduPipeline', 'pipelines.QiubaiPipeline']
2019-04-26 16:40:38 engine.py[line:71] INFO: 当前开启的下载器中间件: ['spider_middlewares.TestSpiderMiddleware1']
2019-04-26 16:40:38 engine.py[line:72] INFO: 当前开启的爬虫中间件: ['downloader_middlewares.TestDownloaderMiddleware2']
2019-04-26 16:40:38 scheduler.py[line:59] INFO: 添加新的请求: <http://www.douban.com>
2019-04-26 16:40:38 scheduler.py[line:63] INFO: 发现重复的请求：<GET http://www.douban.com>
2019-04-26 16:40:38 scheduler.py[line:59] INFO: 添加新的请求: <http://www.baidu.com>
2019-04-26 16:40:38 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/1/>
2019-04-26 16:40:38 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/2/>
2019-04-26 16:40:38 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/3/>
2019-04-26 16:40:38 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/4/>
2019-04-26 16:40:38 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/5/>
2019-04-26 16:40:38 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/6/>
2019-04-26 16:40:38 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/7/>
2019-04-26 16:40:38 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/8/>
2019-04-26 16:40:38 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/9/>
2019-04-26 16:40:38 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/10/>
2019-04-26 16:40:38 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/11/>
2019-04-26 16:40:38 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/12/>
2019-04-26 16:40:38 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/13/>
2019-04-26 16:40:39 downloader.py[line:26] INFO: <200 https://www.douban.com/>
2019-04-26 16:41:38 engine.py[line:68] INFO: 爬虫启动: 2019-04-26 16:41:38.794508
2019-04-26 16:41:38 engine.py[line:69] INFO: 当前启动的爬虫: ['spiders.baidu.BaiduSpider', 'spiders.qiubai.QiubaiSpider']
2019-04-26 16:41:38 engine.py[line:70] INFO: 当前开启的管道: ['pipelines.BaiduPipeline', 'pipelines.QiubaiPipeline']
2019-04-26 16:41:38 engine.py[line:71] INFO: 当前开启的下载器中间件: ['spider_middlewares.TestSpiderMiddleware1']
2019-04-26 16:41:38 engine.py[line:72] INFO: 当前开启的爬虫中间件: ['downloader_middlewares.TestDownloaderMiddleware2']
2019-04-26 16:41:38 scheduler.py[line:59] INFO: 添加新的请求: <http://www.douban.com>
2019-04-26 16:41:38 scheduler.py[line:63] INFO: 发现重复的请求：<GET http://www.douban.com>
2019-04-26 16:41:38 scheduler.py[line:59] INFO: 添加新的请求: <http://www.baidu.com>
2019-04-26 16:41:38 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/1/>
2019-04-26 16:41:38 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/2/>
2019-04-26 16:41:38 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/3/>
2019-04-26 16:41:38 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/4/>
2019-04-26 16:41:38 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/5/>
2019-04-26 16:41:38 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/6/>
2019-04-26 16:41:38 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/7/>
2019-04-26 16:41:38 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/8/>
2019-04-26 16:41:38 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/9/>
2019-04-26 16:41:38 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/10/>
2019-04-26 16:41:38 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/11/>
2019-04-26 16:41:38 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/12/>
2019-04-26 16:41:38 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/13/>
2019-04-26 16:41:53 engine.py[line:68] INFO: 爬虫启动: 2019-04-26 16:41:53.077509
2019-04-26 16:41:53 engine.py[line:69] INFO: 当前启动的爬虫: ['spiders.baidu.BaiduSpider', 'spiders.qiubai.QiubaiSpider']
2019-04-26 16:41:53 engine.py[line:70] INFO: 当前开启的管道: ['pipelines.BaiduPipeline', 'pipelines.QiubaiPipeline']
2019-04-26 16:41:53 engine.py[line:71] INFO: 当前开启的下载器中间件: ['spider_middlewares.TestSpiderMiddleware1']
2019-04-26 16:41:53 engine.py[line:72] INFO: 当前开启的爬虫中间件: ['downloader_middlewares.TestDownloaderMiddleware2']
2019-04-26 16:41:53 scheduler.py[line:59] INFO: 添加新的请求: <http://www.douban.com>
2019-04-26 16:41:53 scheduler.py[line:63] INFO: 发现重复的请求：<GET http://www.douban.com>
2019-04-26 16:41:53 scheduler.py[line:59] INFO: 添加新的请求: <http://www.baidu.com>
2019-04-26 16:41:53 engine.py[line:75] INFO: 爬虫结束: 2019-04-26 16:41:53.080507
2019-04-26 16:41:53 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/1/>
2019-04-26 16:41:53 engine.py[line:76] INFO: 爬虫运行时间: 0.002998
2019-04-26 16:41:53 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/2/>
2019-04-26 16:41:53 engine.py[line:78] INFO: 总的请求数量: 4个
2019-04-26 16:41:53 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/3/>
2019-04-26 16:41:53 engine.py[line:79] INFO: 总的响应数量: 0个
2019-04-26 16:41:53 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/4/>
2019-04-26 16:41:53 engine.py[line:80] INFO: 总的重复数量: 1个
2019-04-26 16:41:53 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/5/>
2019-04-26 16:41:53 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/6/>
2019-04-26 16:41:53 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/7/>
2019-04-26 16:41:53 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/8/>
2019-04-26 16:41:53 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/9/>
2019-04-26 16:41:53 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/10/>
2019-04-26 16:41:53 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/11/>
2019-04-26 16:41:53 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/12/>
2019-04-26 16:41:53 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/13/>
2019-04-26 16:42:55 engine.py[line:67] INFO: 爬虫启动: 2019-04-26 16:42:55.527509
2019-04-26 16:42:55 engine.py[line:68] INFO: 当前启动的爬虫: ['spiders.baidu.BaiduSpider', 'spiders.qiubai.QiubaiSpider']
2019-04-26 16:42:55 engine.py[line:69] INFO: 当前开启的管道: ['pipelines.BaiduPipeline', 'pipelines.QiubaiPipeline']
2019-04-26 16:42:55 engine.py[line:70] INFO: 当前开启的下载器中间件: ['spider_middlewares.TestSpiderMiddleware1']
2019-04-26 16:42:55 engine.py[line:71] INFO: 当前开启的爬虫中间件: ['downloader_middlewares.TestDownloaderMiddleware2']
2019-04-26 16:42:55 scheduler.py[line:59] INFO: 添加新的请求: <http://www.douban.com>
2019-04-26 16:42:55 scheduler.py[line:63] INFO: 发现重复的请求：<GET http://www.douban.com>
2019-04-26 16:42:55 scheduler.py[line:59] INFO: 添加新的请求: <http://www.baidu.com>
2019-04-26 16:42:55 engine.py[line:74] INFO: 爬虫结束: 2019-04-26 16:42:55.530507
2019-04-26 16:42:55 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/1/>
2019-04-26 16:42:55 engine.py[line:75] INFO: 爬虫运行时间: 0.002998
2019-04-26 16:42:55 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/2/>
2019-04-26 16:42:55 engine.py[line:77] INFO: 总的请求数量: 4个
2019-04-26 16:42:55 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/3/>
2019-04-26 16:42:55 engine.py[line:78] INFO: 总的响应数量: 0个
2019-04-26 16:42:55 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/4/>
2019-04-26 16:42:55 engine.py[line:79] INFO: 总的重复数量: 1个
2019-04-26 16:42:55 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/5/>
2019-04-26 16:42:55 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/6/>
2019-04-26 16:42:55 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/7/>
2019-04-26 16:42:55 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/8/>
2019-04-26 16:42:55 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/9/>
2019-04-26 16:42:55 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/10/>
2019-04-26 16:42:55 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/11/>
2019-04-26 16:42:55 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/12/>
2019-04-26 16:42:55 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/13/>
2019-04-26 16:44:07 engine.py[line:67] INFO: 爬虫启动: 2019-04-26 16:44:07.880507
2019-04-26 16:44:07 engine.py[line:68] INFO: 当前启动的爬虫: ['spiders.baidu.BaiduSpider', 'spiders.qiubai.QiubaiSpider']
2019-04-26 16:44:07 engine.py[line:69] INFO: 当前开启的管道: ['pipelines.BaiduPipeline', 'pipelines.QiubaiPipeline']
2019-04-26 16:44:07 engine.py[line:70] INFO: 当前开启的下载器中间件: ['spider_middlewares.TestSpiderMiddleware1']
2019-04-26 16:44:07 engine.py[line:71] INFO: 当前开启的爬虫中间件: ['downloader_middlewares.TestDownloaderMiddleware2']
2019-04-26 16:44:07 scheduler.py[line:59] INFO: 添加新的请求: <http://www.douban.com>
2019-04-26 16:44:07 scheduler.py[line:63] INFO: 发现重复的请求：<GET http://www.douban.com>
2019-04-26 16:44:07 scheduler.py[line:59] INFO: 添加新的请求: <http://www.baidu.com>
2019-04-26 16:44:07 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/1/>
2019-04-26 16:44:07 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/2/>
2019-04-26 16:44:07 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/3/>
2019-04-26 16:44:07 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/4/>
2019-04-26 16:44:07 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/5/>
2019-04-26 16:44:07 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/6/>
2019-04-26 16:44:07 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/7/>
2019-04-26 16:44:07 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/8/>
2019-04-26 16:44:07 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/9/>
2019-04-26 16:44:07 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/10/>
2019-04-26 16:44:07 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/11/>
2019-04-26 16:44:07 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/12/>
2019-04-26 16:44:07 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/13/>
2019-04-26 16:44:08 downloader.py[line:26] INFO: <200 https://www.douban.com/>
2019-04-26 16:44:38 engine.py[line:67] INFO: 爬虫启动: 2019-04-26 16:44:38.300522
2019-04-26 16:44:38 engine.py[line:68] INFO: 当前启动的爬虫: ['spiders.baidu.BaiduSpider', 'spiders.qiubai.QiubaiSpider']
2019-04-26 16:44:38 engine.py[line:69] INFO: 当前开启的管道: ['pipelines.BaiduPipeline', 'pipelines.QiubaiPipeline']
2019-04-26 16:44:38 engine.py[line:70] INFO: 当前开启的下载器中间件: ['spider_middlewares.TestSpiderMiddleware1']
2019-04-26 16:44:38 engine.py[line:71] INFO: 当前开启的爬虫中间件: ['downloader_middlewares.TestDownloaderMiddleware2']
2019-04-26 16:44:38 scheduler.py[line:59] INFO: 添加新的请求: <http://www.douban.com>
2019-04-26 16:44:38 scheduler.py[line:63] INFO: 发现重复的请求：<GET http://www.douban.com>
2019-04-26 16:44:38 scheduler.py[line:59] INFO: 添加新的请求: <http://www.baidu.com>
2019-04-26 16:44:38 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/1/>
2019-04-26 16:44:38 engine.py[line:74] INFO: 爬虫结束: 2019-04-26 16:44:38.306520
2019-04-26 16:44:38 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/2/>
2019-04-26 16:44:38 engine.py[line:75] INFO: 爬虫运行时间: 0.005998
2019-04-26 16:44:38 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/3/>
2019-04-26 16:44:38 engine.py[line:77] INFO: 总的请求数量: 5个
2019-04-26 16:44:38 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/4/>
2019-04-26 16:44:38 engine.py[line:78] INFO: 总的响应数量: 0个
2019-04-26 16:44:38 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/5/>
2019-04-26 16:44:38 engine.py[line:79] INFO: 总的重复数量: 1个
2019-04-26 16:44:38 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/6/>
2019-04-26 16:44:38 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/7/>
2019-04-26 16:44:38 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/8/>
2019-04-26 16:44:38 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/9/>
2019-04-26 16:44:38 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/10/>
2019-04-26 16:44:38 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/11/>
2019-04-26 16:44:38 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/12/>
2019-04-26 16:44:38 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/13/>
2019-04-26 16:45:22 engine.py[line:67] INFO: 爬虫启动: 2019-04-26 16:45:22.984508
2019-04-26 16:45:22 engine.py[line:68] INFO: 当前启动的爬虫: ['spiders.baidu.BaiduSpider', 'spiders.qiubai.QiubaiSpider']
2019-04-26 16:45:22 engine.py[line:69] INFO: 当前开启的管道: ['pipelines.BaiduPipeline', 'pipelines.QiubaiPipeline']
2019-04-26 16:45:22 engine.py[line:70] INFO: 当前开启的下载器中间件: ['spider_middlewares.TestSpiderMiddleware1']
2019-04-26 16:45:22 engine.py[line:71] INFO: 当前开启的爬虫中间件: ['downloader_middlewares.TestDownloaderMiddleware2']
2019-04-26 16:45:22 scheduler.py[line:59] INFO: 添加新的请求: <http://www.douban.com>
2019-04-26 16:45:22 scheduler.py[line:63] INFO: 发现重复的请求：<GET http://www.douban.com>
2019-04-26 16:45:22 scheduler.py[line:59] INFO: 添加新的请求: <http://www.baidu.com>
2019-04-26 16:45:22 engine.py[line:74] INFO: 爬虫结束: 2019-04-26 16:45:22.987508
2019-04-26 16:45:22 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/1/>
2019-04-26 16:45:22 engine.py[line:75] INFO: 爬虫运行时间: 0.003
2019-04-26 16:45:22 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/2/>
2019-04-26 16:45:22 engine.py[line:77] INFO: 总的请求数量: 4个
2019-04-26 16:45:22 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/3/>
2019-04-26 16:45:22 engine.py[line:78] INFO: 总的响应数量: 0个
2019-04-26 16:45:22 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/4/>
2019-04-26 16:45:22 engine.py[line:79] INFO: 总的重复数量: 1个
2019-04-26 16:45:22 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/5/>
2019-04-26 16:45:22 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/6/>
2019-04-26 16:45:22 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/7/>
2019-04-26 16:45:22 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/8/>
2019-04-26 16:45:22 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/9/>
2019-04-26 16:45:22 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/10/>
2019-04-26 16:45:22 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/11/>
2019-04-26 16:45:22 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/12/>
2019-04-26 16:45:22 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/13/>
2019-04-26 16:47:47 engine.py[line:67] INFO: 爬虫启动: 2019-04-26 16:47:47.774507
2019-04-26 16:47:47 engine.py[line:68] INFO: 当前启动的爬虫: ['spiders.baidu.BaiduSpider', 'spiders.qiubai.QiubaiSpider']
2019-04-26 16:47:47 engine.py[line:69] INFO: 当前开启的管道: ['pipelines.BaiduPipeline', 'pipelines.QiubaiPipeline']
2019-04-26 16:47:47 engine.py[line:70] INFO: 当前开启的下载器中间件: ['spider_middlewares.TestSpiderMiddleware1']
2019-04-26 16:47:47 engine.py[line:71] INFO: 当前开启的爬虫中间件: ['downloader_middlewares.TestDownloaderMiddleware2']
2019-04-26 16:47:47 scheduler.py[line:59] INFO: 添加新的请求: <http://www.douban.com>
2019-04-26 16:47:47 scheduler.py[line:63] INFO: 发现重复的请求：<GET http://www.douban.com>
2019-04-26 16:47:47 engine.py[line:74] INFO: 爬虫结束: 2019-04-26 16:47:47.777518
2019-04-26 16:47:47 scheduler.py[line:59] INFO: 添加新的请求: <http://www.baidu.com>
2019-04-26 16:47:47 engine.py[line:75] INFO: 爬虫运行时间: 0.003011
2019-04-26 16:47:47 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/1/>
2019-04-26 16:47:47 engine.py[line:77] INFO: 总的请求数量: 3个
2019-04-26 16:47:47 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/2/>
2019-04-26 16:47:47 engine.py[line:78] INFO: 总的响应数量: 0个
2019-04-26 16:47:47 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/3/>
2019-04-26 16:47:47 engine.py[line:79] INFO: 总的重复数量: 1个
2019-04-26 16:47:47 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/4/>
2019-04-26 16:47:47 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/5/>
2019-04-26 16:47:47 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/6/>
2019-04-26 16:47:47 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/7/>
2019-04-26 16:47:47 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/8/>
2019-04-26 16:47:47 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/9/>
2019-04-26 16:47:47 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/10/>
2019-04-26 16:47:47 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/11/>
2019-04-26 16:47:47 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/12/>
2019-04-26 16:47:47 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/13/>
2019-04-26 16:48:34 engine.py[line:67] INFO: 爬虫启动: 2019-04-26 16:48:34.492507
2019-04-26 16:48:34 engine.py[line:68] INFO: 当前启动的爬虫: ['spiders.baidu.BaiduSpider', 'spiders.qiubai.QiubaiSpider']
2019-04-26 16:48:34 engine.py[line:69] INFO: 当前开启的管道: ['pipelines.BaiduPipeline', 'pipelines.QiubaiPipeline']
2019-04-26 16:48:34 engine.py[line:70] INFO: 当前开启的下载器中间件: ['spider_middlewares.TestSpiderMiddleware1']
2019-04-26 16:48:34 engine.py[line:71] INFO: 当前开启的爬虫中间件: ['downloader_middlewares.TestDownloaderMiddleware2']
2019-04-26 16:48:34 scheduler.py[line:59] INFO: 添加新的请求: <http://www.douban.com>
2019-04-26 16:48:34 scheduler.py[line:63] INFO: 发现重复的请求：<GET http://www.douban.com>
2019-04-26 16:48:34 scheduler.py[line:59] INFO: 添加新的请求: <http://www.baidu.com>
2019-04-26 16:48:34 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/1/>
2019-04-26 16:48:34 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/2/>
2019-04-26 16:48:34 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/3/>
2019-04-26 16:48:34 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/4/>
2019-04-26 16:48:34 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/5/>
2019-04-26 16:48:34 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/6/>
2019-04-26 16:48:34 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/7/>
2019-04-26 16:48:34 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/8/>
2019-04-26 16:48:34 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/9/>
2019-04-26 16:48:34 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/10/>
2019-04-26 16:48:34 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/11/>
2019-04-26 16:48:34 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/12/>
2019-04-26 16:48:34 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/13/>
2019-04-26 16:48:35 downloader.py[line:26] INFO: <200 https://www.douban.com/>
2019-04-26 16:48:35 downloader.py[line:26] INFO: <200 http://www.baidu.com/>
2019-04-26 16:48:35 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/1/>
2019-04-26 16:48:35 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121170509>
2019-04-26 16:48:35 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/2/>
2019-04-26 16:48:35 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121207643>
2019-04-26 16:48:35 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/3/>
2019-04-26 16:48:35 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121181776>
2019-04-26 16:48:36 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/4/>
2019-04-26 16:48:36 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121133753>
2019-04-26 16:48:36 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/5/>
2019-04-26 16:48:36 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121218849>
2019-04-26 16:48:36 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/6/>
2019-04-26 16:48:36 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121168901>
2019-04-26 16:48:36 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/7/>
2019-04-26 16:48:36 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121172765>
2019-04-26 16:48:37 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/8/>
2019-04-26 16:48:37 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121179429>
2019-04-26 16:48:37 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/9/>
2019-04-26 16:48:37 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121176368>
2019-04-26 16:48:37 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/10/>
2019-04-26 16:48:37 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121151646>
2019-04-26 16:48:37 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/11/>
2019-04-26 16:48:37 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121220444>
2019-04-26 16:48:38 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/12/>
2019-04-26 16:48:38 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121211058>
2019-04-26 16:48:38 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/13/>
2019-04-26 16:48:38 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121149745>
2019-04-26 16:48:38 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121170509>
2019-04-26 16:48:38 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121207643>
2019-04-26 16:48:39 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121181776>
2019-04-26 16:48:39 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121133753>
2019-04-26 16:48:39 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121218849>
2019-04-26 16:48:39 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121168901>
2019-04-26 16:49:17 engine.py[line:67] INFO: 爬虫启动: 2019-04-26 16:49:17.335503
2019-04-26 16:49:17 engine.py[line:68] INFO: 当前启动的爬虫: ['spiders.baidu.BaiduSpider', 'spiders.qiubai.QiubaiSpider']
2019-04-26 16:49:17 engine.py[line:69] INFO: 当前开启的管道: ['pipelines.BaiduPipeline', 'pipelines.QiubaiPipeline']
2019-04-26 16:49:17 engine.py[line:70] INFO: 当前开启的下载器中间件: ['spider_middlewares.TestSpiderMiddleware1']
2019-04-26 16:49:17 engine.py[line:71] INFO: 当前开启的爬虫中间件: ['downloader_middlewares.TestDownloaderMiddleware2']
2019-04-26 16:49:17 scheduler.py[line:59] INFO: 添加新的请求: <http://www.douban.com>
2019-04-26 16:49:17 scheduler.py[line:63] INFO: 发现重复的请求：<GET http://www.douban.com>
2019-04-26 16:49:17 scheduler.py[line:59] INFO: 添加新的请求: <http://www.baidu.com>
2019-04-26 16:49:17 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/1/>
2019-04-26 16:49:17 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/2/>
2019-04-26 16:49:17 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/3/>
2019-04-26 16:49:17 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/4/>
2019-04-26 16:49:17 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/5/>
2019-04-26 16:49:17 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/6/>
2019-04-26 16:49:17 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/7/>
2019-04-26 16:49:17 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/8/>
2019-04-26 16:49:17 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/9/>
2019-04-26 16:49:17 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/10/>
2019-04-26 16:49:17 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/11/>
2019-04-26 16:49:17 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/12/>
2019-04-26 16:49:17 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/13/>
2019-04-26 16:49:17 downloader.py[line:26] INFO: <200 https://www.douban.com/>
2019-04-26 16:49:17 downloader.py[line:26] INFO: <200 http://www.baidu.com/>
2019-04-26 16:49:18 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/1/>
2019-04-26 16:49:18 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121170509>
2019-04-26 16:49:18 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/2/>
2019-04-26 16:49:18 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121207643>
2019-04-26 16:49:18 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/3/>
2019-04-26 16:49:18 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121181776>
2019-04-26 16:49:18 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/4/>
2019-04-26 16:49:18 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121133753>
2019-04-26 16:49:19 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/5/>
2019-04-26 16:49:19 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121218849>
2019-04-26 16:49:19 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/6/>
2019-04-26 16:49:19 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121168901>
2019-04-26 16:49:19 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/7/>
2019-04-26 16:49:19 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121172765>
2019-04-26 16:49:19 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/8/>
2019-04-26 16:49:19 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121179429>
2019-04-26 16:49:20 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/9/>
2019-04-26 16:49:20 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121176368>
2019-04-26 16:49:20 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/10/>
2019-04-26 16:49:20 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121151646>
2019-04-26 16:49:20 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/11/>
2019-04-26 16:49:20 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121220444>
2019-04-26 16:49:20 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/12/>
2019-04-26 16:49:20 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121211058>
2019-04-26 16:49:21 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/13/>
2019-04-26 16:49:21 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121149745>
2019-04-26 16:49:21 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121170509>
2019-04-26 16:49:21 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121207643>
2019-04-26 16:49:21 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121181776>
2019-04-26 16:49:22 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121133753>
2019-04-26 16:49:22 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121218849>
2019-04-26 16:49:22 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121168901>
2019-04-26 16:49:22 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121172765>
2019-04-26 16:49:23 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121179429>
2019-04-26 16:49:23 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121176368>
2019-04-26 16:49:23 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121151646>
2019-04-26 16:49:23 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121220444>
2019-04-26 16:49:24 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121211058>
2019-04-26 16:49:24 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121149745>
2019-04-26 16:49:24 engine.py[line:74] INFO: 爬虫结束: 2019-04-26 16:49:24.507509
2019-04-26 16:49:24 engine.py[line:75] INFO: 爬虫运行时间: 7.172006
2019-04-26 16:49:24 engine.py[line:77] INFO: 总的请求数量: 29个
2019-04-26 16:49:24 engine.py[line:78] INFO: 总的响应数量: 28个
2019-04-26 16:49:24 engine.py[line:79] INFO: 总的重复数量: 1个
2019-04-26 16:50:57 engine.py[line:67] INFO: 爬虫启动: 2019-04-26 16:50:57.829509
2019-04-26 16:50:57 engine.py[line:68] INFO: 当前启动的爬虫: ['spiders.baidu.BaiduSpider', 'spiders.qiubai.QiubaiSpider']
2019-04-26 16:50:57 engine.py[line:69] INFO: 当前开启的管道: ['pipelines.BaiduPipeline', 'pipelines.QiubaiPipeline']
2019-04-26 16:50:57 engine.py[line:70] INFO: 当前开启的下载器中间件: ['spider_middlewares.TestSpiderMiddleware1']
2019-04-26 16:50:57 engine.py[line:71] INFO: 当前开启的爬虫中间件: ['downloader_middlewares.TestDownloaderMiddleware2']
2019-04-26 16:50:57 scheduler.py[line:59] INFO: 添加新的请求: <http://www.douban.com>
2019-04-26 16:50:57 scheduler.py[line:63] INFO: 发现重复的请求：<GET http://www.douban.com>
2019-04-26 16:50:57 scheduler.py[line:59] INFO: 添加新的请求: <http://www.baidu.com>
2019-04-26 16:50:57 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/1/>
2019-04-26 16:50:57 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/2/>
2019-04-26 16:50:57 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/3/>
2019-04-26 16:50:57 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/4/>
2019-04-26 16:50:57 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/5/>
2019-04-26 16:50:57 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/6/>
2019-04-26 16:50:57 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/7/>
2019-04-26 16:50:57 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/8/>
2019-04-26 16:50:57 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/9/>
2019-04-26 16:50:57 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/10/>
2019-04-26 16:50:57 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/11/>
2019-04-26 16:50:57 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/12/>
2019-04-26 16:50:57 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/13/>
2019-04-26 16:50:58 downloader.py[line:26] INFO: <200 https://www.douban.com/>
2019-04-26 16:50:58 downloader.py[line:26] INFO: <200 http://www.baidu.com/>
2019-04-26 16:50:58 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/1/>
2019-04-26 16:50:58 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121154207>
2019-04-26 16:50:58 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/2/>
2019-04-26 16:50:58 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121165020>
2019-04-26 16:50:59 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/3/>
2019-04-26 16:50:59 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121180757>
2019-04-26 16:50:59 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/4/>
2019-04-26 16:50:59 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121203017>
2019-04-26 16:50:59 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/5/>
2019-04-26 16:50:59 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121170631>
2019-04-26 16:50:59 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/6/>
2019-04-26 16:50:59 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121179036>
2019-04-26 16:51:00 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/7/>
2019-04-26 16:51:00 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121176143>
2019-04-26 16:51:00 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/8/>
2019-04-26 16:51:00 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121165756>
2019-04-26 16:51:00 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/9/>
2019-04-26 16:51:00 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121212864>
2019-04-26 16:51:00 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/10/>
2019-04-26 16:51:00 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121161545>
2019-04-26 16:51:01 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/11/>
2019-04-26 16:51:01 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121215962>
2019-04-26 16:51:01 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/12/>
2019-04-26 16:51:01 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121213257>
2019-04-26 16:51:01 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/13/>
2019-04-26 16:51:01 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121168665>
2019-04-26 16:51:01 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121154207>
2019-04-26 16:51:02 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121165020>
2019-04-26 16:51:02 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121180757>
2019-04-26 16:51:02 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121203017>
2019-04-26 16:51:02 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121170631>
2019-04-26 16:51:03 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121179036>
2019-04-26 16:51:03 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121176143>
2019-04-26 16:51:03 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121165756>
2019-04-26 16:51:04 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121212864>
2019-04-26 16:51:04 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121161545>
2019-04-26 16:51:05 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121215962>
2019-04-26 16:51:05 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121213257>
2019-04-26 16:51:05 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121168665>
2019-04-26 16:51:05 engine.py[line:74] INFO: 爬虫结束: 2019-04-26 16:51:05.607526
2019-04-26 16:51:05 engine.py[line:75] INFO: 爬虫运行时间: 7.778017
2019-04-26 16:51:05 engine.py[line:77] INFO: 总的请求数量: 29个
2019-04-26 16:51:05 engine.py[line:78] INFO: 总的响应数量: 28个
2019-04-26 16:51:05 engine.py[line:79] INFO: 总的重复数量: 1个
2019-04-26 16:51:18 engine.py[line:67] INFO: 爬虫启动: 2019-04-26 16:51:18.675508
2019-04-26 16:51:18 engine.py[line:68] INFO: 当前启动的爬虫: ['spiders.baidu.BaiduSpider', 'spiders.qiubai.QiubaiSpider']
2019-04-26 16:51:18 engine.py[line:69] INFO: 当前开启的管道: ['pipelines.BaiduPipeline', 'pipelines.QiubaiPipeline']
2019-04-26 16:51:18 engine.py[line:70] INFO: 当前开启的下载器中间件: ['spider_middlewares.TestSpiderMiddleware1']
2019-04-26 16:51:18 engine.py[line:71] INFO: 当前开启的爬虫中间件: ['downloader_middlewares.TestDownloaderMiddleware2']
2019-04-26 16:51:18 scheduler.py[line:59] INFO: 添加新的请求: <http://www.douban.com>
2019-04-26 16:51:18 scheduler.py[line:63] INFO: 发现重复的请求：<GET http://www.douban.com>
2019-04-26 16:51:18 scheduler.py[line:59] INFO: 添加新的请求: <http://www.baidu.com>
2019-04-26 16:51:18 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/1/>
2019-04-26 16:51:18 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/2/>
2019-04-26 16:51:18 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/3/>
2019-04-26 16:51:18 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/4/>
2019-04-26 16:51:18 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/5/>
2019-04-26 16:51:18 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/6/>
2019-04-26 16:51:18 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/7/>
2019-04-26 16:51:18 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/8/>
2019-04-26 16:51:18 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/9/>
2019-04-26 16:51:18 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/10/>
2019-04-26 16:51:18 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/11/>
2019-04-26 16:51:18 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/12/>
2019-04-26 16:51:18 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/13/>
2019-04-26 16:51:18 downloader.py[line:26] INFO: <200 http://www.baidu.com/>
2019-04-26 16:51:18 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/2/>
2019-04-26 16:51:18 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121165020>
2019-04-26 16:51:18 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/3/>
2019-04-26 16:51:18 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121180757>
2019-04-26 16:51:18 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/1/>
2019-04-26 16:51:18 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121154207>
2019-04-26 16:51:19 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/4/>
2019-04-26 16:51:19 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121203017>
2019-04-26 16:51:19 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/5/>
2019-04-26 16:51:19 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121170631>
2019-04-26 16:51:19 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/6/>
2019-04-26 16:51:19 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/7/>
2019-04-26 16:51:19 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121179036>
2019-04-26 16:51:19 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121176143>
2019-04-26 16:51:19 downloader.py[line:26] INFO: <200 https://www.douban.com/>
2019-04-26 16:51:19 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/8/>
2019-04-26 16:51:19 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121165756>
2019-04-26 16:51:19 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/9/>
2019-04-26 16:51:19 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121212864>
2019-04-26 16:51:19 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/11/>
2019-04-26 16:51:19 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/10/>
2019-04-26 16:51:19 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121215962>
2019-04-26 16:51:19 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121161545>
2019-04-26 16:51:19 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/12/>
2019-04-26 16:51:19 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/13/>
2019-04-26 16:51:19 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121213257>
2019-04-26 16:51:19 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121168665>
2019-04-26 16:51:19 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121165020>
2019-04-26 16:51:19 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121180757>
2019-04-26 16:51:19 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121154207>
2019-04-26 16:51:19 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121170631>
2019-04-26 16:51:19 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121203017>
2019-04-26 16:51:19 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121179036>
2019-04-26 16:51:20 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121176143>
2019-04-26 16:51:20 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121165756>
2019-04-26 16:51:20 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121212864>
2019-04-26 16:51:20 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121215962>
2019-04-26 16:51:20 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121161545>
2019-04-26 16:51:20 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121213257>
2019-04-26 16:51:20 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121168665>
2019-04-26 16:51:20 engine.py[line:74] INFO: 爬虫结束: 2019-04-26 16:51:20.392507
2019-04-26 16:51:20 engine.py[line:75] INFO: 爬虫运行时间: 1.716999
2019-04-26 16:51:20 engine.py[line:77] INFO: 总的请求数量: 29个
2019-04-26 16:51:20 engine.py[line:78] INFO: 总的响应数量: 28个
2019-04-26 16:51:20 engine.py[line:79] INFO: 总的重复数量: 1个
2019-04-26 16:54:39 engine.py[line:67] INFO: 爬虫启动: 2019-04-26 16:54:39.872481
2019-04-26 16:54:39 engine.py[line:68] INFO: 当前启动的爬虫: ['spiders.baidu.BaiduSpider', 'spiders.qiubai.QiubaiSpider']
2019-04-26 16:54:39 engine.py[line:69] INFO: 当前开启的管道: ['pipelines.BaiduPipeline', 'pipelines.QiubaiPipeline']
2019-04-26 16:54:39 engine.py[line:70] INFO: 当前开启的下载器中间件: ['spider_middlewares.TestSpiderMiddleware1']
2019-04-26 16:54:39 engine.py[line:71] INFO: 当前开启的爬虫中间件: ['downloader_middlewares.TestDownloaderMiddleware2']
2019-04-26 16:54:39 scheduler.py[line:59] INFO: 添加新的请求: <http://www.douban.com>
2019-04-26 16:54:39 scheduler.py[line:63] INFO: 发现重复的请求：<GET http://www.douban.com>
2019-04-26 16:54:39 scheduler.py[line:59] INFO: 添加新的请求: <http://www.baidu.com>
2019-04-26 16:54:39 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/1/>
2019-04-26 16:54:39 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/2/>
2019-04-26 16:54:39 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/3/>
2019-04-26 16:54:39 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/4/>
2019-04-26 16:54:39 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/5/>
2019-04-26 16:54:39 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/6/>
2019-04-26 16:54:39 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/7/>
2019-04-26 16:54:39 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/8/>
2019-04-26 16:54:39 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/9/>
2019-04-26 16:54:39 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/10/>
2019-04-26 16:54:39 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/11/>
2019-04-26 16:54:39 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/12/>
2019-04-26 16:54:39 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/13/>
2019-04-26 16:54:39 downloader.py[line:26] INFO: <200 http://www.baidu.com/>
2019-04-26 16:54:40 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/3/>
2019-04-26 16:54:40 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/4/>
2019-04-26 16:54:40 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121180757>
2019-04-26 16:54:40 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/2/>
2019-04-26 16:54:40 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121203017>
2019-04-26 16:54:40 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/1/>
2019-04-26 16:54:40 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121165020>
2019-04-26 16:54:40 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121154207>
2019-04-26 16:54:40 downloader.py[line:26] INFO: <200 https://www.douban.com/>
2019-04-26 16:54:40 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/6/>
2019-04-26 16:54:40 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/8/>
2019-04-26 16:54:40 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121179036>
2019-04-26 16:54:40 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/5/>
2019-04-26 16:54:40 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121165756>
2019-04-26 16:54:40 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121170631>
2019-04-26 16:54:40 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/7/>
2019-04-26 16:54:40 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121176143>
2019-04-26 16:54:40 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/9/>
2019-04-26 16:54:40 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/10/>
2019-04-26 16:54:40 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/11/>
2019-04-26 16:54:40 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/13/>
2019-04-26 16:54:40 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/12/>
2019-04-26 16:54:40 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121212864>
2019-04-26 16:54:40 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121161545>
2019-04-26 16:54:40 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121215962>
2019-04-26 16:54:40 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121168665>
2019-04-26 16:54:40 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121213257>
2019-04-26 16:54:41 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121180757>
2019-04-26 16:54:41 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121203017>
2019-04-26 16:54:41 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121154207>
2019-04-26 16:54:41 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121179036>
2019-04-26 16:54:41 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121165020>
2019-04-26 16:54:41 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121165756>
2019-04-26 16:54:41 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121170631>
2019-04-26 16:54:41 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121176143>
2019-04-26 16:54:41 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121212864>
2019-04-26 16:54:41 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121161545>
2019-04-26 16:54:41 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121215962>
2019-04-26 16:54:41 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121168665>
2019-04-26 16:54:41 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121213257>
2019-04-26 16:54:41 engine.py[line:74] INFO: 爬虫结束: 2019-04-26 16:54:41.790471
2019-04-26 16:54:41 engine.py[line:75] INFO: 爬虫运行时间: 1.91799
2019-04-26 16:54:41 engine.py[line:77] INFO: 总的请求数量: 29个
2019-04-26 16:54:41 engine.py[line:78] INFO: 总的响应数量: 28个
2019-04-26 16:54:41 engine.py[line:79] INFO: 总的重复数量: 1个
2019-04-26 18:10:36 engine.py[line:78] INFO: 爬虫启动: 2019-04-26 18:10:36.486845
2019-04-26 18:10:36 engine.py[line:79] INFO: 当前启动的爬虫: ['spiders.baidu.BaiduSpider', 'spiders.qiubai.QiubaiSpider']
2019-04-26 18:10:36 engine.py[line:80] INFO: 当前开启的管道: ['pipelines.BaiduPipeline', 'pipelines.QiubaiPipeline']
2019-04-26 18:10:36 engine.py[line:81] INFO: 当前开启的下载器中间件: ['spider_middlewares.TestSpiderMiddleware1']
2019-04-26 18:10:36 engine.py[line:82] INFO: 当前开启的爬虫中间件: ['downloader_middlewares.TestDownloaderMiddleware2']
2019-04-26 18:10:36 scheduler.py[line:59] INFO: 添加新的请求: <http://www.douban.com>
2019-04-26 18:10:36 scheduler.py[line:63] INFO: 发现重复的请求：<GET http://www.douban.com>
2019-04-26 18:10:36 scheduler.py[line:59] INFO: 添加新的请求: <http://www.baidu.com>
2019-04-26 18:10:36 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/1/>
2019-04-26 18:10:36 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/2/>
2019-04-26 18:10:36 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/3/>
2019-04-26 18:10:36 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/4/>
2019-04-26 18:10:36 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/5/>
2019-04-26 18:10:36 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/6/>
2019-04-26 18:10:36 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/7/>
2019-04-26 18:10:36 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/8/>
2019-04-26 18:10:36 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/9/>
2019-04-26 18:10:36 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/10/>
2019-04-26 18:10:36 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/11/>
2019-04-26 18:10:36 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/12/>
2019-04-26 18:10:36 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/13/>
2019-04-26 18:10:36 downloader.py[line:26] INFO: <200 http://www.baidu.com/>
2019-04-26 18:10:36 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/3/>
2019-04-26 18:10:36 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121136635>
2019-04-26 18:10:36 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/2/>
2019-04-26 18:10:36 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121150903>
2019-04-26 18:10:36 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/1/>
2019-04-26 18:10:36 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121199089>
2019-04-26 18:10:37 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/4/>
2019-04-26 18:10:37 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121203036>
2019-04-26 18:10:37 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/5/>
2019-04-26 18:10:37 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121226213>
2019-04-26 18:10:37 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/6/>
2019-04-26 18:10:37 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121208019>
2019-04-26 18:10:37 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/7/>
2019-04-26 18:10:37 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121215363>
2019-04-26 18:10:37 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/8/>
2019-04-26 18:10:37 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121127898>
2019-04-26 18:10:37 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/9/>
2019-04-26 18:10:37 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121159951>
2019-04-26 18:10:37 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/10/>
2019-04-26 18:10:37 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121206805>
2019-04-26 18:10:37 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/11/>
2019-04-26 18:10:37 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121213654>
2019-04-26 18:10:37 downloader.py[line:26] INFO: <200 https://www.douban.com/>
2019-04-26 18:10:37 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/12/>
2019-04-26 18:10:37 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121185050>
2019-04-26 18:10:37 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/13/>
2019-04-26 18:10:37 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121197104>
2019-04-26 18:10:37 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121136635>
2019-04-26 18:10:37 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121150903>
2019-04-26 18:10:37 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121199089>
2019-04-26 18:10:37 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121203036>
2019-04-26 18:10:37 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121226213>
2019-04-26 18:10:38 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121208019>
2019-04-26 18:10:38 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121127898>
2019-04-26 18:10:38 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121159951>
2019-04-26 18:10:38 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121215363>
2019-04-26 18:10:38 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121206805>
2019-04-26 18:10:38 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121213654>
2019-04-26 18:10:38 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121185050>
2019-04-26 18:10:38 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121197104>
2019-04-26 18:10:38 engine.py[line:85] INFO: 爬虫结束: 2019-04-26 18:10:38.693846
2019-04-26 18:10:38 engine.py[line:86] INFO: 爬虫运行时间: 2.207001
2019-04-26 18:10:38 engine.py[line:88] INFO: 总的请求数量: 29个
2019-04-26 18:10:38 engine.py[line:89] INFO: 总的响应数量: 28个
2019-04-26 18:10:38 engine.py[line:90] INFO: 总的重复数量: 1个
2019-04-26 18:12:21 engine.py[line:78] INFO: 爬虫启动: 2019-04-26 18:12:21.669838
2019-04-26 18:12:21 engine.py[line:79] INFO: 当前启动的爬虫: ['spiders.baidu.BaiduSpider', 'spiders.qiubai.QiubaiSpider']
2019-04-26 18:12:21 engine.py[line:80] INFO: 当前开启的管道: ['pipelines.BaiduPipeline', 'pipelines.QiubaiPipeline']
2019-04-26 18:12:21 engine.py[line:81] INFO: 当前开启的下载器中间件: ['spider_middlewares.TestSpiderMiddleware1']
2019-04-26 18:12:21 engine.py[line:82] INFO: 当前开启的爬虫中间件: ['downloader_middlewares.TestDownloaderMiddleware2']
2019-04-26 18:12:21 scheduler.py[line:59] INFO: 添加新的请求: <http://www.douban.com>
2019-04-26 18:12:21 scheduler.py[line:63] INFO: 发现重复的请求：<GET http://www.douban.com>
2019-04-26 18:12:21 scheduler.py[line:59] INFO: 添加新的请求: <http://www.baidu.com>
2019-04-26 18:12:21 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/1/>
2019-04-26 18:12:21 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/2/>
2019-04-26 18:12:21 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/3/>
2019-04-26 18:12:21 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/4/>
2019-04-26 18:12:21 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/5/>
2019-04-26 18:12:21 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/6/>
2019-04-26 18:12:21 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/7/>
2019-04-26 18:12:21 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/8/>
2019-04-26 18:12:21 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/9/>
2019-04-26 18:12:21 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/10/>
2019-04-26 18:12:21 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/11/>
2019-04-26 18:12:21 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/12/>
2019-04-26 18:12:21 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/13/>
2019-04-26 18:12:21 downloader.py[line:26] INFO: <200 http://www.baidu.com/>
2019-04-26 18:12:22 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/3/>
2019-04-26 18:12:22 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121136635>
2019-04-26 18:12:22 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/1/>
2019-04-26 18:12:22 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121199089>
2019-04-26 18:12:22 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/2/>
2019-04-26 18:12:22 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121150903>
2019-04-26 18:12:22 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/4/>
2019-04-26 18:12:22 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121203036>
2019-04-26 18:12:22 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/5/>
2019-04-26 18:12:22 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121226213>
2019-04-26 18:12:22 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/6/>
2019-04-26 18:12:22 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121208019>
2019-04-26 18:12:22 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/7/>
2019-04-26 18:12:22 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121215363>
2019-04-26 18:12:22 downloader.py[line:26] INFO: <200 https://www.douban.com/>
2019-04-26 18:12:22 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/8/>
2019-04-26 18:12:22 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121127898>
2019-04-26 18:12:22 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/10/>
2019-04-26 18:12:22 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121206805>
2019-04-26 18:12:22 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/11/>
2019-04-26 18:12:22 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121213654>
2019-04-26 18:12:22 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/9/>
2019-04-26 18:12:22 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121159951>
2019-04-26 18:12:22 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/12/>
2019-04-26 18:12:22 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121185050>
2019-04-26 18:12:22 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/13/>
2019-04-26 18:12:22 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121197104>
2019-04-26 18:12:22 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121136635>
2019-04-26 18:12:22 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121203036>
2019-04-26 18:12:22 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121150903>
2019-04-26 18:12:23 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121199089>
2019-04-26 18:12:23 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121226213>
2019-04-26 18:12:23 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121208019>
2019-04-26 18:12:23 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121127898>
2019-04-26 18:12:23 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121215363>
2019-04-26 18:12:23 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121206805>
2019-04-26 18:12:23 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121213654>
2019-04-26 18:12:23 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121159951>
2019-04-26 18:12:23 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121185050>
2019-04-26 18:12:23 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121197104>
2019-04-26 18:12:23 engine.py[line:85] INFO: 爬虫结束: 2019-04-26 18:12:23.735841
2019-04-26 18:12:23 engine.py[line:86] INFO: 爬虫运行时间: 2.066003
2019-04-26 18:12:23 engine.py[line:88] INFO: 总的请求数量: 29个
2019-04-26 18:12:23 engine.py[line:89] INFO: 总的响应数量: 28个
2019-04-26 18:12:23 engine.py[line:90] INFO: 总的重复数量: 1个
2019-04-26 18:13:16 engine.py[line:78] INFO: 爬虫启动: 2019-04-26 18:13:16.236232
2019-04-26 18:13:16 engine.py[line:79] INFO: 当前启动的爬虫: ['spiders.baidu.BaiduSpider', 'spiders.qiubai.QiubaiSpider']
2019-04-26 18:13:16 engine.py[line:80] INFO: 当前开启的管道: ['pipelines.BaiduPipeline', 'pipelines.QiubaiPipeline']
2019-04-26 18:13:16 engine.py[line:81] INFO: 当前开启的下载器中间件: ['spider_middlewares.TestSpiderMiddleware1']
2019-04-26 18:13:16 engine.py[line:82] INFO: 当前开启的爬虫中间件: ['downloader_middlewares.TestDownloaderMiddleware2']
2019-04-26 18:13:16 scheduler.py[line:59] INFO: 添加新的请求: <http://www.douban.com>
2019-04-26 18:13:16 scheduler.py[line:63] INFO: 发现重复的请求：<GET http://www.douban.com>
2019-04-26 18:13:16 scheduler.py[line:59] INFO: 添加新的请求: <http://www.baidu.com>
2019-04-26 18:13:16 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/1/>
2019-04-26 18:13:16 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/2/>
2019-04-26 18:13:16 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/3/>
2019-04-26 18:13:16 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/4/>
2019-04-26 18:13:16 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/5/>
2019-04-26 18:13:16 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/6/>
2019-04-26 18:13:16 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/7/>
2019-04-26 18:13:16 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/8/>
2019-04-26 18:13:16 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/9/>
2019-04-26 18:13:16 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/10/>
2019-04-26 18:13:16 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/11/>
2019-04-26 18:13:16 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/12/>
2019-04-26 18:13:16 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/13/>
2019-04-26 18:13:16 downloader.py[line:26] INFO: <200 https://www.douban.com/>
2019-04-26 18:13:16 downloader.py[line:26] INFO: <200 http://www.baidu.com/>
2019-04-26 18:13:17 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/1/>
2019-04-26 18:13:17 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121199089>
2019-04-26 18:13:17 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/2/>
2019-04-26 18:13:17 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121150903>
2019-04-26 18:13:17 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/3/>
2019-04-26 18:13:17 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121136635>
2019-04-26 18:13:17 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/4/>
2019-04-26 18:13:17 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121203036>
2019-04-26 18:13:18 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/5/>
2019-04-26 18:13:18 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121226213>
2019-04-26 18:13:18 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/6/>
2019-04-26 18:13:18 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121208019>
2019-04-26 18:13:18 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/7/>
2019-04-26 18:13:18 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121215363>
2019-04-26 18:13:18 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/8/>
2019-04-26 18:13:18 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121127898>
2019-04-26 18:13:19 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/9/>
2019-04-26 18:13:19 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121159951>
2019-04-26 18:13:19 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/10/>
2019-04-26 18:13:19 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121206805>
2019-04-26 18:13:19 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/11/>
2019-04-26 18:13:19 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121213654>
2019-04-26 18:13:19 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/12/>
2019-04-26 18:13:19 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121185050>
2019-04-26 18:13:19 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/13/>
2019-04-26 18:13:19 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121197104>
2019-04-26 18:13:20 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121199089>
2019-04-26 18:13:20 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121150903>
2019-04-26 18:13:20 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121136635>
2019-04-26 18:13:21 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121203036>
2019-04-26 18:13:21 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121226213>
2019-04-26 18:13:21 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121208019>
2019-04-26 18:13:21 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121215363>
2019-04-26 18:13:22 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121127898>
2019-04-26 18:13:22 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121159951>
2019-04-26 18:13:22 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121206805>
2019-04-26 18:13:22 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121213654>
2019-04-26 18:13:23 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121185050>
2019-04-26 18:13:23 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121197104>
2019-04-26 18:13:23 engine.py[line:85] INFO: 爬虫结束: 2019-04-26 18:13:23.432243
2019-04-26 18:13:23 engine.py[line:86] INFO: 爬虫运行时间: 7.196011
2019-04-26 18:13:23 engine.py[line:88] INFO: 总的请求数量: 29个
2019-04-26 18:13:23 engine.py[line:89] INFO: 总的响应数量: 28个
2019-04-26 18:13:23 engine.py[line:90] INFO: 总的重复数量: 1个
2019-04-26 18:13:33 engine.py[line:78] INFO: 爬虫启动: 2019-04-26 18:13:33.782231
2019-04-26 18:13:33 engine.py[line:79] INFO: 当前启动的爬虫: ['spiders.baidu.BaiduSpider', 'spiders.qiubai.QiubaiSpider']
2019-04-26 18:13:33 engine.py[line:80] INFO: 当前开启的管道: ['pipelines.BaiduPipeline', 'pipelines.QiubaiPipeline']
2019-04-26 18:13:33 engine.py[line:81] INFO: 当前开启的下载器中间件: ['spider_middlewares.TestSpiderMiddleware1']
2019-04-26 18:13:33 engine.py[line:82] INFO: 当前开启的爬虫中间件: ['downloader_middlewares.TestDownloaderMiddleware2']
2019-04-26 18:13:33 scheduler.py[line:59] INFO: 添加新的请求: <http://www.douban.com>
2019-04-26 18:13:33 scheduler.py[line:63] INFO: 发现重复的请求：<GET http://www.douban.com>
2019-04-26 18:13:33 scheduler.py[line:59] INFO: 添加新的请求: <http://www.baidu.com>
2019-04-26 18:13:33 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/1/>
2019-04-26 18:13:33 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/2/>
2019-04-26 18:13:33 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/3/>
2019-04-26 18:13:33 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/4/>
2019-04-26 18:13:33 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/5/>
2019-04-26 18:13:33 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/6/>
2019-04-26 18:13:33 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/7/>
2019-04-26 18:13:33 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/8/>
2019-04-26 18:13:33 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/9/>
2019-04-26 18:13:33 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/10/>
2019-04-26 18:13:33 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/11/>
2019-04-26 18:13:33 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/12/>
2019-04-26 18:13:33 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/13/>
2019-04-26 18:13:34 downloader.py[line:26] INFO: <200 http://www.baidu.com/>
2019-04-26 18:13:34 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/3/>
2019-04-26 18:13:34 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121136635>
2019-04-26 18:13:34 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/1/>
2019-04-26 18:13:34 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121199089>
2019-04-26 18:13:34 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/2/>
2019-04-26 18:13:34 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121150903>
2019-04-26 18:13:34 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/4/>
2019-04-26 18:13:34 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121203036>
2019-04-26 18:13:34 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/5/>
2019-04-26 18:13:34 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121226213>
2019-04-26 18:13:34 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/6/>
2019-04-26 18:13:34 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121208019>
2019-04-26 18:13:34 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/7/>
2019-04-26 18:13:34 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121215363>
2019-04-26 18:13:34 downloader.py[line:26] INFO: <200 https://www.douban.com/>
2019-04-26 18:13:34 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/8/>
2019-04-26 18:13:34 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121127898>
2019-04-26 18:13:34 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/11/>
2019-04-26 18:13:34 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121213654>
2019-04-26 18:13:34 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/9/>
2019-04-26 18:13:34 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121159951>
2019-04-26 18:13:35 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/12/>
2019-04-26 18:13:35 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121185050>
2019-04-26 18:13:35 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/10/>
2019-04-26 18:13:35 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121206805>
2019-04-26 18:13:35 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/13/>
2019-04-26 18:13:35 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121197104>
2019-04-26 18:13:35 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121199089>
2019-04-26 18:13:35 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121136635>
2019-04-26 18:13:35 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121150903>
2019-04-26 18:13:35 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121203036>
2019-04-26 18:13:35 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121226213>
2019-04-26 18:13:35 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121215363>
2019-04-26 18:13:35 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121127898>
2019-04-26 18:13:35 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121213654>
2019-04-26 18:13:35 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121159951>
2019-04-26 18:13:35 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121185050>
2019-04-26 18:13:35 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121208019>
2019-04-26 18:13:35 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121206805>
2019-04-26 18:13:36 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121197104>
2019-04-26 18:13:36 engine.py[line:85] INFO: 爬虫结束: 2019-04-26 18:13:36.069232
2019-04-26 18:13:36 engine.py[line:86] INFO: 爬虫运行时间: 2.287001
2019-04-26 18:13:36 engine.py[line:88] INFO: 总的请求数量: 29个
2019-04-26 18:13:36 engine.py[line:89] INFO: 总的响应数量: 28个
2019-04-26 18:13:36 engine.py[line:90] INFO: 总的重复数量: 1个
2019-04-26 18:13:58 engine.py[line:78] INFO: 爬虫启动: 2019-04-26 18:13:58.156240
2019-04-26 18:13:58 engine.py[line:79] INFO: 当前启动的爬虫: ['spiders.baidu.BaiduSpider', 'spiders.qiubai.QiubaiSpider']
2019-04-26 18:13:58 engine.py[line:80] INFO: 当前开启的管道: ['pipelines.BaiduPipeline', 'pipelines.QiubaiPipeline']
2019-04-26 18:13:58 engine.py[line:81] INFO: 当前开启的下载器中间件: ['spider_middlewares.TestSpiderMiddleware1']
2019-04-26 18:13:58 engine.py[line:82] INFO: 当前开启的爬虫中间件: ['downloader_middlewares.TestDownloaderMiddleware2']
2019-04-26 18:13:58 scheduler.py[line:59] INFO: 添加新的请求: <http://www.douban.com>
2019-04-26 18:13:58 scheduler.py[line:63] INFO: 发现重复的请求：<GET http://www.douban.com>
2019-04-26 18:13:58 scheduler.py[line:59] INFO: 添加新的请求: <http://www.baidu.com>
2019-04-26 18:13:58 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/1/>
2019-04-26 18:13:58 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/2/>
2019-04-26 18:13:58 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/3/>
2019-04-26 18:13:58 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/4/>
2019-04-26 18:13:58 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/5/>
2019-04-26 18:13:58 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/6/>
2019-04-26 18:13:58 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/7/>
2019-04-26 18:13:58 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/8/>
2019-04-26 18:13:58 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/9/>
2019-04-26 18:13:58 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/10/>
2019-04-26 18:13:58 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/11/>
2019-04-26 18:13:58 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/12/>
2019-04-26 18:13:58 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/13/>
2019-04-26 18:13:58 downloader.py[line:26] INFO: <200 http://www.baidu.com/>
2019-04-26 18:13:58 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/3/>
2019-04-26 18:13:58 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/2/>
2019-04-26 18:13:58 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121136635>
2019-04-26 18:13:58 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/1/>
2019-04-26 18:13:58 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121150903>
2019-04-26 18:13:58 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121199089>
2019-04-26 18:13:58 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/4/>
2019-04-26 18:13:58 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121203036>
2019-04-26 18:13:58 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/5/>
2019-04-26 18:13:58 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/6/>
2019-04-26 18:13:58 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/7/>
2019-04-26 18:13:58 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121226213>
2019-04-26 18:13:58 downloader.py[line:26] INFO: <200 https://www.douban.com/>
2019-04-26 18:13:58 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121208019>
2019-04-26 18:13:58 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121215363>
2019-04-26 18:13:58 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/8/>
2019-04-26 18:13:58 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121127898>
2019-04-26 18:13:58 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/9/>
2019-04-26 18:13:58 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121159951>
2019-04-26 18:13:58 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/12/>
2019-04-26 18:13:58 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/10/>
2019-04-26 18:13:59 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121185050>
2019-04-26 18:13:59 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/11/>
2019-04-26 18:13:59 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121206805>
2019-04-26 18:13:59 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/13/>
2019-04-26 18:13:59 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121213654>
2019-04-26 18:13:59 scheduler.py[line:59] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121197104>
2019-04-26 18:13:59 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121150903>
2019-04-26 18:13:59 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121136635>
2019-04-26 18:13:59 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121199089>
2019-04-26 18:13:59 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121226213>
2019-04-26 18:13:59 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121203036>
2019-04-26 18:13:59 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121208019>
2019-04-26 18:13:59 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121215363>
2019-04-26 18:13:59 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121127898>
2019-04-26 18:13:59 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121159951>
2019-04-26 18:13:59 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121185050>
2019-04-26 18:13:59 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121206805>
2019-04-26 18:13:59 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121213654>
2019-04-26 18:13:59 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121197104>
2019-04-26 18:13:59 engine.py[line:85] INFO: 爬虫结束: 2019-04-26 18:13:59.872235
2019-04-26 18:13:59 engine.py[line:86] INFO: 爬虫运行时间: 1.715995
2019-04-26 18:13:59 engine.py[line:88] INFO: 总的请求数量: 29个
2019-04-26 18:13:59 engine.py[line:89] INFO: 总的响应数量: 28个
2019-04-26 18:13:59 engine.py[line:90] INFO: 总的重复数量: 1个
2019-04-28 09:05:11 engine.py[line:81] INFO: 爬虫启动: 2019-04-28 09:05:11.975807
2019-04-28 09:05:12 engine.py[line:82] INFO: 当前启动的爬虫: ['spiders.baidu.BaiduSpider', 'spiders.qiubai.QiubaiSpider']
2019-04-28 09:05:12 engine.py[line:83] INFO: 当前开启的管道: ['pipelines.BaiduPipeline', 'pipelines.QiubaiPipeline']
2019-04-28 09:05:12 engine.py[line:84] INFO: 当前开启的下载器中间件: ['spider_middlewares.TestSpiderMiddleware1']
2019-04-28 09:05:12 engine.py[line:85] INFO: 当前开启的爬虫中间件: ['downloader_middlewares.TestDownloaderMiddleware2']
2019-04-28 09:05:13 scheduler.py[line:71] INFO: 添加新的请求: <http://www.douban.com>
2019-04-28 09:05:14 scheduler.py[line:75] INFO: 发现重复的请求：<GET http://www.douban.com>
2019-04-28 09:05:14 scheduler.py[line:71] INFO: 添加新的请求: <http://www.baidu.com>
2019-04-28 09:05:14 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/1/>
2019-04-28 09:05:14 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/2/>
2019-04-28 09:05:14 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/3/>
2019-04-28 09:05:14 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/4/>
2019-04-28 09:05:14 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/5/>
2019-04-28 09:05:14 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/6/>
2019-04-28 09:05:14 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/7/>
2019-04-28 09:05:14 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/8/>
2019-04-28 09:05:14 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/9/>
2019-04-28 09:05:14 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/10/>
2019-04-28 09:05:14 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/11/>
2019-04-28 09:05:14 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/12/>
2019-04-28 09:05:14 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/13/>
2019-04-28 09:05:14 downloader.py[line:26] INFO: <200 http://www.baidu.com/>
2019-04-28 09:05:14 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/1/>
2019-04-28 09:05:14 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/2/>
2019-04-28 09:05:14 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121188557>
2019-04-28 09:05:14 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/3/>
2019-04-28 09:05:14 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121194008>
2019-04-28 09:05:14 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121189163>
2019-04-28 09:05:14 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/4/>
2019-04-28 09:05:14 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121148333>
2019-04-28 09:05:14 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/5/>
2019-04-28 09:05:14 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121218657>
2019-04-28 09:05:14 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/7/>
2019-04-28 09:05:14 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/6/>
2019-04-28 09:05:14 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121159412>
2019-04-28 09:05:14 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121194125>
2019-04-28 09:05:14 downloader.py[line:26] INFO: <200 https://www.douban.com/>
2019-04-28 09:05:14 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/8/>
2019-04-28 09:05:14 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121149246>
2019-04-28 09:05:14 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/9/>
2019-04-28 09:05:14 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/10/>
2019-04-28 09:05:14 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121163574>
2019-04-28 09:05:14 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/11/>
2019-04-28 09:05:14 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121202973>
2019-04-28 09:05:14 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121170733>
2019-04-28 09:05:14 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/12/>
2019-04-28 09:05:14 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/13/>
2019-04-28 09:05:14 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121173183>
2019-04-28 09:05:14 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121179298>
2019-04-28 09:05:15 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121188557>
2019-04-28 09:05:15 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121194008>
2019-04-28 09:05:15 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121148333>
2019-04-28 09:05:15 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121189163>
2019-04-28 09:05:15 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121218657>
2019-04-28 09:05:15 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121159412>
2019-04-28 09:05:15 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121194125>
2019-04-28 09:05:15 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121149246>
2019-04-28 09:05:15 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121163574>
2019-04-28 09:05:15 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121202973>
2019-04-28 09:05:15 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121173183>
2019-04-28 09:05:15 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121170733>
2019-04-28 09:05:15 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121179298>
2019-04-28 09:05:15 engine.py[line:88] INFO: 爬虫结束: 2019-04-28 09:05:15.917813
2019-04-28 09:05:15 engine.py[line:89] INFO: 爬虫运行时间: 3.942006
2019-04-28 09:05:15 engine.py[line:92] INFO: 总的请求数量: _request_num个
2019-04-28 09:05:15 engine.py[line:94] INFO: 总的响应数量: _response_num个
2019-04-28 09:05:15 engine.py[line:96] INFO: 总的重复数量: _duplicate_request_num个
2019-04-28 09:07:04 engine.py[line:81] INFO: 爬虫启动: 2019-04-28 09:07:04.429813
2019-04-28 09:07:04 engine.py[line:82] INFO: 当前启动的爬虫: ['spiders.baidu.BaiduSpider', 'spiders.qiubai.QiubaiSpider']
2019-04-28 09:07:04 engine.py[line:83] INFO: 当前开启的管道: ['pipelines.BaiduPipeline', 'pipelines.QiubaiPipeline']
2019-04-28 09:07:04 engine.py[line:84] INFO: 当前开启的下载器中间件: ['spider_middlewares.TestSpiderMiddleware1']
2019-04-28 09:07:04 engine.py[line:85] INFO: 当前开启的爬虫中间件: ['downloader_middlewares.TestDownloaderMiddleware2']
2019-04-28 09:07:05 scheduler.py[line:75] INFO: 发现重复的请求：<GET http://www.douban.com>
2019-04-28 09:07:06 scheduler.py[line:75] INFO: 发现重复的请求：<GET http://www.douban.com>
2019-04-28 09:07:06 scheduler.py[line:75] INFO: 发现重复的请求：<GET http://www.baidu.com>
2019-04-28 09:07:06 scheduler.py[line:75] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/1/>
2019-04-28 09:07:06 scheduler.py[line:75] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/2/>
2019-04-28 09:07:06 scheduler.py[line:75] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/3/>
2019-04-28 09:07:06 scheduler.py[line:75] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/4/>
2019-04-28 09:07:06 scheduler.py[line:75] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/5/>
2019-04-28 09:07:06 scheduler.py[line:75] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/6/>
2019-04-28 09:07:06 scheduler.py[line:75] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/7/>
2019-04-28 09:07:06 scheduler.py[line:75] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/8/>
2019-04-28 09:07:06 scheduler.py[line:75] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/9/>
2019-04-28 09:07:06 scheduler.py[line:75] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/10/>
2019-04-28 09:07:06 scheduler.py[line:75] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/11/>
2019-04-28 09:07:06 scheduler.py[line:75] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/12/>
2019-04-28 09:07:06 scheduler.py[line:75] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/13/>
2019-04-28 09:07:06 engine.py[line:88] INFO: 爬虫结束: 2019-04-28 09:07:06.550819
2019-04-28 09:07:06 engine.py[line:89] INFO: 爬虫运行时间: 2.121006
2019-04-28 09:07:06 engine.py[line:92] INFO: 总的请求数量: 45个
2019-04-28 09:07:06 engine.py[line:94] INFO: 总的响应数量: 28个
2019-04-28 09:07:06 engine.py[line:96] INFO: 总的重复数量: 17个
2019-04-28 09:07:18 engine.py[line:81] INFO: 爬虫启动: 2019-04-28 09:07:18.071814
2019-04-28 09:07:18 engine.py[line:82] INFO: 当前启动的爬虫: ['spiders.baidu.BaiduSpider', 'spiders.qiubai.QiubaiSpider']
2019-04-28 09:07:18 engine.py[line:83] INFO: 当前开启的管道: ['pipelines.BaiduPipeline', 'pipelines.QiubaiPipeline']
2019-04-28 09:07:18 engine.py[line:84] INFO: 当前开启的下载器中间件: ['spider_middlewares.TestSpiderMiddleware1']
2019-04-28 09:07:18 engine.py[line:85] INFO: 当前开启的爬虫中间件: ['downloader_middlewares.TestDownloaderMiddleware2']
2019-04-28 09:07:19 scheduler.py[line:75] INFO: 发现重复的请求：<GET http://www.douban.com>
2019-04-28 09:07:20 scheduler.py[line:75] INFO: 发现重复的请求：<GET http://www.douban.com>
2019-04-28 09:07:20 scheduler.py[line:75] INFO: 发现重复的请求：<GET http://www.baidu.com>
2019-04-28 09:07:20 scheduler.py[line:75] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/1/>
2019-04-28 09:07:20 scheduler.py[line:75] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/2/>
2019-04-28 09:07:20 scheduler.py[line:75] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/3/>
2019-04-28 09:07:20 scheduler.py[line:75] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/4/>
2019-04-28 09:07:20 scheduler.py[line:75] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/5/>
2019-04-28 09:07:20 scheduler.py[line:75] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/6/>
2019-04-28 09:07:20 scheduler.py[line:75] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/7/>
2019-04-28 09:07:20 scheduler.py[line:75] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/8/>
2019-04-28 09:07:20 scheduler.py[line:75] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/9/>
2019-04-28 09:07:20 scheduler.py[line:75] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/10/>
2019-04-28 09:07:20 scheduler.py[line:75] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/11/>
2019-04-28 09:07:20 scheduler.py[line:75] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/12/>
2019-04-28 09:07:20 scheduler.py[line:75] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/13/>
2019-04-28 09:07:20 engine.py[line:88] INFO: 爬虫结束: 2019-04-28 09:07:20.191803
2019-04-28 09:07:20 engine.py[line:89] INFO: 爬虫运行时间: 2.119989
2019-04-28 09:07:20 engine.py[line:92] INFO: 总的请求数量: 61个
2019-04-28 09:07:20 engine.py[line:94] INFO: 总的响应数量: 28个
2019-04-28 09:07:20 engine.py[line:96] INFO: 总的重复数量: 33个
2019-04-28 09:12:09 engine.py[line:82] INFO: 爬虫启动: 2019-04-28 09:12:09.264067
2019-04-28 09:12:09 engine.py[line:83] INFO: 当前启动的爬虫: ['spiders.baidu.BaiduSpider', 'spiders.qiubai.QiubaiSpider']
2019-04-28 09:12:09 engine.py[line:84] INFO: 当前开启的管道: ['pipelines.BaiduPipeline', 'pipelines.QiubaiPipeline']
2019-04-28 09:12:09 engine.py[line:85] INFO: 当前开启的下载器中间件: ['spider_middlewares.TestSpiderMiddleware1']
2019-04-28 09:12:09 engine.py[line:86] INFO: 当前开启的爬虫中间件: ['downloader_middlewares.TestDownloaderMiddleware2']
2019-04-28 09:12:10 scheduler.py[line:71] INFO: 添加新的请求: <http://www.douban.com>
2019-04-28 09:12:11 scheduler.py[line:75] INFO: 发现重复的请求：<GET http://www.douban.com>
2019-04-28 09:12:11 downloader.py[line:26] INFO: <200 https://www.douban.com/>
2019-04-28 09:12:12 scheduler.py[line:71] INFO: 添加新的请求: <http://www.baidu.com>
2019-04-28 09:12:12 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/1/>
2019-04-28 09:12:12 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/2/>
2019-04-28 09:12:12 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/3/>
2019-04-28 09:12:12 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/4/>
2019-04-28 09:12:12 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/5/>
2019-04-28 09:12:12 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/6/>
2019-04-28 09:12:12 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/7/>
2019-04-28 09:12:12 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/8/>
2019-04-28 09:12:12 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/9/>
2019-04-28 09:12:12 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/10/>
2019-04-28 09:12:12 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/11/>
2019-04-28 09:12:12 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/12/>
2019-04-28 09:12:12 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/13/>
2019-04-28 09:12:12 downloader.py[line:26] INFO: <200 http://www.baidu.com/>
2019-04-28 09:12:12 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/3/>
2019-04-28 09:12:12 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/1/>
2019-04-28 09:12:12 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121123593>
2019-04-28 09:12:12 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/2/>
2019-04-28 09:12:12 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121189565>
2019-04-28 09:12:12 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121213114>
2019-04-28 09:12:12 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/4/>
2019-04-28 09:12:12 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121203048>
2019-04-28 09:12:12 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/6/>
2019-04-28 09:12:12 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/5/>
2019-04-28 09:12:12 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/7/>
2019-04-28 09:12:12 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121205245>
2019-04-28 09:12:12 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121189062>
2019-04-28 09:12:12 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/8/>
2019-04-28 09:12:12 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121154203>
2019-04-28 09:12:12 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121179630>
2019-04-28 09:12:13 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/9/>
2019-04-28 09:12:13 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121197932>
2019-04-28 09:12:13 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/10/>
2019-04-28 09:12:13 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/12/>
2019-04-28 09:12:13 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121189236>
2019-04-28 09:12:13 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121218452>
2019-04-28 09:12:13 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/11/>
2019-04-28 09:12:13 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121194453>
2019-04-28 09:12:13 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/13/>
2019-04-28 09:12:13 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121209182>
2019-04-28 09:12:13 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121123593>
2019-04-28 09:12:13 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121213114>
2019-04-28 09:12:13 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121189565>
2019-04-28 09:12:13 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121203048>
2019-04-28 09:12:13 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121205245>
2019-04-28 09:12:13 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121189062>
2019-04-28 09:12:13 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121154203>
2019-04-28 09:12:13 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121179630>
2019-04-28 09:12:13 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121189236>
2019-04-28 09:12:13 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121197932>
2019-04-28 09:12:13 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121218452>
2019-04-28 09:12:13 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121194453>
2019-04-28 09:12:14 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121209182>
2019-04-28 09:12:14 engine.py[line:89] INFO: 爬虫结束: 2019-04-28 09:12:14.112064
2019-04-28 09:12:14 engine.py[line:90] INFO: 爬虫运行时间: 4.847997
2019-04-28 09:12:14 engine.py[line:93] INFO: 总的请求数量: 29个
2019-04-28 09:12:14 engine.py[line:95] INFO: 总的响应数量: 28个
2019-04-28 09:12:14 engine.py[line:97] INFO: 总的重复数量: 1个
2019-04-28 09:14:01 engine.py[line:82] INFO: 爬虫启动: 2019-04-28 09:14:01.748460
2019-04-28 09:14:01 engine.py[line:83] INFO: 当前启动的爬虫: ['spiders.baidu.BaiduSpider', 'spiders.qiubai.QiubaiSpider']
2019-04-28 09:14:01 engine.py[line:84] INFO: 当前开启的管道: ['pipelines.BaiduPipeline', 'pipelines.QiubaiPipeline']
2019-04-28 09:14:01 engine.py[line:85] INFO: 当前开启的下载器中间件: ['spider_middlewares.TestSpiderMiddleware1']
2019-04-28 09:14:01 engine.py[line:86] INFO: 当前开启的爬虫中间件: ['downloader_middlewares.TestDownloaderMiddleware2']
2019-04-28 09:14:02 scheduler.py[line:75] INFO: 发现重复的请求：<GET http://www.douban.com>
2019-04-28 09:14:03 scheduler.py[line:75] INFO: 发现重复的请求：<GET http://www.douban.com>
2019-04-28 09:14:03 scheduler.py[line:75] INFO: 发现重复的请求：<GET http://www.baidu.com>
2019-04-28 09:14:03 scheduler.py[line:75] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/1/>
2019-04-28 09:14:03 scheduler.py[line:75] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/2/>
2019-04-28 09:14:03 scheduler.py[line:75] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/3/>
2019-04-28 09:14:03 scheduler.py[line:75] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/4/>
2019-04-28 09:14:03 scheduler.py[line:75] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/5/>
2019-04-28 09:14:03 scheduler.py[line:75] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/6/>
2019-04-28 09:14:03 scheduler.py[line:75] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/7/>
2019-04-28 09:14:03 scheduler.py[line:75] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/8/>
2019-04-28 09:14:03 scheduler.py[line:75] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/9/>
2019-04-28 09:14:03 scheduler.py[line:75] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/10/>
2019-04-28 09:14:03 scheduler.py[line:75] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/11/>
2019-04-28 09:14:03 scheduler.py[line:75] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/12/>
2019-04-28 09:14:03 scheduler.py[line:75] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/13/>
2019-04-28 09:14:03 engine.py[line:89] INFO: 爬虫结束: 2019-04-28 09:14:03.870474
2019-04-28 09:14:03 engine.py[line:90] INFO: 爬虫运行时间: 2.122014
2019-04-28 09:14:03 engine.py[line:93] INFO: 总的请求数量: 16个
2019-04-28 09:14:03 engine.py[line:95] INFO: 总的响应数量: 0个
2019-04-28 09:14:03 engine.py[line:97] INFO: 总的重复数量: 16个
2019-04-28 09:15:00 engine.py[line:82] INFO: 爬虫启动: 2019-04-28 09:15:00.202760
2019-04-28 09:15:00 engine.py[line:83] INFO: 当前启动的爬虫: ['spiders.baidu.BaiduSpider', 'spiders.qiubai.QiubaiSpider']
2019-04-28 09:15:00 engine.py[line:84] INFO: 当前开启的管道: ['pipelines.BaiduPipeline', 'pipelines.QiubaiPipeline']
2019-04-28 09:15:00 engine.py[line:85] INFO: 当前开启的下载器中间件: ['spider_middlewares.TestSpiderMiddleware1']
2019-04-28 09:15:00 engine.py[line:86] INFO: 当前开启的爬虫中间件: ['downloader_middlewares.TestDownloaderMiddleware2']
2019-04-28 09:15:01 scheduler.py[line:71] INFO: 添加新的请求: <http://www.douban.com>
2019-04-28 09:15:01 scheduler.py[line:75] INFO: 发现重复的请求：<GET http://www.douban.com>
2019-04-28 09:15:01 scheduler.py[line:71] INFO: 添加新的请求: <http://www.baidu.com>
2019-04-28 09:15:01 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/1/>
2019-04-28 09:15:01 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/2/>
2019-04-28 09:15:01 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/3/>
2019-04-28 09:15:01 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/4/>
2019-04-28 09:15:01 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/5/>
2019-04-28 09:15:01 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/6/>
2019-04-28 09:15:01 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/7/>
2019-04-28 09:15:01 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/8/>
2019-04-28 09:15:01 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/9/>
2019-04-28 09:15:01 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/10/>
2019-04-28 09:15:01 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/11/>
2019-04-28 09:15:01 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/12/>
2019-04-28 09:15:01 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/13/>
2019-04-28 09:15:01 downloader.py[line:26] INFO: <200 http://www.baidu.com/>
2019-04-28 09:15:01 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/2/>
2019-04-28 09:15:01 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121213114>
2019-04-28 09:15:01 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/3/>
2019-04-28 09:15:01 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/1/>
2019-04-28 09:15:01 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121123593>
2019-04-28 09:15:01 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121189565>
2019-04-28 09:15:01 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/4/>
2019-04-28 09:15:01 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121203048>
2019-04-28 09:15:01 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/5/>
2019-04-28 09:15:01 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121189062>
2019-04-28 09:15:01 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/6/>
2019-04-28 09:15:01 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/7/>
2019-04-28 09:15:01 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121205245>
2019-04-28 09:15:01 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121154203>
2019-04-28 09:15:01 downloader.py[line:26] INFO: <200 https://www.douban.com/>
2019-04-28 09:15:01 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/8/>
2019-04-28 09:15:01 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121179630>
2019-04-28 09:15:02 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/9/>
2019-04-28 09:15:02 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121197932>
2019-04-28 09:15:02 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/10/>
2019-04-28 09:15:02 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121189236>
2019-04-28 09:15:02 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/11/>
2019-04-28 09:15:02 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/12/>
2019-04-28 09:15:02 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121194453>
2019-04-28 09:15:02 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121218452>
2019-04-28 09:15:02 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/13/>
2019-04-28 09:15:02 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121209182>
2019-04-28 09:15:02 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121213114>
2019-04-28 09:15:02 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121123593>
2019-04-28 09:15:02 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121189565>
2019-04-28 09:15:02 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121203048>
2019-04-28 09:15:02 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121189062>
2019-04-28 09:15:02 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121205245>
2019-04-28 09:15:02 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121154203>
2019-04-28 09:15:02 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121179630>
2019-04-28 09:15:02 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121197932>
2019-04-28 09:15:02 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121189236>
2019-04-28 09:15:02 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121194453>
2019-04-28 09:15:02 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121218452>
2019-04-28 09:15:02 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121209182>
2019-04-28 09:15:03 engine.py[line:89] INFO: 爬虫结束: 2019-04-28 09:15:03.033759
2019-04-28 09:15:03 engine.py[line:90] INFO: 爬虫运行时间: 2.830999
2019-04-28 09:15:03 engine.py[line:93] INFO: 总的请求数量: 29个
2019-04-28 09:15:03 engine.py[line:95] INFO: 总的响应数量: 28个
2019-04-28 09:15:03 engine.py[line:97] INFO: 总的重复数量: 1个
2019-04-28 09:17:27 engine.py[line:82] INFO: 爬虫启动: 2019-04-28 09:17:27.157775
2019-04-28 09:17:27 engine.py[line:83] INFO: 当前启动的爬虫: ['spiders.baidu.BaiduSpider', 'spiders.qiubai.QiubaiSpider']
2019-04-28 09:17:27 engine.py[line:84] INFO: 当前开启的管道: ['pipelines.BaiduPipeline', 'pipelines.QiubaiPipeline']
2019-04-28 09:17:27 engine.py[line:85] INFO: 当前开启的下载器中间件: ['spider_middlewares.TestSpiderMiddleware1']
2019-04-28 09:17:27 engine.py[line:86] INFO: 当前开启的爬虫中间件: ['downloader_middlewares.TestDownloaderMiddleware2']
2019-04-28 09:17:28 scheduler.py[line:75] INFO: 发现重复的请求：<GET http://www.douban.com>
2019-04-28 09:17:28 scheduler.py[line:75] INFO: 发现重复的请求：<GET http://www.douban.com>
2019-04-28 09:17:28 scheduler.py[line:75] INFO: 发现重复的请求：<GET http://www.baidu.com>
2019-04-28 09:17:28 scheduler.py[line:75] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/1/>
2019-04-28 09:17:28 scheduler.py[line:75] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/2/>
2019-04-28 09:17:28 scheduler.py[line:75] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/3/>
2019-04-28 09:17:28 scheduler.py[line:75] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/4/>
2019-04-28 09:17:28 scheduler.py[line:75] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/5/>
2019-04-28 09:17:28 scheduler.py[line:75] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/6/>
2019-04-28 09:17:28 scheduler.py[line:75] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/7/>
2019-04-28 09:17:28 scheduler.py[line:75] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/8/>
2019-04-28 09:17:28 scheduler.py[line:75] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/9/>
2019-04-28 09:17:28 scheduler.py[line:75] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/10/>
2019-04-28 09:17:28 scheduler.py[line:75] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/11/>
2019-04-28 09:17:28 scheduler.py[line:75] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/12/>
2019-04-28 09:17:28 scheduler.py[line:75] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/13/>
2019-04-28 09:17:28 engine.py[line:89] INFO: 爬虫结束: 2019-04-28 09:17:28.268767
2019-04-28 09:17:28 engine.py[line:90] INFO: 爬虫运行时间: 1.110992
2019-04-28 09:17:28 engine.py[line:93] INFO: 总的请求数量: 45个
2019-04-28 09:17:28 engine.py[line:95] INFO: 总的响应数量: 28个
2019-04-28 09:17:28 engine.py[line:97] INFO: 总的重复数量: 17个
2019-04-28 09:22:58 engine.py[line:82] INFO: 爬虫启动: 2019-04-28 09:22:58.362744
2019-04-28 09:22:58 engine.py[line:83] INFO: 当前启动的爬虫: ['spiders.baidu.BaiduSpider', 'spiders.qiubai.QiubaiSpider']
2019-04-28 09:22:58 engine.py[line:84] INFO: 当前开启的管道: ['pipelines.BaiduPipeline', 'pipelines.QiubaiPipeline']
2019-04-28 09:22:58 engine.py[line:85] INFO: 当前开启的下载器中间件: ['spider_middlewares.TestSpiderMiddleware1']
2019-04-28 09:22:58 engine.py[line:86] INFO: 当前开启的爬虫中间件: ['downloader_middlewares.TestDownloaderMiddleware2']
2019-04-28 09:22:59 scheduler.py[line:71] INFO: 添加新的请求: <http://www.douban.com>
2019-04-28 09:23:00 scheduler.py[line:75] INFO: 发现重复的请求：<GET http://www.douban.com>
2019-04-28 09:23:00 scheduler.py[line:71] INFO: 添加新的请求: <http://www.baidu.com>
2019-04-28 09:23:00 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/1/>
2019-04-28 09:23:00 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/2/>
2019-04-28 09:23:00 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/3/>
2019-04-28 09:23:00 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/4/>
2019-04-28 09:23:00 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/5/>
2019-04-28 09:23:00 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/6/>
2019-04-28 09:23:00 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/7/>
2019-04-28 09:23:00 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/8/>
2019-04-28 09:23:00 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/9/>
2019-04-28 09:23:00 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/10/>
2019-04-28 09:23:00 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/11/>
2019-04-28 09:23:00 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/12/>
2019-04-28 09:23:00 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/13/>
2019-04-28 09:23:00 downloader.py[line:26] INFO: <200 http://www.baidu.com/>
2019-04-28 09:23:00 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/3/>
2019-04-28 09:23:00 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121185254>
2019-04-28 09:23:00 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/1/>
2019-04-28 09:23:00 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/2/>
2019-04-28 09:23:00 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121123045>
2019-04-28 09:23:00 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121215834>
2019-04-28 09:23:00 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/4/>
2019-04-28 09:23:00 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121226280>
2019-04-28 09:23:00 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/5/>
2019-04-28 09:23:00 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/7/>
2019-04-28 09:23:00 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121172570>
2019-04-28 09:23:00 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121226419>
2019-04-28 09:23:00 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/6/>
2019-04-28 09:23:00 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121212466>
2019-04-28 09:23:01 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/8/>
2019-04-28 09:23:01 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121214259>
2019-04-28 09:23:01 downloader.py[line:26] INFO: <200 https://www.douban.com/>
2019-04-28 09:23:01 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/9/>
2019-04-28 09:23:01 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/10/>
2019-04-28 09:23:01 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121168431>
2019-04-28 09:23:01 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121133825>
2019-04-28 09:23:01 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/11/>
2019-04-28 09:23:01 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121182171>
2019-04-28 09:23:01 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/12/>
2019-04-28 09:23:01 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121181426>
2019-04-28 09:23:01 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/13/>
2019-04-28 09:23:01 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121220378>
2019-04-28 09:23:01 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121123045>
2019-04-28 09:23:01 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121185254>
2019-04-28 09:23:01 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121215834>
2019-04-28 09:23:01 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121226280>
2019-04-28 09:23:01 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121226419>
2019-04-28 09:23:01 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121172570>
2019-04-28 09:23:01 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121212466>
2019-04-28 09:23:01 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121214259>
2019-04-28 09:23:02 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121133825>
2019-04-28 09:23:02 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121168431>
2019-04-28 09:23:02 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121182171>
2019-04-28 09:23:02 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121181426>
2019-04-28 09:23:02 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121220378>
2019-04-28 09:23:02 engine.py[line:89] INFO: 爬虫结束: 2019-04-28 09:23:02.403743
2019-04-28 09:23:02 engine.py[line:90] INFO: 爬虫运行时间: 4.040999
2019-04-28 09:23:02 engine.py[line:93] INFO: 总的请求数量: 29个
2019-04-28 09:23:02 engine.py[line:95] INFO: 总的响应数量: 28个
2019-04-28 09:23:02 engine.py[line:97] INFO: 总的重复数量: 1个
2019-04-28 09:23:27 engine.py[line:82] INFO: 爬虫启动: 2019-04-28 09:23:27.557743
2019-04-28 09:23:27 engine.py[line:83] INFO: 当前启动的爬虫: ['spiders.baidu.BaiduSpider', 'spiders.qiubai.QiubaiSpider']
2019-04-28 09:23:27 engine.py[line:84] INFO: 当前开启的管道: ['pipelines.BaiduPipeline', 'pipelines.QiubaiPipeline']
2019-04-28 09:23:27 engine.py[line:85] INFO: 当前开启的下载器中间件: ['spider_middlewares.TestSpiderMiddleware1']
2019-04-28 09:23:27 engine.py[line:86] INFO: 当前开启的爬虫中间件: ['downloader_middlewares.TestDownloaderMiddleware2']
2019-04-28 09:23:28 scheduler.py[line:75] INFO: 发现重复的请求：<GET http://www.douban.com>
2019-04-28 09:23:29 scheduler.py[line:75] INFO: 发现重复的请求：<GET http://www.douban.com>
2019-04-28 09:23:29 scheduler.py[line:75] INFO: 发现重复的请求：<GET http://www.baidu.com>
2019-04-28 09:23:29 scheduler.py[line:75] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/1/>
2019-04-28 09:23:29 scheduler.py[line:75] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/2/>
2019-04-28 09:23:29 scheduler.py[line:75] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/3/>
2019-04-28 09:23:29 scheduler.py[line:75] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/4/>
2019-04-28 09:23:29 scheduler.py[line:75] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/5/>
2019-04-28 09:23:29 scheduler.py[line:75] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/6/>
2019-04-28 09:23:29 scheduler.py[line:75] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/7/>
2019-04-28 09:23:29 scheduler.py[line:75] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/8/>
2019-04-28 09:23:29 scheduler.py[line:75] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/9/>
2019-04-28 09:23:29 scheduler.py[line:75] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/10/>
2019-04-28 09:23:29 scheduler.py[line:75] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/11/>
2019-04-28 09:23:29 scheduler.py[line:75] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/12/>
2019-04-28 09:23:29 scheduler.py[line:75] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/13/>
2019-04-28 09:23:29 engine.py[line:89] INFO: 爬虫结束: 2019-04-28 09:23:29.677740
2019-04-28 09:23:29 engine.py[line:90] INFO: 爬虫运行时间: 2.119997
2019-04-28 09:23:29 engine.py[line:93] INFO: 总的请求数量: 16个
2019-04-28 09:23:29 engine.py[line:95] INFO: 总的响应数量: 0个
2019-04-28 09:23:29 engine.py[line:97] INFO: 总的重复数量: 16个
2019-04-28 09:26:46 engine.py[line:82] INFO: 爬虫启动: 2019-04-28 09:26:46.800742
2019-04-28 09:26:46 engine.py[line:83] INFO: 当前启动的爬虫: ['spiders.baidu.BaiduSpider', 'spiders.qiubai.QiubaiSpider']
2019-04-28 09:26:46 engine.py[line:84] INFO: 当前开启的管道: ['pipelines.BaiduPipeline', 'pipelines.QiubaiPipeline']
2019-04-28 09:26:46 engine.py[line:85] INFO: 当前开启的下载器中间件: ['spider_middlewares.TestSpiderMiddleware1']
2019-04-28 09:26:46 engine.py[line:86] INFO: 当前开启的爬虫中间件: ['downloader_middlewares.TestDownloaderMiddleware2']
2019-04-28 09:26:47 scheduler.py[line:71] INFO: 添加新的请求: <http://www.douban.com>
2019-04-28 09:26:48 scheduler.py[line:75] INFO: 发现重复的请求：<GET http://www.douban.com>
2019-04-28 09:26:48 scheduler.py[line:71] INFO: 添加新的请求: <http://www.baidu.com>
2019-04-28 09:26:48 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/1/>
2019-04-28 09:26:48 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/2/>
2019-04-28 09:26:48 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/3/>
2019-04-28 09:26:48 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/4/>
2019-04-28 09:26:48 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/5/>
2019-04-28 09:26:48 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/6/>
2019-04-28 09:26:48 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/7/>
2019-04-28 09:26:48 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/8/>
2019-04-28 09:26:48 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/9/>
2019-04-28 09:26:48 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/10/>
2019-04-28 09:26:48 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/11/>
2019-04-28 09:26:48 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/12/>
2019-04-28 09:26:48 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/13/>
2019-04-28 09:26:48 downloader.py[line:26] INFO: <200 http://www.baidu.com/>
2019-04-28 09:26:49 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/2/>
2019-04-28 09:26:49 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121215834>
2019-04-28 09:26:49 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/3/>
2019-04-28 09:26:49 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/1/>
2019-04-28 09:26:49 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121185254>
2019-04-28 09:26:49 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121123045>
2019-04-28 09:26:49 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/4/>
2019-04-28 09:26:49 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121226280>
2019-04-28 09:26:49 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/5/>
2019-04-28 09:26:49 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121172570>
2019-04-28 09:26:49 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/6/>
2019-04-28 09:26:49 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/7/>
2019-04-28 09:26:49 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121212466>
2019-04-28 09:26:49 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121226419>
2019-04-28 09:26:49 downloader.py[line:26] INFO: <200 https://www.douban.com/>
2019-04-28 09:26:49 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/8/>
2019-04-28 09:26:49 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121214259>
2019-04-28 09:26:49 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/9/>
2019-04-28 09:26:49 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121168431>
2019-04-28 09:26:49 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/10/>
2019-04-28 09:26:49 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121133825>
2019-04-28 09:26:49 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/11/>
2019-04-28 09:26:49 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/12/>
2019-04-28 09:26:49 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121182171>
2019-04-28 09:26:49 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121181426>
2019-04-28 09:26:49 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/13/>
2019-04-28 09:26:49 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121220378>
2019-04-28 09:26:49 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121215834>
2019-04-28 09:31:21 engine.py[line:82] INFO: 爬虫启动: 2019-04-28 09:31:21.982888
2019-04-28 09:31:21 engine.py[line:83] INFO: 当前启动的爬虫: ['spiders.baidu.BaiduSpider', 'spiders.qiubai.QiubaiSpider']
2019-04-28 09:31:21 engine.py[line:84] INFO: 当前开启的管道: ['pipelines.BaiduPipeline', 'pipelines.QiubaiPipeline']
2019-04-28 09:31:21 engine.py[line:85] INFO: 当前开启的下载器中间件: ['spider_middlewares.TestSpiderMiddleware1']
2019-04-28 09:31:21 engine.py[line:86] INFO: 当前开启的爬虫中间件: ['downloader_middlewares.TestDownloaderMiddleware2']
2019-04-28 09:31:23 scheduler.py[line:71] INFO: 添加新的请求: <http://www.douban.com>
2019-04-28 09:31:23 downloader.py[line:26] INFO: <200 https://www.douban.com/>
2019-04-28 09:31:24 scheduler.py[line:75] INFO: 发现重复的请求：<GET http://www.douban.com>
2019-04-28 09:31:24 scheduler.py[line:71] INFO: 添加新的请求: <http://www.baidu.com>
2019-04-28 09:31:24 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/1/>
2019-04-28 09:31:24 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/2/>
2019-04-28 09:31:24 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/3/>
2019-04-28 09:31:24 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/4/>
2019-04-28 09:31:24 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/5/>
2019-04-28 09:31:24 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/6/>
2019-04-28 09:31:24 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/7/>
2019-04-28 09:31:24 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/8/>
2019-04-28 09:31:24 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/9/>
2019-04-28 09:31:24 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/10/>
2019-04-28 09:31:24 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/11/>
2019-04-28 09:31:24 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/12/>
2019-04-28 09:31:24 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/13/>
2019-04-28 09:31:24 downloader.py[line:26] INFO: <200 http://www.baidu.com/>
2019-04-28 09:31:24 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/3/>
2019-04-28 09:31:24 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/2/>
2019-04-28 09:31:24 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121219282>
2019-04-28 09:31:24 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/4/>
2019-04-28 09:31:24 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121173259>
2019-04-28 09:31:24 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121159640>
2019-04-28 09:31:24 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/1/>
2019-04-28 09:31:24 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121182515>
2019-04-28 09:31:24 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/5/>
2019-04-28 09:31:24 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121159510>
2019-04-28 09:31:24 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/8/>
2019-04-28 09:31:24 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121191480>
2019-04-28 09:31:24 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/6/>
2019-04-28 09:31:24 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/9/>
2019-04-28 09:31:24 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/7/>
2019-04-28 09:31:24 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121151603>
2019-04-28 09:31:24 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121170868>
2019-04-28 09:31:24 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121214382>
2019-04-28 09:31:24 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/10/>
2019-04-28 09:31:24 scheduler.py[line:71] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121143627>
2019-04-28 09:31:37 engine.py[line:82] INFO: 爬虫启动: 2019-04-28 09:31:37.902890
2019-04-28 09:31:37 engine.py[line:83] INFO: 当前启动的爬虫: ['spiders.baidu.BaiduSpider', 'spiders.qiubai.QiubaiSpider']
2019-04-28 09:31:37 engine.py[line:84] INFO: 当前开启的管道: ['pipelines.BaiduPipeline', 'pipelines.QiubaiPipeline']
2019-04-28 09:31:37 engine.py[line:85] INFO: 当前开启的下载器中间件: ['spider_middlewares.TestSpiderMiddleware1']
2019-04-28 09:31:37 engine.py[line:86] INFO: 当前开启的爬虫中间件: ['downloader_middlewares.TestDownloaderMiddleware2']
2019-04-28 09:31:38 scheduler.py[line:75] INFO: 发现重复的请求：<GET http://www.douban.com>
2019-04-28 09:31:39 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121159640>
2019-04-28 09:31:39 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121182515>
2019-04-28 09:31:39 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121159510>
2019-04-28 09:31:39 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121191480>
2019-04-28 09:31:39 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121151603>
2019-04-28 09:31:39 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121170868>
2019-04-28 09:31:39 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121214382>
2019-04-28 09:31:39 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121143627>
2019-04-28 09:31:39 scheduler.py[line:75] INFO: 发现重复的请求：<GET http://www.douban.com>
2019-04-28 09:31:39 scheduler.py[line:75] INFO: 发现重复的请求：<GET http://www.baidu.com>
2019-04-28 09:31:39 scheduler.py[line:75] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/1/>
2019-04-28 09:31:39 scheduler.py[line:75] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/2/>
2019-04-28 09:31:39 scheduler.py[line:75] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/3/>
2019-04-28 09:31:39 scheduler.py[line:75] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/4/>
2019-04-28 09:31:39 scheduler.py[line:75] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/5/>
2019-04-28 09:31:39 scheduler.py[line:75] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/6/>
2019-04-28 09:31:39 scheduler.py[line:75] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/7/>
2019-04-28 09:31:39 scheduler.py[line:75] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/8/>
2019-04-28 09:31:39 scheduler.py[line:75] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/9/>
2019-04-28 09:31:39 scheduler.py[line:75] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/10/>
2019-04-28 09:31:39 scheduler.py[line:75] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/11/>
2019-04-28 09:31:39 scheduler.py[line:75] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/12/>
2019-04-28 09:31:39 scheduler.py[line:75] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/13/>
2019-04-28 11:46:19 engine.py[line:81] INFO: 爬虫启动: 2019-04-28 11:46:19.337333
2019-04-28 11:46:19 engine.py[line:82] INFO: 当前启动的爬虫: ['spiders.baidu.BaiduSpider', 'spiders.qiubai.QiubaiSpider']
2019-04-28 11:46:19 engine.py[line:83] INFO: 当前开启的管道: ['pipelines.BaiduPipeline', 'pipelines.QiubaiPipeline']
2019-04-28 11:46:19 engine.py[line:84] INFO: 当前开启的下载器中间件: ['spider_middlewares.TestSpiderMiddleware1']
2019-04-28 11:46:19 engine.py[line:85] INFO: 当前开启的爬虫中间件: ['downloader_middlewares.TestDownloaderMiddleware2']
2019-04-28 11:46:21 scheduler.py[line:82] INFO: 发现重复的请求：<GET http://www.douban.com>
2019-04-28 11:46:21 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/1/>
2019-04-28 11:46:22 scheduler.py[line:82] INFO: 发现重复的请求：<GET http://www.douban.com>
2019-04-28 11:46:22 scheduler.py[line:82] INFO: 发现重复的请求：<GET http://www.baidu.com>
2019-04-28 11:46:22 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/2/>
2019-04-28 11:46:22 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/3/>
2019-04-28 11:46:22 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/4/>
2019-04-28 11:46:22 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/5/>
2019-04-28 11:46:22 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/6/>
2019-04-28 11:46:22 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/7/>
2019-04-28 11:46:22 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/8/>
2019-04-28 11:46:22 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/9/>
2019-04-28 11:46:22 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/10/>
2019-04-28 11:46:22 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/11/>
2019-04-28 11:46:22 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/12/>
2019-04-28 11:46:22 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/13/>
2019-04-28 11:46:55 engine.py[line:88] INFO: 爬虫结束: 2019-04-28 11:46:55.903134
2019-04-28 11:46:55 engine.py[line:89] INFO: 爬虫运行时间: 36.565801
2019-04-28 11:46:55 engine.py[line:92] INFO: 总的请求数量: 0个
2019-04-28 11:46:55 engine.py[line:94] INFO: 总的响应数量: 0个
2019-04-28 11:46:55 engine.py[line:96] INFO: 总的重复数量: 0个
2019-04-28 11:47:02 engine.py[line:81] INFO: 爬虫启动: 2019-04-28 11:47:02.454134
2019-04-28 11:47:02 engine.py[line:82] INFO: 当前启动的爬虫: ['spiders.baidu.BaiduSpider', 'spiders.qiubai.QiubaiSpider']
2019-04-28 11:47:02 engine.py[line:83] INFO: 当前开启的管道: ['pipelines.BaiduPipeline', 'pipelines.QiubaiPipeline']
2019-04-28 11:47:02 engine.py[line:84] INFO: 当前开启的下载器中间件: ['spider_middlewares.TestSpiderMiddleware1']
2019-04-28 11:47:02 engine.py[line:85] INFO: 当前开启的爬虫中间件: ['downloader_middlewares.TestDownloaderMiddleware2']
2019-04-28 11:47:04 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/1/>
2019-04-28 11:47:04 scheduler.py[line:78] INFO: 添加新的请求: <http://www.douban.com>
2019-04-28 11:47:04 scheduler.py[line:82] INFO: 发现重复的请求：<GET http://www.douban.com>
2019-04-28 11:47:04 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/1/>
2019-04-28 11:47:04 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121155143>
2019-04-28 11:47:05 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121155143>
2019-04-28 11:47:05 downloader.py[line:26] INFO: <200 https://www.douban.com/>
2019-04-28 11:47:05 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/2/>
2019-04-28 11:47:05 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/3/>
2019-04-28 11:47:05 scheduler.py[line:78] INFO: 添加新的请求: <http://www.baidu.com>
2019-04-28 11:47:05 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/4/>
2019-04-28 11:47:05 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/5/>
2019-04-28 11:47:05 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/6/>
2019-04-28 11:47:05 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/7/>
2019-04-28 11:47:05 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/8/>
2019-04-28 11:47:05 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/9/>
2019-04-28 11:47:05 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/10/>
2019-04-28 11:47:05 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/11/>
2019-04-28 11:47:05 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/12/>
2019-04-28 11:47:05 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/13/>
2019-04-28 11:47:05 downloader.py[line:26] INFO: <200 http://www.baidu.com/>
2019-04-28 11:47:05 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/2/>
2019-04-28 11:47:05 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/4/>
2019-04-28 11:47:05 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/3/>
2019-04-28 11:47:05 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121226423>
2019-04-28 11:47:05 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/5/>
2019-04-28 11:47:05 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121151932>
2019-04-28 11:47:05 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121165245>
2019-04-28 11:47:05 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121218723>
2019-04-28 11:47:05 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/6/>
2019-04-28 11:47:05 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121143324>
2019-04-28 11:47:05 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/7/>
2019-04-28 11:47:05 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121128956>
2019-04-28 11:47:06 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/10/>
2019-04-28 11:47:06 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/8/>
2019-04-28 11:47:06 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/9/>
2019-04-28 11:47:06 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121156404>
2019-04-28 11:47:06 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121141528>
2019-04-28 11:47:06 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121196405>
2019-04-28 11:47:06 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/11/>
2019-04-28 11:47:06 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121178165>
2019-04-28 11:47:06 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/12/>
2019-04-28 11:47:06 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121222123>
2019-04-28 11:47:06 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/13/>
2019-04-28 11:47:06 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121150803>
2019-04-28 11:47:06 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121226423>
2019-04-28 11:47:06 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121151932>
2019-04-28 11:47:06 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121165245>
2019-04-28 11:47:06 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121218723>
2019-04-28 11:47:06 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121143324>
2019-04-28 11:47:06 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121128956>
2019-04-28 11:47:06 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121156404>
2019-04-28 11:47:06 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121141528>
2019-04-28 11:47:06 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121196405>
2019-04-28 11:47:06 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121178165>
2019-04-28 11:47:06 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121222123>
2019-04-28 11:47:06 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121150803>
2019-04-28 11:47:06 engine.py[line:88] INFO: 爬虫结束: 2019-04-28 11:47:06.998134
2019-04-28 11:47:06 engine.py[line:89] INFO: 爬虫运行时间: 4.544
2019-04-28 11:47:07 engine.py[line:92] INFO: 总的请求数量: 29个
2019-04-28 11:47:07 engine.py[line:94] INFO: 总的响应数量: 28个
2019-04-28 11:47:07 engine.py[line:96] INFO: 总的重复数量: 1个
2019-04-28 11:47:22 engine.py[line:81] INFO: 爬虫启动: 2019-04-28 11:47:22.542153
2019-04-28 11:47:22 engine.py[line:82] INFO: 当前启动的爬虫: ['spiders.baidu.BaiduSpider', 'spiders.qiubai.QiubaiSpider']
2019-04-28 11:47:22 engine.py[line:83] INFO: 当前开启的管道: ['pipelines.BaiduPipeline', 'pipelines.QiubaiPipeline']
2019-04-28 11:47:22 engine.py[line:84] INFO: 当前开启的下载器中间件: ['spider_middlewares.TestSpiderMiddleware1']
2019-04-28 11:47:22 engine.py[line:85] INFO: 当前开启的爬虫中间件: ['downloader_middlewares.TestDownloaderMiddleware2']
2019-04-28 11:47:24 scheduler.py[line:82] INFO: 发现重复的请求：<GET http://www.douban.com>
2019-04-28 11:47:24 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/1/>
2019-04-28 11:47:24 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/2/>
2019-04-28 11:47:24 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/3/>
2019-04-28 11:47:24 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/4/>
2019-04-28 11:47:24 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/5/>
2019-04-28 11:47:24 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/6/>
2019-04-28 11:47:24 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/7/>
2019-04-28 11:47:24 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/8/>
2019-04-28 11:47:24 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/9/>
2019-04-28 11:47:24 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/10/>
2019-04-28 11:47:24 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/11/>
2019-04-28 11:47:24 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/12/>
2019-04-28 11:47:24 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/13/>
2019-04-28 11:47:25 scheduler.py[line:82] INFO: 发现重复的请求：<GET http://www.douban.com>
2019-04-28 11:47:25 scheduler.py[line:82] INFO: 发现重复的请求：<GET http://www.baidu.com>
2019-04-28 11:47:25 engine.py[line:88] INFO: 爬虫结束: 2019-04-28 11:47:25.672135
2019-04-28 11:47:25 engine.py[line:89] INFO: 爬虫运行时间: 3.129982
2019-04-28 11:47:25 engine.py[line:92] INFO: 总的请求数量: 16个
2019-04-28 11:47:25 engine.py[line:94] INFO: 总的响应数量: 0个
2019-04-28 11:47:25 engine.py[line:96] INFO: 总的重复数量: 16个
2019-04-28 11:49:04 engine.py[line:81] INFO: 爬虫启动: 2019-04-28 11:49:04.226139
2019-04-28 11:49:04 engine.py[line:82] INFO: 当前启动的爬虫: ['spiders.baidu.BaiduSpider', 'spiders.qiubai.QiubaiSpider']
2019-04-28 11:49:04 engine.py[line:83] INFO: 当前开启的管道: ['pipelines.BaiduPipeline', 'pipelines.QiubaiPipeline']
2019-04-28 11:49:04 engine.py[line:84] INFO: 当前开启的下载器中间件: ['spider_middlewares.TestSpiderMiddleware1']
2019-04-28 11:49:04 engine.py[line:85] INFO: 当前开启的爬虫中间件: ['downloader_middlewares.TestDownloaderMiddleware2']
2019-04-28 11:49:06 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/1/>
2019-04-28 11:49:06 scheduler.py[line:78] INFO: 添加新的请求: <http://www.douban.com>
2019-04-28 11:49:06 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/2/>
2019-04-28 11:49:06 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/3/>
2019-04-28 11:49:06 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/4/>
2019-04-28 11:49:06 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/5/>
2019-04-28 11:49:06 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/6/>
2019-04-28 11:49:06 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/7/>
2019-04-28 11:49:06 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/8/>
2019-04-28 11:49:06 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/9/>
2019-04-28 11:49:06 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/10/>
2019-04-28 11:49:06 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/11/>
2019-04-28 11:49:06 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/12/>
2019-04-28 11:49:06 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/13/>
2019-04-28 11:49:06 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/1/>
2019-04-28 11:49:06 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/3/>
2019-04-28 11:49:06 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121155143>
2019-04-28 11:49:06 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/2/>
2019-04-28 11:49:06 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121165245>
2019-04-28 11:49:06 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121226423>
2019-04-28 11:49:06 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/4/>
2019-04-28 11:49:06 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/6/>
2019-04-28 11:49:06 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/5/>
2019-04-28 11:49:06 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121151932>
2019-04-28 11:49:06 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121143324>
2019-04-28 11:49:06 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121218723>
2019-04-28 11:49:06 downloader.py[line:26] INFO: <200 https://www.douban.com/>
2019-04-28 11:49:07 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/8/>
2019-04-28 11:49:07 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121141528>
2019-04-28 11:49:07 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/7/>
2019-04-28 11:49:07 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121128956>
2019-04-28 11:49:07 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/9/>
2019-04-28 11:49:07 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121196405>
2019-04-28 11:49:07 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/10/>
2019-04-28 11:49:07 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121156404>
2019-04-28 11:49:07 scheduler.py[line:82] INFO: 发现重复的请求：<GET http://www.douban.com>
2019-04-28 11:49:07 scheduler.py[line:78] INFO: 添加新的请求: <http://www.baidu.com>
2019-04-28 11:49:07 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/12/>
2019-04-28 11:49:07 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/11/>
2019-04-28 11:49:07 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121222123>
2019-04-28 11:49:07 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121178165>
2019-04-28 11:49:07 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121155143>
2019-04-28 11:49:07 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/13/>
2019-04-28 11:49:07 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121150803>
2019-04-28 11:49:07 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121165245>
2019-04-28 11:49:07 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121226423>
2019-04-28 11:49:07 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121151932>
2019-04-28 11:49:07 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121143324>
2019-04-28 11:49:07 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121218723>
2019-04-28 11:49:07 downloader.py[line:26] INFO: <200 http://www.baidu.com/>
2019-04-28 11:49:07 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121141528>
2019-04-28 11:49:07 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121128956>
2019-04-28 11:49:07 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121196405>
2019-04-28 11:49:07 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121156404>
2019-04-28 11:49:07 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121222123>
2019-04-28 11:49:08 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121178165>
2019-04-28 11:49:08 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121150803>
2019-04-28 11:49:08 engine.py[line:88] INFO: 爬虫结束: 2019-04-28 11:49:08.166137
2019-04-28 11:49:08 engine.py[line:89] INFO: 爬虫运行时间: 3.939998
2019-04-28 11:49:08 engine.py[line:92] INFO: 总的请求数量: 29个
2019-04-28 11:49:08 engine.py[line:94] INFO: 总的响应数量: 28个
2019-04-28 11:49:08 engine.py[line:96] INFO: 总的重复数量: 1个
2019-04-28 11:49:08 engine.py[line:98] INFO: 总的重复数量: 2个
2019-04-28 11:50:45 engine.py[line:81] INFO: 爬虫启动: 2019-04-28 11:50:45.873135
2019-04-28 11:50:45 engine.py[line:82] INFO: 当前启动的爬虫: ['spiders.baidu.BaiduSpider', 'spiders.qiubai.QiubaiSpider', 'spiders.sina.SinaRollNews']
2019-04-28 11:50:45 engine.py[line:83] INFO: 当前开启的管道: ['pipelines.BaiduPipeline', 'pipelines.QiubaiPipeline']
2019-04-28 11:50:45 engine.py[line:84] INFO: 当前开启的下载器中间件: ['spider_middlewares.TestSpiderMiddleware1']
2019-04-28 11:50:45 engine.py[line:85] INFO: 当前开启的爬虫中间件: ['downloader_middlewares.TestDownloaderMiddleware2']
2019-04-28 11:50:46 scheduler.py[line:46] INFO: 添加不去重的请求: <GET https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2509&k=&num=50&page=1&r=0.4002104982344896&_=1556415569224>
2019-04-28 11:50:47 downloader.py[line:26] INFO: <200 https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2509&k=&num=50&page=1&r=0.4002104982344896&_=1556415569224>
2019-04-28 11:50:47 engine.py[line:197] ERROR: 'dict' object is not callable
Traceback (most recent call last):
  File "D:\David\Desktop\spider_plus_fw\spider_plus\core\engine.py", line 195, in _error_callback
    raise exception  # 抛出异常后, 才能被日志进行完整记录下来
  File "c:\python36\Lib\multiprocessing\pool.py", line 119, in worker
    result = (True, func(*args, **kwds))
  File "D:\David\Desktop\spider_plus_fw\spider_plus\core\engine.py", line 164, in _execute_request_response_item
    for result in parse(response):
  File "D:\David\Desktop\spider_plus_fw\spider_project\spiders\sina.py", line 18, in parse
    yield Item(response.json().get("result").get("data"))
TypeError: 'dict' object is not callable
2019-04-28 11:50:47 scheduler.py[line:82] INFO: 发现重复的请求：<GET http://www.douban.com>
2019-04-28 11:50:47 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/1/>
2019-04-28 11:50:47 scheduler.py[line:82] INFO: 发现重复的请求：<GET http://www.douban.com>
2019-04-28 11:50:48 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/2/>
2019-04-28 11:50:48 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/3/>
2019-04-28 11:50:48 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/4/>
2019-04-28 11:50:48 scheduler.py[line:82] INFO: 发现重复的请求：<GET http://www.baidu.com>
2019-04-28 11:50:48 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/5/>
2019-04-28 11:50:48 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/6/>
2019-04-28 11:50:48 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/7/>
2019-04-28 11:50:48 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/8/>
2019-04-28 11:50:48 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/9/>
2019-04-28 11:50:48 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/10/>
2019-04-28 11:50:48 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/11/>
2019-04-28 11:50:48 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/12/>
2019-04-28 11:50:48 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/13/>
2019-04-28 11:50:56 scheduler.py[line:46] INFO: 添加不去重的请求: <GET https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2509&k=&num=50&page=1&r=0.4002104982344896&_=1556415569224>
2019-04-28 11:50:57 downloader.py[line:26] INFO: <200 https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2509&k=&num=50&page=1&r=0.4002104982344896&_=1556415569224>
2019-04-28 11:50:57 engine.py[line:197] ERROR: 'dict' object is not callable
Traceback (most recent call last):
  File "D:\David\Desktop\spider_plus_fw\spider_plus\core\engine.py", line 195, in _error_callback
    raise exception  # 抛出异常后, 才能被日志进行完整记录下来
  File "c:\python36\Lib\multiprocessing\pool.py", line 119, in worker
    result = (True, func(*args, **kwds))
  File "D:\David\Desktop\spider_plus_fw\spider_plus\core\engine.py", line 164, in _execute_request_response_item
    for result in parse(response):
  File "D:\David\Desktop\spider_plus_fw\spider_project\spiders\sina.py", line 18, in parse
    yield Item(response.json().get("result").get("data"))
TypeError: 'dict' object is not callable
2019-04-28 11:51:06 scheduler.py[line:46] INFO: 添加不去重的请求: <GET https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2509&k=&num=50&page=1&r=0.4002104982344896&_=1556415569224>
2019-04-28 11:51:07 downloader.py[line:26] INFO: <200 https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2509&k=&num=50&page=1&r=0.4002104982344896&_=1556415569224>
2019-04-28 11:51:07 engine.py[line:197] ERROR: 'dict' object is not callable
Traceback (most recent call last):
  File "D:\David\Desktop\spider_plus_fw\spider_plus\core\engine.py", line 195, in _error_callback
    raise exception  # 抛出异常后, 才能被日志进行完整记录下来
  File "c:\python36\Lib\multiprocessing\pool.py", line 119, in worker
    result = (True, func(*args, **kwds))
  File "D:\David\Desktop\spider_plus_fw\spider_plus\core\engine.py", line 164, in _execute_request_response_item
    for result in parse(response):
  File "D:\David\Desktop\spider_plus_fw\spider_project\spiders\sina.py", line 18, in parse
    yield Item(response.json().get("result").get("data"))
TypeError: 'dict' object is not callable
2019-04-28 11:51:21 engine.py[line:81] INFO: 爬虫启动: 2019-04-28 11:51:21.089137
2019-04-28 11:51:21 engine.py[line:82] INFO: 当前启动的爬虫: ['spiders.baidu.BaiduSpider', 'spiders.qiubai.QiubaiSpider', 'spiders.sina.SinaRollNews']
2019-04-28 11:51:21 engine.py[line:83] INFO: 当前开启的管道: ['pipelines.BaiduPipeline', 'pipelines.QiubaiPipeline']
2019-04-28 11:51:21 engine.py[line:84] INFO: 当前开启的下载器中间件: ['spider_middlewares.TestSpiderMiddleware1']
2019-04-28 11:51:21 engine.py[line:85] INFO: 当前开启的爬虫中间件: ['downloader_middlewares.TestDownloaderMiddleware2']
2019-04-28 11:51:22 scheduler.py[line:46] INFO: 添加不去重的请求: <GET https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2509&k=&num=50&page=1&r=0.4002104982344896&_=1556415569224>
2019-04-28 11:51:22 downloader.py[line:26] INFO: <200 https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2509&k=&num=50&page=1&r=0.4002104982344896&_=1556415569224>
2019-04-28 11:51:22 engine.py[line:197] ERROR: 'dict' object is not callable
Traceback (most recent call last):
  File "D:\David\Desktop\spider_plus_fw\spider_plus\core\engine.py", line 195, in _error_callback
    raise exception  # 抛出异常后, 才能被日志进行完整记录下来
  File "c:\python36\Lib\multiprocessing\pool.py", line 119, in worker
    result = (True, func(*args, **kwds))
  File "D:\David\Desktop\spider_plus_fw\spider_plus\core\engine.py", line 164, in _execute_request_response_item
    for result in parse(response):
  File "D:\David\Desktop\spider_plus_fw\spider_project\spiders\sina.py", line 18, in parse
    yield Item(response.json().get("result").get("data"))
TypeError: 'dict' object is not callable
2019-04-28 11:51:23 scheduler.py[line:82] INFO: 发现重复的请求：<GET http://www.douban.com>
2019-04-28 11:51:23 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/1/>
2019-04-28 11:51:23 scheduler.py[line:82] INFO: 发现重复的请求：<GET http://www.douban.com>
2019-04-28 11:51:23 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/2/>
2019-04-28 11:51:23 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/3/>
2019-04-28 11:51:23 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/4/>
2019-04-28 11:51:23 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/5/>
2019-04-28 11:51:23 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/6/>
2019-04-28 11:51:23 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/7/>
2019-04-28 11:51:23 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/8/>
2019-04-28 11:51:23 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/9/>
2019-04-28 11:51:23 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/10/>
2019-04-28 11:51:23 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/11/>
2019-04-28 11:51:23 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/12/>
2019-04-28 11:51:23 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/13/>
2019-04-28 11:51:24 scheduler.py[line:82] INFO: 发现重复的请求：<GET http://www.baidu.com>
2019-04-28 11:56:02 engine.py[line:81] INFO: 爬虫启动: 2019-04-28 11:56:02.177137
2019-04-28 11:56:02 engine.py[line:82] INFO: 当前启动的爬虫: ['spiders.baidu.BaiduSpider', 'spiders.qiubai.QiubaiSpider', 'spiders.sina.SinaRollNews']
2019-04-28 11:56:02 engine.py[line:83] INFO: 当前开启的管道: ['pipelines.BaiduPipeline', 'pipelines.QiubaiPipeline']
2019-04-28 11:56:02 engine.py[line:84] INFO: 当前开启的下载器中间件: ['spider_middlewares.TestSpiderMiddleware1']
2019-04-28 11:56:02 engine.py[line:85] INFO: 当前开启的爬虫中间件: ['downloader_middlewares.TestDownloaderMiddleware2']
2019-04-28 11:56:03 scheduler.py[line:46] INFO: 添加不去重的请求: <GET https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2509&k=&num=50&page=1&r=0.4002104982344896&_=1556415569224>
2019-04-28 11:56:03 downloader.py[line:26] INFO: <200 https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2509&k=&num=50&page=1&r=0.4002104982344896&_=1556415569224>
2019-04-28 11:56:03 engine.py[line:197] ERROR: 'dict' object is not callable
Traceback (most recent call last):
  File "D:\David\Desktop\spider_plus_fw\spider_plus\core\engine.py", line 195, in _error_callback
    raise exception  # 抛出异常后, 才能被日志进行完整记录下来
  File "c:\python36\Lib\multiprocessing\pool.py", line 119, in worker
    result = (True, func(*args, **kwds))
  File "D:\David\Desktop\spider_plus_fw\spider_plus\core\engine.py", line 164, in _execute_request_response_item
    for result in parse(response):
  File "D:\David\Desktop\spider_plus_fw\spider_project\spiders\sina.py", line 18, in parse
    yield Item(str(response.json().get("result").get("data")))
TypeError: 'dict' object is not callable
2019-04-28 11:56:04 scheduler.py[line:82] INFO: 发现重复的请求：<GET http://www.douban.com>
2019-04-28 11:56:04 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/1/>
2019-04-28 11:56:04 scheduler.py[line:82] INFO: 发现重复的请求：<GET http://www.douban.com>
2019-04-28 11:56:04 scheduler.py[line:82] INFO: 发现重复的请求：<GET http://www.baidu.com>
2019-04-28 11:56:05 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/2/>
2019-04-28 11:56:05 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/3/>
2019-04-28 11:56:05 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/4/>
2019-04-28 11:56:05 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/5/>
2019-04-28 11:56:05 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/6/>
2019-04-28 11:56:05 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/7/>
2019-04-28 11:56:05 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/8/>
2019-04-28 11:56:05 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/9/>
2019-04-28 11:56:05 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/10/>
2019-04-28 11:56:05 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/11/>
2019-04-28 11:56:05 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/12/>
2019-04-28 11:56:05 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/13/>
2019-04-28 11:56:13 scheduler.py[line:46] INFO: 添加不去重的请求: <GET https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2509&k=&num=50&page=1&r=0.4002104982344896&_=1556415569224>
2019-04-28 11:56:13 downloader.py[line:26] INFO: <200 https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2509&k=&num=50&page=1&r=0.4002104982344896&_=1556415569224>
2019-04-28 11:56:13 engine.py[line:197] ERROR: 'dict' object is not callable
Traceback (most recent call last):
  File "D:\David\Desktop\spider_plus_fw\spider_plus\core\engine.py", line 195, in _error_callback
    raise exception  # 抛出异常后, 才能被日志进行完整记录下来
  File "c:\python36\Lib\multiprocessing\pool.py", line 119, in worker
    result = (True, func(*args, **kwds))
  File "D:\David\Desktop\spider_plus_fw\spider_plus\core\engine.py", line 164, in _execute_request_response_item
    for result in parse(response):
  File "D:\David\Desktop\spider_plus_fw\spider_project\spiders\sina.py", line 18, in parse
    yield Item(str(response.json().get("result").get("data")))
TypeError: 'dict' object is not callable
2019-04-28 11:58:40 engine.py[line:81] INFO: 爬虫启动: 2019-04-28 11:58:40.423356
2019-04-28 11:58:40 engine.py[line:82] INFO: 当前启动的爬虫: ['spiders.baidu.BaiduSpider', 'spiders.qiubai.QiubaiSpider', 'spiders.sina.SinaRollNews']
2019-04-28 11:58:40 engine.py[line:83] INFO: 当前开启的管道: ['pipelines.BaiduPipeline', 'pipelines.QiubaiPipeline']
2019-04-28 11:58:40 engine.py[line:84] INFO: 当前开启的下载器中间件: ['spider_middlewares.TestSpiderMiddleware1']
2019-04-28 11:58:40 engine.py[line:85] INFO: 当前开启的爬虫中间件: ['downloader_middlewares.TestDownloaderMiddleware2']
2019-04-28 11:58:41 scheduler.py[line:46] INFO: 添加不去重的请求: <GET https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2509&k=&num=50&page=1&r=0.4002104982344896&_=1556415569224>
2019-04-28 11:58:41 downloader.py[line:26] INFO: <200 https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2509&k=&num=50&page=1&r=0.4002104982344896&_=1556415569224>
2019-04-28 11:58:41 engine.py[line:197] ERROR: 'dict' object is not callable
Traceback (most recent call last):
  File "D:\David\Desktop\spider_plus_fw\spider_plus\core\engine.py", line 195, in _error_callback
    raise exception  # 抛出异常后, 才能被日志进行完整记录下来
  File "c:\python36\Lib\multiprocessing\pool.py", line 119, in worker
    result = (True, func(*args, **kwds))
  File "D:\David\Desktop\spider_plus_fw\spider_plus\core\engine.py", line 164, in _execute_request_response_item
    for result in parse(response):
  File "D:\David\Desktop\spider_plus_fw\spider_project\spiders\sina.py", line 19, in parse
    yield Item(str(response.json()))
TypeError: 'dict' object is not callable
2019-04-28 11:58:42 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/1/>
2019-04-28 11:58:42 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/2/>
2019-04-28 11:58:42 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/3/>
2019-04-28 11:58:42 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/4/>
2019-04-28 11:58:42 scheduler.py[line:78] INFO: 添加新的请求: <http://www.douban.com>
2019-04-28 11:58:42 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/5/>
2019-04-28 11:58:42 scheduler.py[line:82] INFO: 发现重复的请求：<GET http://www.douban.com>
2019-04-28 11:58:42 scheduler.py[line:78] INFO: 添加新的请求: <http://www.baidu.com>
2019-04-28 11:58:42 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/3/>
2019-04-28 11:58:42 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/1/>
2019-04-28 11:58:42 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121172241>
2019-04-28 11:58:42 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121127392>
2019-04-28 11:58:42 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/2/>
2019-04-28 11:58:42 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121161490>
2019-04-28 11:58:42 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/4/>
2019-04-28 11:58:42 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121210843>
2019-04-28 11:58:43 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/5/>
2019-04-28 11:58:43 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121218989>
2019-04-28 11:58:43 downloader.py[line:26] INFO: <200 http://www.baidu.com/>
2019-04-28 11:58:43 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121172241>
2019-04-28 11:58:43 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121127392>
2019-04-28 11:58:43 downloader.py[line:26] INFO: <200 https://www.douban.com/>
2019-04-28 11:58:43 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/6/>
2019-04-28 11:58:43 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/7/>
2019-04-28 11:58:43 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/8/>
2019-04-28 11:58:43 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/9/>
2019-04-28 11:58:43 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/10/>
2019-04-28 11:58:43 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/11/>
2019-04-28 11:58:43 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/12/>
2019-04-28 11:58:43 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/13/>
2019-04-28 11:58:43 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121161490>
2019-04-28 11:58:43 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121210843>
2019-04-28 11:58:43 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121218989>
2019-04-28 11:58:43 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/6/>
2019-04-28 11:58:43 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121194391>
2019-04-28 11:58:43 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/7/>
2019-04-28 11:58:43 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121222696>
2019-04-28 11:58:43 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/8/>
2019-04-28 11:58:43 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121185708>
2019-04-28 11:58:43 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/9/>
2019-04-28 11:58:43 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121185666>
2019-04-28 11:58:44 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/10/>
2019-04-28 11:58:44 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121224187>
2019-04-28 11:58:44 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/11/>
2019-04-28 11:58:44 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121149728>
2019-04-28 11:58:44 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/12/>
2019-04-28 11:58:44 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121197472>
2019-04-28 11:58:44 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/13/>
2019-04-28 11:58:44 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121195800>
2019-04-28 11:58:44 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121194391>
2019-04-28 11:58:44 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121222696>
2019-04-28 11:58:44 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121185708>
2019-04-28 11:58:44 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121185666>
2019-04-28 11:58:44 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121224187>
2019-04-28 11:58:44 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121149728>
2019-04-28 11:58:44 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121197472>
2019-04-28 11:58:44 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121195800>
2019-04-28 11:58:51 scheduler.py[line:46] INFO: 添加不去重的请求: <GET https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2509&k=&num=50&page=1&r=0.4002104982344896&_=1556415569224>
2019-04-28 11:58:51 downloader.py[line:26] INFO: <200 https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2509&k=&num=50&page=1&r=0.4002104982344896&_=1556415569224>
2019-04-28 11:58:51 engine.py[line:197] ERROR: 'dict' object is not callable
Traceback (most recent call last):
  File "D:\David\Desktop\spider_plus_fw\spider_plus\core\engine.py", line 195, in _error_callback
    raise exception  # 抛出异常后, 才能被日志进行完整记录下来
  File "c:\python36\Lib\multiprocessing\pool.py", line 119, in worker
    result = (True, func(*args, **kwds))
  File "D:\David\Desktop\spider_plus_fw\spider_plus\core\engine.py", line 164, in _execute_request_response_item
    for result in parse(response):
  File "D:\David\Desktop\spider_plus_fw\spider_project\spiders\sina.py", line 19, in parse
    yield Item(str(response.json()))
TypeError: 'dict' object is not callable
2019-04-28 11:59:01 scheduler.py[line:46] INFO: 添加不去重的请求: <GET https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2509&k=&num=50&page=1&r=0.4002104982344896&_=1556415569224>
2019-04-28 11:59:01 downloader.py[line:26] INFO: <200 https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2509&k=&num=50&page=1&r=0.4002104982344896&_=1556415569224>
2019-04-28 11:59:01 engine.py[line:197] ERROR: 'dict' object is not callable
Traceback (most recent call last):
  File "D:\David\Desktop\spider_plus_fw\spider_plus\core\engine.py", line 195, in _error_callback
    raise exception  # 抛出异常后, 才能被日志进行完整记录下来
  File "c:\python36\Lib\multiprocessing\pool.py", line 119, in worker
    result = (True, func(*args, **kwds))
  File "D:\David\Desktop\spider_plus_fw\spider_plus\core\engine.py", line 164, in _execute_request_response_item
    for result in parse(response):
  File "D:\David\Desktop\spider_plus_fw\spider_project\spiders\sina.py", line 19, in parse
    yield Item(str(response.json()))
TypeError: 'dict' object is not callable
2019-04-28 11:59:11 scheduler.py[line:46] INFO: 添加不去重的请求: <GET https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2509&k=&num=50&page=1&r=0.4002104982344896&_=1556415569224>
2019-04-28 11:59:11 downloader.py[line:26] INFO: <200 https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2509&k=&num=50&page=1&r=0.4002104982344896&_=1556415569224>
2019-04-28 11:59:11 engine.py[line:197] ERROR: 'dict' object is not callable
Traceback (most recent call last):
  File "D:\David\Desktop\spider_plus_fw\spider_plus\core\engine.py", line 195, in _error_callback
    raise exception  # 抛出异常后, 才能被日志进行完整记录下来
  File "c:\python36\Lib\multiprocessing\pool.py", line 119, in worker
    result = (True, func(*args, **kwds))
  File "D:\David\Desktop\spider_plus_fw\spider_plus\core\engine.py", line 164, in _execute_request_response_item
    for result in parse(response):
  File "D:\David\Desktop\spider_plus_fw\spider_project\spiders\sina.py", line 19, in parse
    yield Item(str(response.json()))
TypeError: 'dict' object is not callable
2019-04-28 11:59:21 scheduler.py[line:46] INFO: 添加不去重的请求: <GET https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2509&k=&num=50&page=1&r=0.4002104982344896&_=1556415569224>
2019-04-28 11:59:21 downloader.py[line:26] INFO: <200 https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2509&k=&num=50&page=1&r=0.4002104982344896&_=1556415569224>
2019-04-28 11:59:21 engine.py[line:197] ERROR: 'dict' object is not callable
Traceback (most recent call last):
  File "D:\David\Desktop\spider_plus_fw\spider_plus\core\engine.py", line 195, in _error_callback
    raise exception  # 抛出异常后, 才能被日志进行完整记录下来
  File "c:\python36\Lib\multiprocessing\pool.py", line 119, in worker
    result = (True, func(*args, **kwds))
  File "D:\David\Desktop\spider_plus_fw\spider_plus\core\engine.py", line 164, in _execute_request_response_item
    for result in parse(response):
  File "D:\David\Desktop\spider_plus_fw\spider_project\spiders\sina.py", line 19, in parse
    yield Item(response)
TypeError: 'dict' object is not callable
2019-04-28 11:59:50 engine.py[line:81] INFO: 爬虫启动: 2019-04-28 11:59:50.755347
2019-04-28 11:59:50 engine.py[line:82] INFO: 当前启动的爬虫: ['spiders.baidu.BaiduSpider', 'spiders.qiubai.QiubaiSpider', 'spiders.sina.SinaRollNews']
2019-04-28 11:59:50 engine.py[line:83] INFO: 当前开启的管道: ['pipelines.BaiduPipeline', 'pipelines.QiubaiPipeline']
2019-04-28 11:59:50 engine.py[line:84] INFO: 当前开启的下载器中间件: ['spider_middlewares.TestSpiderMiddleware1']
2019-04-28 11:59:50 engine.py[line:85] INFO: 当前开启的爬虫中间件: ['downloader_middlewares.TestDownloaderMiddleware2']
2019-04-28 11:59:51 scheduler.py[line:46] INFO: 添加不去重的请求: <GET https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2509&k=&num=50&page=1&r=0.4002104982344896&_=1556415569224>
2019-04-28 11:59:52 downloader.py[line:26] INFO: <200 https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2509&k=&num=50&page=1&r=0.4002104982344896&_=1556415569224>
2019-04-28 11:59:52 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/1/>
2019-04-28 11:59:52 scheduler.py[line:78] INFO: 添加新的请求: <http://www.douban.com>
2019-04-28 11:59:52 scheduler.py[line:82] INFO: 发现重复的请求：<GET http://www.douban.com>
2019-04-28 11:59:52 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/2/>
2019-04-28 11:59:52 scheduler.py[line:78] INFO: 添加新的请求: <http://www.baidu.com>
2019-04-28 11:59:52 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/3/>
2019-04-28 11:59:52 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/4/>
2019-04-28 11:59:52 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/5/>
2019-04-28 11:59:52 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/6/>
2019-04-28 11:59:52 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/7/>
2019-04-28 11:59:52 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/8/>
2019-04-28 11:59:52 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/9/>
2019-04-28 11:59:52 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/10/>
2019-04-28 11:59:52 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/11/>
2019-04-28 11:59:52 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/12/>
2019-04-28 11:59:52 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/13/>
2019-04-28 11:59:52 downloader.py[line:26] INFO: <200 http://www.baidu.com/>
2019-04-28 11:59:53 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/1/>
2019-04-28 11:59:53 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121127392>
2019-04-28 11:59:53 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/2/>
2019-04-28 11:59:53 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121161490>
2019-04-28 11:59:53 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/3/>
2019-04-28 11:59:53 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121172241>
2019-04-28 11:59:53 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/5/>
2019-04-28 11:59:53 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/4/>
2019-04-28 11:59:53 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121218989>
2019-04-28 11:59:53 downloader.py[line:26] INFO: <200 https://www.douban.com/>
2019-04-28 11:59:53 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121210843>
2019-04-28 11:59:53 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/6/>
2019-04-28 11:59:53 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121194391>
2019-04-28 11:59:53 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/9/>
2019-04-28 11:59:53 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/8/>
2019-04-28 11:59:53 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121185666>
2019-04-28 11:59:53 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121185708>
2019-04-28 11:59:53 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/7/>
2019-04-28 11:59:53 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121222696>
2019-04-28 11:59:53 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/10/>
2019-04-28 11:59:53 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121224187>
2019-04-28 11:59:53 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/11/>
2019-04-28 11:59:53 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121149728>
2019-04-28 11:59:53 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/12/>
2019-04-28 11:59:53 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/13/>
2019-04-28 11:59:53 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121197472>
2019-04-28 11:59:53 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121195800>
2019-04-28 11:59:53 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121127392>
2019-04-28 11:59:54 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121172241>
2019-04-28 11:59:54 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121161490>
2019-04-28 11:59:54 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121218989>
2019-04-28 11:59:54 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121210843>
2019-04-28 11:59:54 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121194391>
2019-04-28 11:59:54 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121185666>
2019-04-28 11:59:54 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121185708>
2019-04-28 11:59:54 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121222696>
2019-04-28 11:59:54 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121224187>
2019-04-28 11:59:54 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121149728>
2019-04-28 11:59:54 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121197472>
2019-04-28 11:59:54 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121195800>
2019-04-28 12:00:01 scheduler.py[line:46] INFO: 添加不去重的请求: <GET https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2509&k=&num=50&page=1&r=0.4002104982344896&_=1556415569224>
2019-04-28 12:00:02 downloader.py[line:26] INFO: <200 https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2509&k=&num=50&page=1&r=0.4002104982344896&_=1556415569224>
2019-04-28 12:00:11 scheduler.py[line:46] INFO: 添加不去重的请求: <GET https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2509&k=&num=50&page=1&r=0.4002104982344896&_=1556415569224>
2019-04-28 12:00:12 downloader.py[line:26] INFO: <200 https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2509&k=&num=50&page=1&r=0.4002104982344896&_=1556415569224>
2019-04-28 12:00:21 scheduler.py[line:46] INFO: 添加不去重的请求: <GET https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2509&k=&num=50&page=1&r=0.4002104982344896&_=1556415569224>
2019-04-28 12:00:22 downloader.py[line:26] INFO: <200 https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2509&k=&num=50&page=1&r=0.4002104982344896&_=1556415569224>
2019-04-28 12:03:12 engine.py[line:81] INFO: 爬虫启动: 2019-04-28 12:03:12.227355
2019-04-28 12:03:12 engine.py[line:82] INFO: 当前启动的爬虫: ['spiders.baidu.BaiduSpider', 'spiders.qiubai.QiubaiSpider', 'spiders.sina.SinaSpider']
2019-04-28 12:03:12 engine.py[line:83] INFO: 当前开启的管道: ['pipelines.BaiduPipeline', 'pipelines.QiubaiPipeline', 'pipelines.SinaPipeline']
2019-04-28 12:03:12 engine.py[line:84] INFO: 当前开启的下载器中间件: ['spider_middlewares.TestSpiderMiddleware1']
2019-04-28 12:03:12 engine.py[line:85] INFO: 当前开启的爬虫中间件: ['downloader_middlewares.TestDownloaderMiddleware2']
2019-04-28 12:03:13 scheduler.py[line:46] INFO: 添加不去重的请求: <GET https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2509&k=&num=50&page=1&r=0.4002104982344896&_=1556415569224>
2019-04-28 12:03:13 downloader.py[line:26] INFO: <200 https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2509&k=&num=50&page=1&r=0.4002104982344896&_=1556415569224>
2019-04-28 12:03:14 scheduler.py[line:82] INFO: 发现重复的请求：<GET http://www.douban.com>
2019-04-28 12:03:14 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/1/>
2019-04-28 12:03:14 scheduler.py[line:82] INFO: 发现重复的请求：<GET http://www.douban.com>
2019-04-28 12:03:14 scheduler.py[line:82] INFO: 发现重复的请求：<GET http://www.baidu.com>
2019-04-28 12:03:14 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/2/>
2019-04-28 12:03:14 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/3/>
2019-04-28 12:03:14 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/4/>
2019-04-28 12:03:14 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/5/>
2019-04-28 12:03:14 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/6/>
2019-04-28 12:03:14 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/7/>
2019-04-28 12:03:14 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/8/>
2019-04-28 12:03:14 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/9/>
2019-04-28 12:03:14 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/10/>
2019-04-28 12:03:14 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/11/>
2019-04-28 12:03:14 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/12/>
2019-04-28 12:03:14 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/13/>
2019-04-28 12:03:24 scheduler.py[line:46] INFO: 添加不去重的请求: <GET https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2509&k=&num=50&page=1&r=0.4002104982344896&_=1556415569224>
2019-04-28 12:03:24 downloader.py[line:26] INFO: <200 https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2509&k=&num=50&page=1&r=0.4002104982344896&_=1556415569224>
2019-04-28 12:03:34 scheduler.py[line:46] INFO: 添加不去重的请求: <GET https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2509&k=&num=50&page=1&r=0.4002104982344896&_=1556415569224>
2019-04-28 12:03:34 downloader.py[line:26] INFO: <200 https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2509&k=&num=50&page=1&r=0.4002104982344896&_=1556415569224>
2019-04-28 12:07:51 engine.py[line:81] INFO: 爬虫启动: 2019-04-28 12:07:51.134348
2019-04-28 12:07:51 engine.py[line:82] INFO: 当前启动的爬虫: ['spiders.baidu.BaiduSpider', 'spiders.qiubai.QiubaiSpider', 'spiders.sina.SinaSpider']
2019-04-28 12:07:51 engine.py[line:83] INFO: 当前开启的管道: ['pipelines.BaiduPipeline', 'pipelines.QiubaiPipeline', 'pipelines.SinaPipeline']
2019-04-28 12:07:51 engine.py[line:84] INFO: 当前开启的下载器中间件: ['spider_middlewares.TestSpiderMiddleware1']
2019-04-28 12:07:51 engine.py[line:85] INFO: 当前开启的爬虫中间件: ['downloader_middlewares.TestDownloaderMiddleware2']
2019-04-28 12:07:52 scheduler.py[line:46] INFO: 添加不去重的请求: <GET https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2509&k=&num=50&page=1&r=0.4002104982344896&_=1556415569224>
2019-04-28 12:07:52 downloader.py[line:26] INFO: <200 https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2509&k=&num=50&page=1&r=0.4002104982344896&_=1556415569224>
2019-04-28 12:07:52 engine.py[line:197] ERROR: 'dict' object is not callable
Traceback (most recent call last):
  File "D:\David\Desktop\spider_plus_fw\spider_plus\core\engine.py", line 195, in _error_callback
    raise exception  # 抛出异常后, 才能被日志进行完整记录下来
  File "c:\python36\Lib\multiprocessing\pool.py", line 119, in worker
    result = (True, func(*args, **kwds))
  File "D:\David\Desktop\spider_plus_fw\spider_plus\core\engine.py", line 164, in _execute_request_response_item
    for result in parse(response):
  File "D:\David\Desktop\spider_plus_fw\spider_project\spiders\sina.py", line 18, in parse
    for news in response.json().get("result").get("data"):
TypeError: 'dict' object is not callable
2019-04-28 12:07:53 scheduler.py[line:78] INFO: 添加新的请求: <http://www.douban.com>
2019-04-28 12:07:53 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/1/>
2019-04-28 12:07:53 scheduler.py[line:82] INFO: 发现重复的请求：<GET http://www.douban.com>
2019-04-28 12:07:53 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/2/>
2019-04-28 12:07:53 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/3/>
2019-04-28 12:07:53 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/4/>
2019-04-28 12:07:53 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/5/>
2019-04-28 12:07:53 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/6/>
2019-04-28 12:07:53 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/7/>
2019-04-28 12:07:53 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/8/>
2019-04-28 12:07:53 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/9/>
2019-04-28 12:07:53 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/10/>
2019-04-28 12:07:53 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/11/>
2019-04-28 12:07:53 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/12/>
2019-04-28 12:07:53 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/13/>
2019-04-28 12:07:53 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/1/>
2019-04-28 12:07:53 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121183656>
2019-04-28 12:07:53 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/2/>
2019-04-28 12:07:53 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121130278>
2019-04-28 12:07:53 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/3/>
2019-04-28 12:07:53 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121173447>
2019-04-28 12:07:53 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/4/>
2019-04-28 12:07:53 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121168303>
2019-04-28 12:07:53 downloader.py[line:26] INFO: <200 https://www.douban.com/>
2019-04-28 12:07:53 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/5/>
2019-04-28 12:07:53 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121181138>
2019-04-28 12:07:53 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/6/>
2019-04-28 12:07:53 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121147065>
2019-04-28 12:07:53 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/7/>
2019-04-28 12:07:53 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121199019>
2019-04-28 12:07:54 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/8/>
2019-04-28 12:07:54 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121202365>
2019-04-28 12:07:54 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/9/>
2019-04-28 12:07:54 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121154716>
2019-04-28 12:07:54 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/10/>
2019-04-28 12:07:54 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121165116>
2019-04-28 12:07:54 scheduler.py[line:78] INFO: 添加新的请求: <http://www.baidu.com>
2019-04-28 12:07:54 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/11/>
2019-04-28 12:07:54 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121220142>
2019-04-28 12:07:54 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/12/>
2019-04-28 12:07:54 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121160984>
2019-04-28 12:07:54 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/13/>
2019-04-28 12:07:54 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121151289>
2019-04-28 12:07:54 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121183656>
2019-04-28 12:07:54 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121130278>
2019-04-28 12:07:54 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121173447>
2019-04-28 12:07:54 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121168303>
2019-04-28 12:07:54 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121181138>
2019-04-28 12:07:54 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121147065>
2019-04-28 12:07:54 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121199019>
2019-04-28 12:07:54 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121202365>
2019-04-28 12:07:54 downloader.py[line:26] INFO: <200 http://www.baidu.com/>
2019-04-28 12:07:55 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121154716>
2019-04-28 12:07:55 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121165116>
2019-04-28 12:07:55 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121220142>
2019-04-28 12:07:55 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121160984>
2019-04-28 12:07:55 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121151289>
2019-04-28 12:08:03 scheduler.py[line:46] INFO: 添加不去重的请求: <GET https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2509&k=&num=50&page=1&r=0.4002104982344896&_=1556415569224>
2019-04-28 12:08:03 downloader.py[line:26] INFO: <200 https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2509&k=&num=50&page=1&r=0.4002104982344896&_=1556415569224>
2019-04-28 12:08:03 engine.py[line:197] ERROR: 'dict' object is not callable
Traceback (most recent call last):
  File "D:\David\Desktop\spider_plus_fw\spider_plus\core\engine.py", line 195, in _error_callback
    raise exception  # 抛出异常后, 才能被日志进行完整记录下来
  File "c:\python36\Lib\multiprocessing\pool.py", line 119, in worker
    result = (True, func(*args, **kwds))
  File "D:\David\Desktop\spider_plus_fw\spider_plus\core\engine.py", line 164, in _execute_request_response_item
    for result in parse(response):
  File "D:\David\Desktop\spider_plus_fw\spider_project\spiders\sina.py", line 18, in parse
    for news in response.json().get("result").get("data"):
TypeError: 'dict' object is not callable
2019-04-28 12:09:56 engine.py[line:81] INFO: 爬虫启动: 2019-04-28 12:09:56.663349
2019-04-28 12:09:56 engine.py[line:82] INFO: 当前启动的爬虫: ['spiders.baidu.BaiduSpider', 'spiders.qiubai.QiubaiSpider', 'spiders.sina.SinaSpider']
2019-04-28 12:09:56 engine.py[line:83] INFO: 当前开启的管道: ['pipelines.BaiduPipeline', 'pipelines.QiubaiPipeline', 'pipelines.SinaPipeline']
2019-04-28 12:09:56 engine.py[line:84] INFO: 当前开启的下载器中间件: ['spider_middlewares.TestSpiderMiddleware1']
2019-04-28 12:09:56 engine.py[line:85] INFO: 当前开启的爬虫中间件: ['downloader_middlewares.TestDownloaderMiddleware2']
2019-04-28 12:09:57 scheduler.py[line:46] INFO: 添加不去重的请求: <GET https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2509&k=&num=50&page=1&r=0.4002104982344896&_=1556415569224>
2019-04-28 12:09:57 downloader.py[line:26] INFO: <200 https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2509&k=&num=50&page=1&r=0.4002104982344896&_=1556415569224>
2019-04-28 12:09:57 engine.py[line:197] ERROR: 'dict' object is not callable
Traceback (most recent call last):
  File "D:\David\Desktop\spider_plus_fw\spider_plus\core\engine.py", line 195, in _error_callback
    raise exception  # 抛出异常后, 才能被日志进行完整记录下来
  File "c:\python36\Lib\multiprocessing\pool.py", line 119, in worker
    result = (True, func(*args, **kwds))
  File "D:\David\Desktop\spider_plus_fw\spider_plus\core\engine.py", line 164, in _execute_request_response_item
    for result in parse(response):
  File "D:\David\Desktop\spider_plus_fw\spider_project\spiders\sina.py", line 19, in parse
    for news in response.json().get("result").get("data"):
TypeError: 'dict' object is not callable
2019-04-28 12:09:58 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/1/>
2019-04-28 12:09:58 scheduler.py[line:82] INFO: 发现重复的请求：<GET http://www.douban.com>
2019-04-28 12:09:58 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/2/>
2019-04-28 12:09:58 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/3/>
2019-04-28 12:09:58 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/4/>
2019-04-28 12:09:58 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/5/>
2019-04-28 12:09:58 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/6/>
2019-04-28 12:09:58 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/7/>
2019-04-28 12:09:58 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/8/>
2019-04-28 12:09:58 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/9/>
2019-04-28 12:09:58 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/10/>
2019-04-28 12:09:58 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/11/>
2019-04-28 12:09:58 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/12/>
2019-04-28 12:09:58 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/13/>
2019-04-28 12:09:59 scheduler.py[line:82] INFO: 发现重复的请求：<GET http://www.douban.com>
2019-04-28 12:09:59 scheduler.py[line:82] INFO: 发现重复的请求：<GET http://www.baidu.com>
2019-04-28 12:11:41 engine.py[line:81] INFO: 爬虫启动: 2019-04-28 12:11:41.590350
2019-04-28 12:11:41 engine.py[line:82] INFO: 当前启动的爬虫: ['spiders.baidu.BaiduSpider', 'spiders.qiubai.QiubaiSpider', 'spiders.sina.SinaSpider']
2019-04-28 12:11:41 engine.py[line:83] INFO: 当前开启的管道: ['pipelines.BaiduPipeline', 'pipelines.QiubaiPipeline', 'pipelines.SinaPipeline']
2019-04-28 12:11:41 engine.py[line:84] INFO: 当前开启的下载器中间件: ['spider_middlewares.TestSpiderMiddleware1']
2019-04-28 12:11:41 engine.py[line:85] INFO: 当前开启的爬虫中间件: ['downloader_middlewares.TestDownloaderMiddleware2']
2019-04-28 12:11:42 scheduler.py[line:46] INFO: 添加不去重的请求: <GET https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2509&k=&num=50&page=1&r=0.4002104982344896&_=1556415569224>
2019-04-28 12:11:42 downloader.py[line:26] INFO: <200 https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2509&k=&num=50&page=1&r=0.4002104982344896&_=1556415569224>
2019-04-28 12:11:43 scheduler.py[line:82] INFO: 发现重复的请求：<GET http://www.douban.com>
2019-04-28 12:11:43 scheduler.py[line:82] INFO: 发现重复的请求：<GET http://www.douban.com>
2019-04-28 12:11:43 scheduler.py[line:82] INFO: 发现重复的请求：<GET http://www.baidu.com>
2019-04-28 12:11:43 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/1/>
2019-04-28 12:11:43 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/2/>
2019-04-28 12:11:43 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/3/>
2019-04-28 12:11:43 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/4/>
2019-04-28 12:11:43 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/5/>
2019-04-28 12:11:43 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/6/>
2019-04-28 12:11:43 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/7/>
2019-04-28 12:11:43 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/8/>
2019-04-28 12:11:43 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/9/>
2019-04-28 12:11:43 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/10/>
2019-04-28 12:11:43 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/11/>
2019-04-28 12:11:43 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/12/>
2019-04-28 12:11:43 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/13/>
2019-04-28 12:11:53 scheduler.py[line:46] INFO: 添加不去重的请求: <GET https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2509&k=&num=50&page=1&r=0.4002104982344896&_=1556415569224>
2019-04-28 12:11:53 downloader.py[line:26] INFO: <200 https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2509&k=&num=50&page=1&r=0.4002104982344896&_=1556415569224>
2019-04-28 12:12:03 scheduler.py[line:46] INFO: 添加不去重的请求: <GET https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2509&k=&num=50&page=1&r=0.4002104982344896&_=1556415569224>
2019-04-28 12:12:03 downloader.py[line:26] INFO: <200 https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2509&k=&num=50&page=1&r=0.4002104982344896&_=1556415569224>
2019-04-28 12:12:13 scheduler.py[line:46] INFO: 添加不去重的请求: <GET https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2509&k=&num=50&page=1&r=0.4002104982344896&_=1556415569224>
2019-04-28 12:12:13 downloader.py[line:26] INFO: <200 https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2509&k=&num=50&page=1&r=0.4002104982344896&_=1556415569224>
2019-04-28 12:12:23 scheduler.py[line:46] INFO: 添加不去重的请求: <GET https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2509&k=&num=50&page=1&r=0.4002104982344896&_=1556415569224>
2019-04-28 12:12:23 downloader.py[line:26] INFO: <200 https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2509&k=&num=50&page=1&r=0.4002104982344896&_=1556415569224>
2019-04-28 12:23:07 engine.py[line:81] INFO: 爬虫启动: 2019-04-28 12:23:07.500350
2019-04-28 12:23:07 engine.py[line:82] INFO: 当前启动的爬虫: ['spiders.baidu.BaiduSpider', 'spiders.qiubai.QiubaiSpider', 'spiders.sina.SinaSpider']
2019-04-28 12:23:07 engine.py[line:83] INFO: 当前开启的管道: ['pipelines.BaiduPipeline', 'pipelines.QiubaiPipeline', 'pipelines.SinaPipeline']
2019-04-28 12:23:07 engine.py[line:84] INFO: 当前开启的下载器中间件: ['spider_middlewares.TestSpiderMiddleware1']
2019-04-28 12:23:07 engine.py[line:85] INFO: 当前开启的爬虫中间件: ['downloader_middlewares.TestDownloaderMiddleware2']
2019-04-28 12:23:08 scheduler.py[line:46] INFO: 添加不去重的请求: <GET https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2509&k=&num=50&page=1&r=0.4002104982344896&_=1556415569224>
2019-04-28 12:23:08 downloader.py[line:26] INFO: <200 https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2509&k=&num=50&page=1&r=0.4002104982344896&_=1556415569224>
2019-04-28 12:23:09 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/1/>
2019-04-28 12:23:09 scheduler.py[line:82] INFO: 发现重复的请求：<GET http://www.douban.com>
2019-04-28 12:23:09 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/2/>
2019-04-28 12:23:09 scheduler.py[line:82] INFO: 发现重复的请求：<GET http://www.douban.com>
2019-04-28 12:23:09 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/3/>
2019-04-28 12:23:09 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/4/>
2019-04-28 12:23:09 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/5/>
2019-04-28 12:23:09 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/6/>
2019-04-28 12:23:09 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/7/>
2019-04-28 12:23:09 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/8/>
2019-04-28 12:23:09 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/9/>
2019-04-28 12:23:09 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/10/>
2019-04-28 12:23:09 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/11/>
2019-04-28 12:23:09 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/12/>
2019-04-28 12:23:09 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/13/>
2019-04-28 12:23:10 scheduler.py[line:82] INFO: 发现重复的请求：<GET http://www.baidu.com>
2019-04-28 12:23:18 scheduler.py[line:46] INFO: 添加不去重的请求: <GET https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2509&k=&num=50&page=1&r=0.4002104982344896&_=1556415569224>
2019-04-28 12:23:18 downloader.py[line:26] INFO: <200 https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2509&k=&num=50&page=1&r=0.4002104982344896&_=1556415569224>
2019-04-28 12:23:28 scheduler.py[line:46] INFO: 添加不去重的请求: <GET https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2509&k=&num=50&page=1&r=0.4002104982344896&_=1556415569224>
2019-04-28 12:23:28 downloader.py[line:26] INFO: <200 https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2509&k=&num=50&page=1&r=0.4002104982344896&_=1556415569224>
2019-04-28 16:11:39 engine.py[line:81] INFO: 爬虫启动: 2019-04-28 16:11:39.855358
2019-04-28 16:11:39 engine.py[line:82] INFO: 当前启动的爬虫: ['spiders.baidu.BaiduSpider', 'spiders.qiubai.QiubaiSpider', 'spiders.sina.SinaSpider']
2019-04-28 16:11:39 engine.py[line:83] INFO: 当前开启的管道: ['pipelines.BaiduPipeline', 'pipelines.QiubaiPipeline', 'pipelines.SinaPipeline']
2019-04-28 16:11:39 engine.py[line:84] INFO: 当前开启的下载器中间件: ['spider_middlewares.TestSpiderMiddleware1']
2019-04-28 16:11:39 engine.py[line:85] INFO: 当前开启的爬虫中间件: ['downloader_middlewares.TestDownloaderMiddleware2']
2019-04-28 16:11:40 scheduler.py[line:46] INFO: 添加不去重的请求: <GET https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2509&k=&num=50&page=1&r=0.4002104982344896&_=1556415569224>
2019-04-28 16:11:41 downloader.py[line:26] INFO: <200 https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2509&k=&num=50&page=1&r=0.4002104982344896&_=1556415569224>
2019-04-28 16:11:41 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/1/>
2019-04-28 16:11:41 scheduler.py[line:78] INFO: 添加新的请求: <http://www.douban.com>
2019-04-28 16:11:41 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/2/>
2019-04-28 16:11:41 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/3/>
2019-04-28 16:11:41 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/4/>
2019-04-28 16:11:41 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/5/>
2019-04-28 16:11:41 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/6/>
2019-04-28 16:11:41 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/7/>
2019-04-28 16:11:41 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/8/>
2019-04-28 16:11:41 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/9/>
2019-04-28 16:11:41 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/10/>
2019-04-28 16:11:41 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/11/>
2019-04-28 16:11:41 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/12/>
2019-04-28 16:11:41 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/13/>
2019-04-28 16:11:42 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/1/>
2019-04-28 16:11:42 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/2/>
2019-04-28 16:11:42 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121170850>
2019-04-28 16:11:42 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121151292>
2019-04-28 16:11:42 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/3/>
2019-04-28 16:11:42 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121179654>
2019-04-28 16:11:42 downloader.py[line:26] INFO: <200 https://www.douban.com/>
2019-04-28 16:11:42 scheduler.py[line:82] INFO: 发现重复的请求：<GET http://www.douban.com>
2019-04-28 16:11:42 scheduler.py[line:78] INFO: 添加新的请求: <http://www.baidu.com>
2019-04-28 16:11:43 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/6/>
2019-04-28 16:11:43 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121183962>
2019-04-28 16:11:43 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/8/>
2019-04-28 16:11:43 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121194121>
2019-04-28 16:11:44 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/4/>
2019-04-28 16:11:44 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121176182>
2019-04-28 16:11:44 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/7/>
2019-04-28 16:11:44 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121212593>
2019-04-28 16:11:44 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/10/>
2019-04-28 16:11:44 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/9/>
2019-04-28 16:11:44 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121174508>
2019-04-28 16:11:44 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121219576>
2019-04-28 16:11:44 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/11/>
2019-04-28 16:11:44 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121174694>
2019-04-28 16:11:44 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/13/>
2019-04-28 16:11:44 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121208483>
2019-04-28 16:11:44 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/12/>
2019-04-28 16:11:44 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121171047>
2019-04-28 16:11:46 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/5/>
2019-04-28 16:11:46 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121183719>
2019-04-28 16:11:46 downloader.py[line:26] INFO: <200 http://www.baidu.com/>
2019-04-28 16:11:50 scheduler.py[line:46] INFO: 添加不去重的请求: <GET https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2509&k=&num=50&page=1&r=0.4002104982344896&_=1556415569224>
2019-04-28 16:12:00 scheduler.py[line:46] INFO: 添加不去重的请求: <GET https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2509&k=&num=50&page=1&r=0.4002104982344896&_=1556415569224>
2019-04-28 16:12:10 scheduler.py[line:46] INFO: 添加不去重的请求: <GET https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2509&k=&num=50&page=1&r=0.4002104982344896&_=1556415569224>
2019-04-28 16:12:20 scheduler.py[line:46] INFO: 添加不去重的请求: <GET https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2509&k=&num=50&page=1&r=0.4002104982344896&_=1556415569224>
2019-04-28 16:17:19 engine.py[line:81] INFO: 爬虫启动: 2019-04-28 16:17:19.260015
2019-04-28 16:17:19 engine.py[line:82] INFO: 当前启动的爬虫: ['spiders.baidu.BaiduSpider', 'spiders.qiubai.QiubaiSpider', 'spiders.sina.SinaSpider']
2019-04-28 16:17:19 engine.py[line:83] INFO: 当前开启的管道: ['pipelines.BaiduPipeline', 'pipelines.QiubaiPipeline', 'pipelines.SinaPipeline']
2019-04-28 16:17:19 engine.py[line:84] INFO: 当前开启的下载器中间件: ['spider_middlewares.TestSpiderMiddleware1']
2019-04-28 16:17:19 engine.py[line:85] INFO: 当前开启的爬虫中间件: ['downloader_middlewares.TestDownloaderMiddleware2']
2019-04-28 16:17:20 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121212593>
2019-04-28 16:17:20 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121176182>
2019-04-28 16:17:20 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121194121>
2019-04-28 16:17:20 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121174508>
2019-04-28 16:17:20 scheduler.py[line:46] INFO: 添加不去重的请求: <GET https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2509&k=&num=50&page=1&r=0.4002104982344896&_=1556415569224>
2019-04-28 16:17:20 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121219576>
2019-04-28 16:17:21 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121174694>
2019-04-28 16:17:21 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121208483>
2019-04-28 16:17:21 scheduler.py[line:82] INFO: 发现重复的请求：<GET http://www.douban.com>
2019-04-28 16:17:21 scheduler.py[line:82] INFO: 发现重复的请求：<GET http://www.douban.com>
2019-04-28 16:17:21 scheduler.py[line:82] INFO: 发现重复的请求：<GET http://www.baidu.com>
2019-04-28 16:17:21 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/1/>
2019-04-28 16:17:21 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/2/>
2019-04-28 16:17:21 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/3/>
2019-04-28 16:17:21 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/4/>
2019-04-28 16:17:21 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/5/>
2019-04-28 16:17:21 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/6/>
2019-04-28 16:17:21 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/7/>
2019-04-28 16:17:21 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/8/>
2019-04-28 16:17:21 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/9/>
2019-04-28 16:17:21 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/10/>
2019-04-28 16:17:21 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/11/>
2019-04-28 16:17:21 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/12/>
2019-04-28 16:17:21 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/13/>
2019-04-28 16:17:21 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121171047>
2019-04-28 16:17:21 downloader.py[line:26] INFO: <200 https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2509&k=&num=50&page=1&r=0.4002104982344896&_=1556415569224>
2019-04-28 16:17:21 engine.py[line:197] ERROR: 'NoneType' object has no attribute 'parse'
Traceback (most recent call last):
  File "D:\David\Desktop\spider_plus_fw\spider_plus\core\engine.py", line 195, in _error_callback
    raise exception  # 抛出异常后, 才能被日志进行完整记录下来
  File "c:\python36\Lib\multiprocessing\pool.py", line 119, in worker
    result = (True, func(*args, **kwds))
  File "D:\David\Desktop\spider_plus_fw\spider_plus\core\engine.py", line 160, in _execute_request_response_item
    parse = getattr(spider, request.parse)
AttributeError: 'NoneType' object has no attribute 'parse'
2019-04-28 16:17:21 downloader.py[line:26] INFO: <200 https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2509&k=&num=50&page=1&r=0.4002104982344896&_=1556415569224>
2019-04-28 16:17:21 engine.py[line:197] ERROR: 'NoneType' object has no attribute 'parse'
Traceback (most recent call last):
  File "D:\David\Desktop\spider_plus_fw\spider_plus\core\engine.py", line 195, in _error_callback
    raise exception  # 抛出异常后, 才能被日志进行完整记录下来
  File "c:\python36\Lib\multiprocessing\pool.py", line 119, in worker
    result = (True, func(*args, **kwds))
  File "D:\David\Desktop\spider_plus_fw\spider_plus\core\engine.py", line 160, in _execute_request_response_item
    parse = getattr(spider, request.parse)
AttributeError: 'NoneType' object has no attribute 'parse'
2019-04-28 16:17:22 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121183719>
2019-04-28 16:17:22 downloader.py[line:26] INFO: <200 https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2509&k=&num=50&page=1&r=0.4002104982344896&_=1556415569224>
2019-04-28 16:17:22 engine.py[line:197] ERROR: 'NoneType' object has no attribute 'parse'
Traceback (most recent call last):
  File "D:\David\Desktop\spider_plus_fw\spider_plus\core\engine.py", line 195, in _error_callback
    raise exception  # 抛出异常后, 才能被日志进行完整记录下来
  File "c:\python36\Lib\multiprocessing\pool.py", line 119, in worker
    result = (True, func(*args, **kwds))
  File "D:\David\Desktop\spider_plus_fw\spider_plus\core\engine.py", line 160, in _execute_request_response_item
    parse = getattr(spider, request.parse)
AttributeError: 'NoneType' object has no attribute 'parse'
2019-04-28 16:17:22 downloader.py[line:26] INFO: <200 https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2509&k=&num=50&page=1&r=0.4002104982344896&_=1556415569224>
2019-04-28 16:17:22 engine.py[line:197] ERROR: 'NoneType' object has no attribute 'parse'
Traceback (most recent call last):
  File "D:\David\Desktop\spider_plus_fw\spider_plus\core\engine.py", line 195, in _error_callback
    raise exception  # 抛出异常后, 才能被日志进行完整记录下来
  File "c:\python36\Lib\multiprocessing\pool.py", line 119, in worker
    result = (True, func(*args, **kwds))
  File "D:\David\Desktop\spider_plus_fw\spider_plus\core\engine.py", line 160, in _execute_request_response_item
    parse = getattr(spider, request.parse)
AttributeError: 'NoneType' object has no attribute 'parse'
2019-04-28 16:17:22 downloader.py[line:26] INFO: <200 https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2509&k=&num=50&page=1&r=0.4002104982344896&_=1556415569224>
2019-04-28 16:17:30 scheduler.py[line:46] INFO: 添加不去重的请求: <GET https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2509&k=&num=50&page=1&r=0.4002104982344896&_=1556415569224>
2019-04-28 16:17:30 downloader.py[line:26] INFO: <200 https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2509&k=&num=50&page=1&r=0.4002104982344896&_=1556415569224>
2019-04-28 16:18:15 engine.py[line:81] INFO: 爬虫启动: 2019-04-28 16:18:15.355016
2019-04-28 16:18:15 engine.py[line:82] INFO: 当前启动的爬虫: ['spiders.baidu.BaiduSpider', 'spiders.qiubai.QiubaiSpider', 'spiders.sina.SinaSpider']
2019-04-28 16:18:15 engine.py[line:83] INFO: 当前开启的管道: ['pipelines.BaiduPipeline', 'pipelines.QiubaiPipeline', 'pipelines.SinaPipeline']
2019-04-28 16:18:15 engine.py[line:84] INFO: 当前开启的下载器中间件: ['spider_middlewares.TestSpiderMiddleware1']
2019-04-28 16:18:15 engine.py[line:85] INFO: 当前开启的爬虫中间件: ['downloader_middlewares.TestDownloaderMiddleware2']
2019-04-28 16:18:16 scheduler.py[line:46] INFO: 添加不去重的请求: <GET https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2509&k=&num=50&page=1&r=0.4002104982344896&_=1556415569224>
2019-04-28 16:18:16 downloader.py[line:26] INFO: <200 https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2509&k=&num=50&page=1&r=0.4002104982344896&_=1556415569224>
2019-04-28 16:18:17 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/1/>
2019-04-28 16:18:17 scheduler.py[line:82] INFO: 发现重复的请求：<GET http://www.douban.com>
2019-04-28 16:18:17 scheduler.py[line:82] INFO: 发现重复的请求：<GET http://www.douban.com>
2019-04-28 16:18:17 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/2/>
2019-04-28 16:18:17 scheduler.py[line:82] INFO: 发现重复的请求：<GET http://www.baidu.com>
2019-04-28 16:18:17 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/3/>
2019-04-28 16:18:18 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/4/>
2019-04-28 16:18:18 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/5/>
2019-04-28 16:18:18 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/6/>
2019-04-28 16:18:18 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/7/>
2019-04-28 16:18:18 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/8/>
2019-04-28 16:18:18 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/9/>
2019-04-28 16:18:18 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/10/>
2019-04-28 16:18:18 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/11/>
2019-04-28 16:18:18 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/12/>
2019-04-28 16:18:18 scheduler.py[line:82] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/13/>
2019-04-28 16:18:26 scheduler.py[line:46] INFO: 添加不去重的请求: <GET https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2509&k=&num=50&page=1&r=0.4002104982344896&_=1556415569224>
2019-04-28 16:18:36 scheduler.py[line:46] INFO: 添加不去重的请求: <GET https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2509&k=&num=50&page=1&r=0.4002104982344896&_=1556415569224>
2019-04-28 16:18:46 scheduler.py[line:46] INFO: 添加不去重的请求: <GET https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2509&k=&num=50&page=1&r=0.4002104982344896&_=1556415569224>
2019-04-28 16:18:56 scheduler.py[line:46] INFO: 添加不去重的请求: <GET https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2509&k=&num=50&page=1&r=0.4002104982344896&_=1556415569224>
2019-04-28 16:19:21 engine.py[line:81] INFO: 爬虫启动: 2019-04-28 16:19:21.307015
2019-04-28 16:19:21 engine.py[line:82] INFO: 当前启动的爬虫: ['spiders.baidu.BaiduSpider', 'spiders.qiubai.QiubaiSpider', 'spiders.sina.SinaSpider']
2019-04-28 16:19:21 engine.py[line:83] INFO: 当前开启的管道: ['pipelines.BaiduPipeline', 'pipelines.QiubaiPipeline', 'pipelines.SinaPipeline']
2019-04-28 16:19:21 engine.py[line:84] INFO: 当前开启的下载器中间件: ['spider_middlewares.TestSpiderMiddleware1']
2019-04-28 16:19:21 engine.py[line:85] INFO: 当前开启的爬虫中间件: ['downloader_middlewares.TestDownloaderMiddleware2']
2019-04-28 16:19:22 scheduler.py[line:46] INFO: 添加不去重的请求: <GET https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2509&k=&num=50&page=1&r=0.4002104982344896&_=1556415569224>
2019-04-28 16:19:22 downloader.py[line:26] INFO: <200 https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2509&k=&num=50&page=1&r=0.4002104982344896&_=1556415569224>
2019-04-28 16:19:23 scheduler.py[line:78] INFO: 添加新的请求: <http://www.douban.com>
2019-04-28 16:19:23 scheduler.py[line:82] INFO: 发现重复的请求：<GET http://www.douban.com>
2019-04-28 16:19:23 scheduler.py[line:78] INFO: 添加新的请求: <http://www.baidu.com>
2019-04-28 16:19:23 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/1/>
2019-04-28 16:19:23 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/2/>
2019-04-28 16:19:23 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/3/>
2019-04-28 16:19:23 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/4/>
2019-04-28 16:19:23 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/5/>
2019-04-28 16:19:23 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/6/>
2019-04-28 16:19:23 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/7/>
2019-04-28 16:19:23 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/8/>
2019-04-28 16:19:23 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/9/>
2019-04-28 16:19:23 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/10/>
2019-04-28 16:19:23 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/11/>
2019-04-28 16:19:23 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/12/>
2019-04-28 16:19:23 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/13/>
2019-04-28 16:19:23 downloader.py[line:26] INFO: <200 http://www.baidu.com/>
2019-04-28 16:19:23 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/1/>
2019-04-28 16:19:23 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121170850>
2019-04-28 16:19:23 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/2/>
2019-04-28 16:19:23 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121151292>
2019-04-28 16:19:23 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/3/>
2019-04-28 16:19:23 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121179654>
2019-04-28 16:19:23 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/4/>
2019-04-28 16:19:23 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121176182>
2019-04-28 16:19:23 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/5/>
2019-04-28 16:19:23 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121183719>
2019-04-28 16:19:23 downloader.py[line:26] INFO: <200 https://www.douban.com/>
2019-04-28 16:19:24 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/6/>
2019-04-28 16:19:24 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121183962>
2019-04-28 16:19:24 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/7/>
2019-04-28 16:19:24 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121212593>
2019-04-28 16:19:24 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/8/>
2019-04-28 16:19:24 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121194121>
2019-04-28 16:19:24 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/9/>
2019-04-28 16:19:24 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121219576>
2019-04-28 16:19:24 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/10/>
2019-04-28 16:19:24 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121174508>
2019-04-28 16:19:24 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/11/>
2019-04-28 16:19:24 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121174694>
2019-04-28 16:19:24 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/12/>
2019-04-28 16:19:24 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121171047>
2019-04-28 16:19:24 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/13/>
2019-04-28 16:19:24 scheduler.py[line:78] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121208483>
2019-04-28 16:19:24 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121170850>
2019-04-28 16:19:24 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121151292>
2019-04-28 16:19:24 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121179654>
2019-04-28 16:19:24 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121176182>
2019-04-28 16:19:24 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121183719>
2019-04-28 16:19:25 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121183962>
2019-04-28 16:19:25 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121212593>
2019-04-28 16:19:25 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121194121>
2019-04-28 16:19:25 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121219576>
2019-04-28 16:19:25 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121174508>
2019-04-28 16:19:25 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121174694>
2019-04-28 16:19:25 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121171047>
2019-04-28 16:19:25 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121208483>
2019-04-28 16:19:33 scheduler.py[line:46] INFO: 添加不去重的请求: <GET https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2509&k=&num=50&page=1&r=0.4002104982344896&_=1556415569224>
2019-04-28 16:19:33 downloader.py[line:26] INFO: <200 https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2509&k=&num=50&page=1&r=0.4002104982344896&_=1556415569224>
2019-04-28 16:19:43 scheduler.py[line:46] INFO: 添加不去重的请求: <GET https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2509&k=&num=50&page=1&r=0.4002104982344896&_=1556415569224>
2019-04-28 16:19:43 downloader.py[line:26] INFO: <200 https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2509&k=&num=50&page=1&r=0.4002104982344896&_=1556415569224>
2019-04-28 16:19:53 scheduler.py[line:46] INFO: 添加不去重的请求: <GET https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2509&k=&num=50&page=1&r=0.4002104982344896&_=1556415569224>
2019-04-28 16:19:53 downloader.py[line:26] INFO: <200 https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2509&k=&num=50&page=1&r=0.4002104982344896&_=1556415569224>
2019-04-28 16:20:03 scheduler.py[line:46] INFO: 添加不去重的请求: <GET https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2509&k=&num=50&page=1&r=0.4002104982344896&_=1556415569224>
2019-04-28 16:20:03 downloader.py[line:26] INFO: <200 https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2509&k=&num=50&page=1&r=0.4002104982344896&_=1556415569224>
2019-04-28 16:20:13 scheduler.py[line:46] INFO: 添加不去重的请求: <GET https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2509&k=&num=50&page=1&r=0.4002104982344896&_=1556415569224>
2019-04-28 16:20:13 downloader.py[line:26] INFO: <200 https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2509&k=&num=50&page=1&r=0.4002104982344896&_=1556415569224>
2019-04-28 16:20:23 scheduler.py[line:46] INFO: 添加不去重的请求: <GET https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2509&k=&num=50&page=1&r=0.4002104982344896&_=1556415569224>
2019-04-28 16:20:23 downloader.py[line:26] INFO: <200 https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2509&k=&num=50&page=1&r=0.4002104982344896&_=1556415569224>
2019-04-28 17:24:24 engine.py[line:81] INFO: 爬虫启动: 2019-04-28 17:24:24.471810
2019-04-28 17:24:24 engine.py[line:82] INFO: 当前启动的爬虫: ['spiders.baidu.BaiduSpider', 'spiders.qiubai.QiubaiSpider', 'spiders.sina.SinaSpider']
2019-04-28 17:24:24 engine.py[line:83] INFO: 当前开启的管道: ['pipelines.BaiduPipeline', 'pipelines.QiubaiPipeline', 'pipelines.SinaPipeline']
2019-04-28 17:24:24 engine.py[line:84] INFO: 当前开启的下载器中间件: ['spider_middlewares.TestSpiderMiddleware1']
2019-04-28 17:24:24 engine.py[line:85] INFO: 当前开启的爬虫中间件: ['downloader_middlewares.TestDownloaderMiddleware2']
2019-04-28 17:24:25 scheduler.py[line:48] INFO: 添加不去重的请求: <GET https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2509&k=&num=50&page=1&r=0.4002104982344896&_=1556415569224>
2019-04-28 17:24:25 downloader.py[line:26] INFO: <200 https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2509&k=&num=50&page=1&r=0.4002104982344896&_=1556415569224>
2019-04-28 17:24:26 scheduler.py[line:109] INFO: 发现重复的请求：<GET http://www.douban.com>
2019-04-28 17:24:26 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/1/>
2019-04-28 17:24:26 scheduler.py[line:109] INFO: 发现重复的请求：<GET http://www.douban.com>
2019-04-28 17:24:26 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/2/>
2019-04-28 17:24:26 scheduler.py[line:109] INFO: 发现重复的请求：<GET http://www.baidu.com>
2019-04-28 17:24:26 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/3/>
2019-04-28 17:24:26 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/4/>
2019-04-28 17:24:26 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/5/>
2019-04-28 17:24:26 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/6/>
2019-04-28 17:24:26 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/7/>
2019-04-28 17:24:26 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/8/>
2019-04-28 17:24:26 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/9/>
2019-04-28 17:24:26 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/10/>
2019-04-28 17:24:26 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/11/>
2019-04-28 17:24:26 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/12/>
2019-04-28 17:24:26 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/13/>
2019-04-28 17:31:45 engine.py[line:81] INFO: 爬虫启动: 2019-04-28 17:31:45.165577
2019-04-28 17:31:45 engine.py[line:82] INFO: 当前启动的爬虫: ['spiders.baidu.BaiduSpider', 'spiders.qiubai.QiubaiSpider', 'spiders.sina.SinaSpider']
2019-04-28 17:31:45 engine.py[line:83] INFO: 当前开启的管道: ['pipelines.BaiduPipeline', 'pipelines.QiubaiPipeline', 'pipelines.SinaPipeline']
2019-04-28 17:31:45 engine.py[line:84] INFO: 当前开启的下载器中间件: ['spider_middlewares.TestSpiderMiddleware1']
2019-04-28 17:31:45 engine.py[line:85] INFO: 当前开启的爬虫中间件: ['downloader_middlewares.TestDownloaderMiddleware2']
2019-04-28 17:31:46 scheduler.py[line:48] INFO: 添加不去重的请求: <GET https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2509&k=&num=50&page=1&r=0.4002104982344896&_=1556415569224>
2019-04-28 17:31:46 downloader.py[line:26] INFO: <200 https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2509&k=&num=50&page=1&r=0.4002104982344896&_=1556415569224>
2019-04-28 17:31:47 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/1/>
2019-04-28 17:31:47 scheduler.py[line:109] INFO: 发现重复的请求：<GET http://www.douban.com>
2019-04-28 17:31:47 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/2/>
2019-04-28 17:31:47 scheduler.py[line:109] INFO: 发现重复的请求：<GET http://www.douban.com>
2019-04-28 17:31:47 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/3/>
2019-04-28 17:31:47 scheduler.py[line:109] INFO: 发现重复的请求：<GET http://www.baidu.com>
2019-04-28 17:31:47 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/4/>
2019-04-28 17:31:47 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/5/>
2019-04-28 17:31:47 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/6/>
2019-04-28 17:31:47 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/7/>
2019-04-28 17:31:47 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/8/>
2019-04-28 17:31:47 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/9/>
2019-04-28 17:31:47 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/10/>
2019-04-28 17:31:47 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/11/>
2019-04-28 17:31:47 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/12/>
2019-04-28 17:31:47 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/13/>
2019-04-28 17:31:56 scheduler.py[line:48] INFO: 添加不去重的请求: <GET https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2509&k=&num=50&page=1&r=0.4002104982344896&_=1556415569224>
2019-04-28 17:31:56 downloader.py[line:26] INFO: <200 https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2509&k=&num=50&page=1&r=0.4002104982344896&_=1556415569224>
2019-04-28 17:32:47 engine.py[line:81] INFO: 爬虫启动: 2019-04-28 17:32:47.896583
2019-04-28 17:32:47 engine.py[line:82] INFO: 当前启动的爬虫: ['spiders.baidu.BaiduSpider', 'spiders.qiubai.QiubaiSpider', 'spiders.sina.SinaSpider']
2019-04-28 17:32:47 engine.py[line:83] INFO: 当前开启的管道: ['pipelines.BaiduPipeline', 'pipelines.QiubaiPipeline', 'pipelines.SinaPipeline']
2019-04-28 17:32:47 engine.py[line:84] INFO: 当前开启的下载器中间件: ['spider_middlewares.TestSpiderMiddleware1']
2019-04-28 17:32:47 engine.py[line:85] INFO: 当前开启的爬虫中间件: ['downloader_middlewares.TestDownloaderMiddleware2']
2019-04-28 17:32:48 scheduler.py[line:48] INFO: 添加不去重的请求: <GET https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2509&k=&num=50&page=1&r=0.4002104982344896&_=1556415569224>
2019-04-28 17:32:49 downloader.py[line:26] INFO: <200 https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2509&k=&num=50&page=1&r=0.4002104982344896&_=1556415569224>
2019-04-28 17:32:49 scheduler.py[line:105] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/1/>
2019-04-28 17:32:49 scheduler.py[line:105] INFO: 添加新的请求: <http://www.douban.com>
2019-04-28 17:32:49 scheduler.py[line:105] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/2/>
2019-04-28 17:32:49 scheduler.py[line:109] INFO: 发现重复的请求：<GET http://www.douban.com>
2019-04-28 17:32:49 scheduler.py[line:105] INFO: 添加新的请求: <http://www.baidu.com>
2019-04-28 17:32:49 scheduler.py[line:105] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/3/>
2019-04-28 17:32:49 scheduler.py[line:105] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/4/>
2019-04-28 17:32:49 scheduler.py[line:105] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/5/>
2019-04-28 17:32:49 scheduler.py[line:105] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/6/>
2019-04-28 17:32:49 scheduler.py[line:105] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/7/>
2019-04-28 17:32:49 scheduler.py[line:105] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/8/>
2019-04-28 17:32:49 scheduler.py[line:105] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/9/>
2019-04-28 17:32:49 scheduler.py[line:105] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/10/>
2019-04-28 17:32:49 scheduler.py[line:105] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/11/>
2019-04-28 17:32:49 scheduler.py[line:105] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/12/>
2019-04-28 17:32:49 scheduler.py[line:105] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/13/>
2019-04-28 17:32:51 downloader.py[line:26] INFO: <200 http://www.baidu.com/>
2019-04-28 17:32:51 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/3/>
2019-04-28 17:32:51 scheduler.py[line:105] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121178129>
2019-04-28 17:32:51 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/2/>
2019-04-28 17:32:51 scheduler.py[line:105] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121206563>
2019-04-28 17:32:51 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/1/>
2019-04-28 17:32:51 scheduler.py[line:105] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121195323>
2019-04-28 17:32:51 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/4/>
2019-04-28 17:32:51 scheduler.py[line:105] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121140722>
2019-04-28 17:32:51 downloader.py[line:26] INFO: <200 https://www.douban.com/>
2019-04-28 17:32:51 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/5/>
2019-04-28 17:32:51 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/6/>
2019-04-28 17:32:51 scheduler.py[line:105] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121212672>
2019-04-28 17:32:51 scheduler.py[line:105] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121177356>
2019-04-28 17:32:51 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/7/>
2019-04-28 17:32:51 scheduler.py[line:105] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121186328>
2019-04-28 17:32:51 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/8/>
2019-04-28 17:32:51 scheduler.py[line:105] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121183420>
2019-04-28 17:32:51 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/9/>
2019-04-28 17:32:51 scheduler.py[line:105] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121221680>
2019-04-28 17:32:51 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/10/>
2019-04-28 17:32:51 scheduler.py[line:105] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121220205>
2019-04-28 17:32:51 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/11/>
2019-04-28 17:32:51 scheduler.py[line:105] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121143665>
2019-04-28 17:32:51 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/12/>
2019-04-28 17:32:51 scheduler.py[line:105] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121195815>
2019-04-28 17:32:51 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/13/>
2019-04-28 17:32:51 scheduler.py[line:105] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121186379>
2019-04-28 17:32:51 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121206563>
2019-04-28 17:32:51 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121195323>
2019-04-28 17:32:52 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121178129>
2019-04-28 17:32:52 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121140722>
2019-04-28 17:32:52 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121212672>
2019-04-28 17:32:52 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121177356>
2019-04-28 17:32:52 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121186328>
2019-04-28 17:32:52 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121221680>
2019-04-28 17:32:52 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121183420>
2019-04-28 17:32:52 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121220205>
2019-04-28 17:32:52 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121143665>
2019-04-28 17:32:52 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121195815>
2019-04-28 17:32:52 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121186379>
2019-04-28 17:32:52 downloader.py[line:26] INFO: <200 http://www.baidu.com/>
2019-04-28 17:33:30 engine.py[line:81] INFO: 爬虫启动: 2019-04-28 17:33:30.273575
2019-04-28 17:33:30 engine.py[line:82] INFO: 当前启动的爬虫: ['spiders.baidu.BaiduSpider', 'spiders.qiubai.QiubaiSpider', 'spiders.sina.SinaSpider']
2019-04-28 17:33:30 engine.py[line:83] INFO: 当前开启的管道: ['pipelines.BaiduPipeline', 'pipelines.QiubaiPipeline', 'pipelines.SinaPipeline']
2019-04-28 17:33:30 engine.py[line:84] INFO: 当前开启的下载器中间件: ['spider_middlewares.TestSpiderMiddleware1']
2019-04-28 17:33:30 engine.py[line:85] INFO: 当前开启的爬虫中间件: ['downloader_middlewares.TestDownloaderMiddleware2']
2019-04-28 17:33:31 scheduler.py[line:48] INFO: 添加不去重的请求: <GET https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2509&k=&num=50&page=1&r=0.4002104982344896&_=1556415569224>
2019-04-28 17:33:31 downloader.py[line:26] INFO: <200 https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2509&k=&num=50&page=1&r=0.4002104982344896&_=1556415569224>
2019-04-28 17:33:32 scheduler.py[line:105] INFO: 添加新的请求: <http://www.douban.com>
2019-04-28 17:33:32 scheduler.py[line:105] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/1/>
2019-04-28 17:33:32 scheduler.py[line:109] INFO: 发现重复的请求：<GET http://www.douban.com>
2019-04-28 17:33:32 scheduler.py[line:105] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/2/>
2019-04-28 17:33:32 scheduler.py[line:105] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/3/>
2019-04-28 17:33:32 scheduler.py[line:105] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/4/>
2019-04-28 17:33:32 scheduler.py[line:105] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/5/>
2019-04-28 17:33:32 scheduler.py[line:105] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/6/>
2019-04-28 17:33:32 scheduler.py[line:105] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/7/>
2019-04-28 17:33:32 scheduler.py[line:105] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/8/>
2019-04-28 17:33:32 scheduler.py[line:105] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/9/>
2019-04-28 17:33:32 scheduler.py[line:105] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/10/>
2019-04-28 17:33:32 scheduler.py[line:105] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/11/>
2019-04-28 17:33:32 scheduler.py[line:105] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/12/>
2019-04-28 17:33:32 scheduler.py[line:105] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/13/>
2019-04-28 17:33:33 scheduler.py[line:105] INFO: 添加新的请求: <http://www.baidu.com>
2019-04-28 17:33:33 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/4/>
2019-04-28 17:33:33 scheduler.py[line:105] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121140722>
2019-04-28 17:33:33 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/2/>
2019-04-28 17:33:33 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/3/>
2019-04-28 17:33:33 scheduler.py[line:105] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121206563>
2019-04-28 17:33:33 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/1/>
2019-04-28 17:33:33 scheduler.py[line:105] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121178129>
2019-04-28 17:33:33 scheduler.py[line:105] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121195323>
2019-04-28 17:33:33 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/6/>
2019-04-28 17:33:33 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/5/>
2019-04-28 17:33:33 scheduler.py[line:105] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121177356>
2019-04-28 17:33:33 scheduler.py[line:105] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121212672>
2019-04-28 17:33:33 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/8/>
2019-04-28 17:33:33 scheduler.py[line:105] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121183420>
2019-04-28 17:33:33 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/7/>
2019-04-28 17:33:33 scheduler.py[line:105] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121186328>
2019-04-28 17:33:33 downloader.py[line:26] INFO: <200 https://www.douban.com/>
2019-04-28 17:33:34 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/9/>
2019-04-28 17:33:34 scheduler.py[line:105] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121221680>
2019-04-28 17:33:34 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/10/>
2019-04-28 17:33:34 scheduler.py[line:105] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121220205>
2019-04-28 17:33:34 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/11/>
2019-04-28 17:33:34 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/12/>
2019-04-28 17:33:34 scheduler.py[line:105] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121143665>
2019-04-28 17:33:34 scheduler.py[line:105] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121195815>
2019-04-28 17:33:34 downloader.py[line:26] INFO: <200 http://www.baidu.com/>
2019-04-28 17:33:34 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/13/>
2019-04-28 17:33:34 scheduler.py[line:105] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121186379>
2019-04-28 17:33:34 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121140722>
2019-04-28 17:33:34 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121206563>
2019-04-28 17:33:34 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121178129>
2019-04-28 17:33:34 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121177356>
2019-04-28 17:33:34 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121195323>
2019-04-28 17:33:34 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121212672>
2019-04-28 17:33:34 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121183420>
2019-04-28 17:33:34 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121186328>
2019-04-28 17:33:34 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121221680>
2019-04-28 17:33:34 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121220205>
2019-04-28 17:33:34 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121143665>
2019-04-28 17:33:34 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121195815>
2019-04-28 17:33:34 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121186379>
2019-04-28 17:33:35 downloader.py[line:26] INFO: <200 http://www.baidu.com/>
2019-04-28 17:33:35 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121186379>
2019-04-28 17:33:35 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/10/>
2019-04-28 17:33:35 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121220205>
2019-04-28 17:33:35 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/11/>
2019-04-28 17:33:35 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/1/>
2019-04-28 17:33:35 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121143665>
2019-04-28 17:33:35 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121195323>
2019-04-28 17:33:36 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/5/>
2019-04-28 17:33:36 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121212672>
2019-04-28 17:33:36 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/12/>
2019-04-28 17:33:36 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121178129>
2019-04-28 17:33:36 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121195815>
2019-04-28 17:33:36 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121177356>
2019-04-28 17:33:36 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121195815>
2019-04-28 17:33:36 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121183420>
2019-04-28 17:33:36 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/4/>
2019-04-28 17:33:36 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121140722>
2019-04-28 17:33:36 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/3/>
2019-04-28 17:33:36 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121178129>
2019-04-28 17:33:36 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121220205>
2019-04-28 17:33:36 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/2/>
2019-04-28 17:33:36 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121206563>
2019-04-28 17:33:36 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121140722>
2019-04-28 17:33:36 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/13/>
2019-04-28 17:33:36 downloader.py[line:26] INFO: <200 https://www.douban.com/>
2019-04-28 17:33:36 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121186379>
2019-04-28 17:33:36 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/9/>
2019-04-28 17:33:36 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121221680>
2019-04-28 17:33:36 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121195323>
2019-04-28 17:33:37 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121212672>
2019-04-28 17:33:37 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/7/>
2019-04-28 17:33:37 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121186328>
2019-04-28 17:33:37 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/6/>
2019-04-28 17:33:37 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121177356>
2019-04-28 17:33:37 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121206563>
2019-04-28 17:33:37 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121143665>
2019-04-28 17:33:37 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/8/>
2019-04-28 17:33:37 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121221680>
2019-04-28 17:33:37 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121183420>
2019-04-28 17:33:37 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121186328>
2019-04-28 17:33:37 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/1/>
2019-04-28 17:33:37 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121195323>
2019-04-28 17:33:37 downloader.py[line:26] INFO: <200 http://www.baidu.com/>
2019-04-28 17:33:37 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/10/>
2019-04-28 17:33:37 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121220205>
2019-04-28 17:33:37 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121186379>
2019-04-28 17:33:37 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/11/>
2019-04-28 17:33:37 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121143665>
2019-04-28 17:33:37 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/5/>
2019-04-28 17:33:37 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121212672>
2019-04-28 17:33:37 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/12/>
2019-04-28 17:33:37 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121195815>
2019-04-28 17:33:37 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121178129>
2019-04-28 17:33:37 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121195815>
2019-04-28 17:33:37 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121177356>
2019-04-28 17:33:37 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121183420>
2019-04-28 17:33:37 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/4/>
2019-04-28 17:33:37 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121140722>
2019-04-28 17:33:38 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/3/>
2019-04-28 17:33:38 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121178129>
2019-04-28 17:33:38 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/2/>
2019-04-28 17:33:38 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121206563>
2019-04-28 17:33:38 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121220205>
2019-04-28 17:33:38 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121140722>
2019-04-28 17:33:38 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/13/>
2019-04-28 17:33:38 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121186379>
2019-04-28 17:33:38 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/9/>
2019-04-28 17:33:38 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121221680>
2019-04-28 17:33:38 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121195323>
2019-04-28 17:33:38 downloader.py[line:26] INFO: <200 https://www.douban.com/>
2019-04-28 17:33:38 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121212672>
2019-04-28 17:33:38 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/7/>
2019-04-28 17:33:38 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121186328>
2019-04-28 17:33:38 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/6/>
2019-04-28 17:33:38 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121177356>
2019-04-28 17:33:38 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121206563>
2019-04-28 17:33:38 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121143665>
2019-04-28 17:33:38 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/8/>
2019-04-28 17:33:38 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121183420>
2019-04-28 17:33:38 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121221680>
2019-04-28 17:33:38 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121186328>
2019-04-28 17:33:38 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/1/>
2019-04-28 17:33:38 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121195323>
2019-04-28 17:33:38 downloader.py[line:26] INFO: <200 http://www.baidu.com/>
2019-04-28 17:33:39 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/10/>
2019-04-28 17:33:39 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121220205>
2019-04-28 17:33:39 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/11/>
2019-04-28 17:33:39 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/5/>
2019-04-28 17:33:39 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121143665>
2019-04-28 17:33:39 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121212672>
2019-04-28 17:33:39 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121186379>
2019-04-28 17:33:39 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/12/>
2019-04-28 17:33:39 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121195815>
2019-04-28 17:33:39 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121178129>
2019-04-28 17:33:39 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121195815>
2019-04-28 17:33:39 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121177356>
2019-04-28 17:33:39 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121183420>
2019-04-28 17:33:39 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/4/>
2019-04-28 17:33:39 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/3/>
2019-04-28 17:33:39 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121140722>
2019-04-28 17:33:39 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121178129>
2019-04-28 17:33:39 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121220205>
2019-04-28 17:33:39 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/2/>
2019-04-28 17:33:39 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121206563>
2019-04-28 17:33:39 downloader.py[line:26] INFO: <200 https://www.douban.com/>
2019-04-28 17:33:39 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/13/>
2019-04-28 17:33:39 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121140722>
2019-04-28 17:33:39 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121186379>
2019-04-28 17:33:39 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/9/>
2019-04-28 17:33:39 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121221680>
2019-04-28 17:33:39 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121195323>
2019-04-28 17:33:39 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121212672>
2019-04-28 17:33:40 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/7/>
2019-04-28 17:33:40 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121186328>
2019-04-28 17:33:40 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/6/>
2019-04-28 17:33:40 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121177356>
2019-04-28 17:33:40 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121206563>
2019-04-28 17:33:40 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121143665>
2019-04-28 17:33:40 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121221680>
2019-04-28 17:33:40 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/8/>
2019-04-28 17:33:40 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121183420>
2019-04-28 17:33:40 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/1/>
2019-04-28 17:33:40 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121195323>
2019-04-28 17:33:40 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121186328>
2019-04-28 17:33:40 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/10/>
2019-04-28 17:33:40 downloader.py[line:26] INFO: <200 http://www.baidu.com/>
2019-04-28 17:33:40 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121220205>
2019-04-28 17:33:40 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121186379>
2019-04-28 17:33:40 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/11/>
2019-04-28 17:33:40 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121143665>
2019-04-28 17:33:40 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/5/>
2019-04-28 17:33:40 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121212672>
2019-04-28 17:33:40 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/12/>
2019-04-28 17:33:40 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121195815>
2019-04-28 17:33:40 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121178129>
2019-04-28 17:33:40 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121195815>
2019-04-28 17:33:40 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121177356>
2019-04-28 17:33:40 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/4/>
2019-04-28 17:33:40 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121183420>
2019-04-28 17:33:40 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121140722>
2019-04-28 17:33:41 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/3/>
2019-04-28 17:33:41 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121178129>
2019-04-28 17:33:41 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121220205>
2019-04-28 17:33:41 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/2/>
2019-04-28 17:33:41 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121206563>
2019-04-28 17:33:41 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121140722>
2019-04-28 17:33:41 downloader.py[line:26] INFO: <200 https://www.douban.com/>
2019-04-28 17:33:41 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/13/>
2019-04-28 17:33:41 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121186379>
2019-04-28 17:33:41 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/9/>
2019-04-28 17:33:41 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121221680>
2019-04-28 17:33:41 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121195323>
2019-04-28 17:33:41 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121212672>
2019-04-28 17:33:41 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/7/>
2019-04-28 17:33:41 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121186328>
2019-04-28 17:33:41 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/6/>
2019-04-28 17:33:41 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121177356>
2019-04-28 17:33:41 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121206563>
2019-04-28 17:33:41 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121143665>
2019-04-28 17:33:41 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121221680>
2019-04-28 17:33:41 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/8/>
2019-04-28 17:33:41 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121183420>
2019-04-28 17:33:41 downloader.py[line:26] INFO: <200 http://www.baidu.com/>
2019-04-28 17:33:41 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121186328>
2019-04-28 17:33:41 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/1/>
2019-04-28 17:33:41 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121195323>
2019-04-28 17:33:41 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/10/>
2019-04-28 17:33:41 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121220205>
2019-04-28 17:33:41 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121186379>
2019-04-28 17:33:41 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/11/>
2019-04-28 17:33:41 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121143665>
2019-04-28 17:33:42 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/5/>
2019-04-28 17:33:42 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121212672>
2019-04-28 17:33:42 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/12/>
2019-04-28 17:33:42 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121195815>
2019-04-28 17:33:42 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121178129>
2019-04-28 17:33:42 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121195815>
2019-04-28 17:33:42 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121177356>
2019-04-28 17:33:42 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121183420>
2019-04-28 17:33:42 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/4/>
2019-04-28 17:33:42 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121140722>
2019-04-28 17:33:42 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/3/>
2019-04-28 17:33:42 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121178129>
2019-04-28 17:33:42 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/2/>
2019-04-28 17:33:42 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121206563>
2019-04-28 17:33:42 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121220205>
2019-04-28 17:33:42 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121140722>
2019-04-28 17:33:42 downloader.py[line:26] INFO: <200 https://www.douban.com/>
2019-04-28 17:33:42 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/13/>
2019-04-28 17:33:42 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121186379>
2019-04-28 17:33:42 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/9/>
2019-04-28 17:33:42 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121221680>
2019-04-28 17:33:42 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121195323>
2019-04-28 17:33:42 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/7/>
2019-04-28 17:33:42 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121186328>
2019-04-28 17:33:42 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/6/>
2019-04-28 17:33:42 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121177356>
2019-04-28 17:33:42 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121212672>
2019-04-28 17:33:43 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121206563>
2019-04-28 17:33:43 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121143665>
2019-04-28 17:33:43 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/8/>
2019-04-28 17:33:43 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121183420>
2019-04-28 17:33:43 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121221680>
2019-04-28 17:33:43 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121186328>
2019-04-28 17:33:43 downloader.py[line:26] INFO: <200 http://www.baidu.com/>
2019-04-28 17:33:43 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/1/>
2019-04-28 17:33:43 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121195323>
2019-04-28 17:33:43 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/10/>
2019-04-28 17:33:43 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121220205>
2019-04-28 17:33:43 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121186379>
2019-04-28 17:33:43 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/11/>
2019-04-28 17:33:43 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121143665>
2019-04-28 17:33:43 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/12/>
2019-04-28 17:33:43 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/5/>
2019-04-28 17:33:43 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121195815>
2019-04-28 17:33:43 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121212672>
2019-04-28 17:33:43 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121178129>
2019-04-28 17:33:43 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121195815>
2019-04-28 17:33:43 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121177356>
2019-04-28 17:33:43 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121183420>
2019-04-28 17:33:43 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/4/>
2019-04-28 17:33:43 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121140722>
2019-04-28 17:33:43 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/3/>
2019-04-28 17:33:43 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121178129>
2019-04-28 17:33:43 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121220205>
2019-04-28 17:33:43 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/2/>
2019-04-28 17:33:43 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121206563>
2019-04-28 17:33:44 downloader.py[line:26] INFO: <200 https://www.douban.com/>
2019-04-28 17:33:44 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121140722>
2019-04-28 17:33:44 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/13/>
2019-04-28 17:33:44 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121186379>
2019-04-28 17:33:44 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/9/>
2019-04-28 17:33:44 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121221680>
2019-04-28 17:33:44 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121195323>
2019-04-28 17:33:44 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121212672>
2019-04-28 17:33:44 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/7/>
2019-04-28 17:33:44 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121186328>
2019-04-28 17:33:44 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/6/>
2019-04-28 17:33:44 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121177356>
2019-04-28 17:33:44 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121206563>
2019-04-28 17:33:44 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121143665>
2019-04-28 17:33:44 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121221680>
2019-04-28 17:33:44 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/8/>
2019-04-28 17:33:44 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121183420>
2019-04-28 17:33:44 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121186328>
2019-04-28 17:33:44 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/1/>
2019-04-28 17:33:44 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121195323>
2019-04-28 17:33:44 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/10/>
2019-04-28 17:33:44 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121220205>
2019-04-28 17:33:44 downloader.py[line:26] INFO: <200 http://www.baidu.com/>
2019-04-28 17:33:44 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121186379>
2019-04-28 17:33:44 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/11/>
2019-04-28 17:33:44 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121143665>
2019-04-28 17:33:44 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/5/>
2019-04-28 17:33:44 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/12/>
2019-04-28 17:33:44 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121212672>
2019-04-28 17:33:45 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121195815>
2019-04-28 17:33:45 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121178129>
2019-04-28 17:33:45 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121195815>
2019-04-28 17:33:45 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121177356>
2019-04-28 17:33:45 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121183420>
2019-04-28 17:33:45 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/4/>
2019-04-28 17:33:45 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121140722>
2019-04-28 17:33:45 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/3/>
2019-04-28 17:33:45 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121178129>
2019-04-28 17:33:45 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121220205>
2019-04-28 17:33:45 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/2/>
2019-04-28 17:33:45 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121206563>
2019-04-28 17:33:45 downloader.py[line:26] INFO: <200 https://www.douban.com/>
2019-04-28 17:33:45 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121140722>
2019-04-28 17:33:45 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/13/>
2019-04-28 17:33:45 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121186379>
2019-04-28 17:33:45 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/9/>
2019-04-28 17:33:45 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121221680>
2019-04-28 17:33:45 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121195323>
2019-04-28 17:33:45 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/7/>
2019-04-28 17:33:45 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121186328>
2019-04-28 17:33:45 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121212672>
2019-04-28 17:33:45 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/6/>
2019-04-28 17:33:45 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121177356>
2019-04-28 17:33:45 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121206563>
2019-04-28 17:33:46 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121143665>
2019-04-28 17:33:46 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/8/>
2019-04-28 17:33:46 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121221680>
2019-04-28 17:33:46 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121183420>
2019-04-28 17:33:46 downloader.py[line:26] INFO: <200 http://www.baidu.com/>
2019-04-28 17:33:46 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121186328>
2019-04-28 17:33:46 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/1/>
2019-04-28 17:33:46 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/10/>
2019-04-28 17:33:46 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121195323>
2019-04-28 17:33:46 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121220205>
2019-04-28 17:33:46 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121186379>
2019-04-28 17:33:46 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/11/>
2019-04-28 17:33:46 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/5/>
2019-04-28 17:33:46 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121143665>
2019-04-28 17:33:46 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121212672>
2019-04-28 17:33:46 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121178129>
2019-04-28 17:33:46 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/12/>
2019-04-28 17:33:46 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121195815>
2019-04-28 17:33:46 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121195815>
2019-04-28 17:33:46 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121177356>
2019-04-28 17:33:46 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121183420>
2019-04-28 17:33:46 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/4/>
2019-04-28 17:33:46 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121140722>
2019-04-28 17:33:46 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/3/>
2019-04-28 17:33:46 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121178129>
2019-04-28 17:33:46 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/2/>
2019-04-28 17:33:46 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121206563>
2019-04-28 17:33:46 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121220205>
2019-04-28 17:33:47 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121140722>
2019-04-28 17:33:47 downloader.py[line:26] INFO: <200 https://www.douban.com/>
2019-04-28 17:33:47 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/13/>
2019-04-28 17:33:47 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121186379>
2019-04-28 17:33:47 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/9/>
2019-04-28 17:33:47 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121221680>
2019-04-28 17:33:47 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121195323>
2019-04-28 17:33:47 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121212672>
2019-04-28 17:33:47 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/7/>
2019-04-28 17:33:47 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/6/>
2019-04-28 17:33:47 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121186328>
2019-04-28 17:33:47 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121177356>
2019-04-28 17:33:47 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121206563>
2019-04-28 17:33:47 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121143665>
2019-04-28 17:33:47 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/8/>
2019-04-28 17:33:47 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121186328>
2019-04-28 17:33:47 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121183420>
2019-04-28 17:33:47 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121221680>
2019-04-28 17:33:47 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/1/>
2019-04-28 17:33:47 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121195323>
2019-04-28 17:33:47 downloader.py[line:26] INFO: <200 http://www.baidu.com/>
2019-04-28 17:33:47 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/10/>
2019-04-28 17:33:47 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121220205>
2019-04-28 17:33:47 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121186379>
2019-04-28 17:33:48 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/11/>
2019-04-28 17:33:48 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121143665>
2019-04-28 17:33:48 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/5/>
2019-04-28 17:33:48 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121212672>
2019-04-28 17:33:48 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/12/>
2019-04-28 17:33:48 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121178129>
2019-04-28 17:33:48 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121195815>
2019-04-28 17:34:55 engine.py[line:81] INFO: 爬虫启动: 2019-04-28 17:34:55.464576
2019-04-28 17:34:55 engine.py[line:82] INFO: 当前启动的爬虫: ['spiders.baidu.BaiduSpider', 'spiders.qiubai.QiubaiSpider']
2019-04-28 17:34:55 engine.py[line:83] INFO: 当前开启的管道: ['pipelines.BaiduPipeline', 'pipelines.QiubaiPipeline']
2019-04-28 17:34:55 engine.py[line:84] INFO: 当前开启的下载器中间件: ['spider_middlewares.TestSpiderMiddleware1']
2019-04-28 17:34:55 engine.py[line:85] INFO: 当前开启的爬虫中间件: ['downloader_middlewares.TestDownloaderMiddleware2']
2019-04-28 17:34:57 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/2/>
2019-04-28 17:34:57 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/13/>
2019-04-28 17:34:57 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/3/>
2019-04-28 17:34:57 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121220205>
2019-04-28 17:34:57 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121140722>
2019-04-28 17:34:58 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121206563>
2019-04-28 17:34:58 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121186379>
2019-04-28 17:34:58 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121178129>
2019-04-28 17:34:58 scheduler.py[line:109] INFO: 发现重复的请求：<GET http://www.douban.com>
2019-04-28 17:34:58 scheduler.py[line:109] INFO: 发现重复的请求：<GET http://www.douban.com>
2019-04-28 17:34:58 scheduler.py[line:109] INFO: 发现重复的请求：<GET http://www.baidu.com>
2019-04-28 17:34:58 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/1/>
2019-04-28 17:34:58 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/2/>
2019-04-28 17:34:58 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/3/>
2019-04-28 17:34:58 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/4/>
2019-04-28 17:34:58 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/5/>
2019-04-28 17:34:58 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/6/>
2019-04-28 17:34:58 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/7/>
2019-04-28 17:34:58 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/8/>
2019-04-28 17:34:58 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/9/>
2019-04-28 17:34:58 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/10/>
2019-04-28 17:34:58 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/11/>
2019-04-28 17:34:58 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/12/>
2019-04-28 17:34:58 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/13/>
2019-04-28 17:34:59 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/9/>
2019-04-28 17:34:59 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121221680>
2019-04-28 17:34:59 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/7/>
2019-04-28 17:34:59 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121212672>
2019-04-28 17:34:59 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121186328>
2019-04-28 17:34:59 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/6/>
2019-04-28 17:34:59 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121177356>
2019-04-28 17:34:59 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121195323>
2019-04-28 17:34:59 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121206563>
2019-04-28 17:34:59 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/8/>
2019-04-28 17:34:59 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121143665>
2019-04-28 17:34:59 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121183420>
2019-04-28 17:34:59 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121221680>
2019-04-28 17:34:59 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121186328>
2019-04-28 17:34:59 downloader.py[line:26] INFO: <200 http://www.baidu.com/>
2019-04-28 17:34:59 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/1/>
2019-04-28 17:34:59 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121195323>
2019-04-28 17:34:59 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/10/>
2019-04-28 17:34:59 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121220205>
2019-04-28 17:34:59 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121186379>
2019-04-28 17:34:59 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/11/>
2019-04-28 17:34:59 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121143665>
2019-04-28 17:34:59 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/5/>
2019-04-28 17:34:59 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121212672>
2019-04-28 17:34:59 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/12/>
2019-04-28 17:34:59 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121195815>
2019-04-28 17:34:59 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121178129>
2019-04-28 17:34:59 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121195815>
2019-04-28 17:34:59 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121177356>
2019-04-28 17:34:59 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121183420>
2019-04-28 17:35:00 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/4/>
2019-04-28 17:35:00 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121140722>
2019-04-28 17:35:00 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/3/>
2019-04-28 17:35:00 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121178129>
2019-04-28 17:35:00 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121220205>
2019-04-28 17:35:00 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/2/>
2019-04-28 17:35:00 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121206563>
2019-04-28 17:35:00 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121140722>
2019-04-28 17:35:00 downloader.py[line:26] INFO: <200 https://www.douban.com/>
2019-04-28 17:35:00 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/13/>
2019-04-28 17:35:00 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121186379>
2019-04-28 17:35:00 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/9/>
2019-04-28 17:35:00 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121221680>
2019-04-28 17:35:00 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121195323>
2019-04-28 17:35:00 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/7/>
2019-04-28 17:35:00 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121186328>
2019-04-28 17:35:00 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121212672>
2019-04-28 17:35:00 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/6/>
2019-04-28 17:35:00 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121177356>
2019-04-28 17:35:00 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121206563>
2019-04-28 17:35:00 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121143665>
2019-04-28 17:35:00 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121221680>
2019-04-28 17:35:00 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/8/>
2019-04-28 17:35:00 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121183420>
2019-04-28 17:35:00 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121186328>
2019-04-28 17:35:00 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/1/>
2019-04-28 17:35:00 downloader.py[line:26] INFO: <200 http://www.baidu.com/>
2019-04-28 17:35:00 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121195323>
2019-04-28 17:35:00 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/10/>
2019-04-28 17:35:00 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121220205>
2019-04-28 17:35:01 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121186379>
2019-04-28 17:35:01 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/11/>
2019-04-28 17:35:01 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121143665>
2019-04-28 17:35:01 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/12/>
2019-04-28 17:35:01 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121195815>
2019-04-28 17:35:01 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/5/>
2019-04-28 17:35:01 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121212672>
2019-04-28 17:35:01 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121178129>
2019-04-28 17:35:01 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121195815>
2019-04-28 17:35:01 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121177356>
2019-04-28 17:35:01 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121183420>
2019-04-28 17:35:01 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/4/>
2019-04-28 17:35:01 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121140722>
2019-04-28 17:35:01 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/3/>
2019-04-28 17:35:01 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121178129>
2019-04-28 17:35:01 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121220205>
2019-04-28 17:35:01 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/2/>
2019-04-28 17:35:01 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121206563>
2019-04-28 17:35:01 downloader.py[line:26] INFO: <200 https://www.douban.com/>
2019-04-28 17:35:01 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121140722>
2019-04-28 17:35:01 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/13/>
2019-04-28 17:35:01 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121186379>
2019-04-28 17:35:01 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/9/>
2019-04-28 17:35:01 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121221680>
2019-04-28 17:35:01 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121195323>
2019-04-28 17:35:01 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121212672>
2019-04-28 17:35:01 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/7/>
2019-04-28 17:35:01 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121186328>
2019-04-28 17:35:02 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/6/>
2019-04-28 17:35:02 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121177356>
2019-04-28 17:35:02 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121206563>
2019-04-28 17:35:02 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121143665>
2019-04-28 17:35:02 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121221680>
2019-04-28 17:35:02 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/8/>
2019-04-28 17:35:02 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121183420>
2019-04-28 17:35:02 downloader.py[line:26] INFO: <200 http://www.baidu.com/>
2019-04-28 17:35:02 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121186328>
2019-04-28 17:35:02 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/1/>
2019-04-28 17:35:02 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121195323>
2019-04-28 17:35:02 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/10/>
2019-04-28 17:35:02 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121220205>
2019-04-28 17:35:02 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121186379>
2019-04-28 17:35:02 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/11/>
2019-04-28 17:35:02 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121143665>
2019-04-28 17:35:02 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/5/>
2019-04-28 17:35:02 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121212672>
2019-04-28 17:35:02 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/12/>
2019-04-28 17:35:02 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121195815>
2019-04-28 17:35:02 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121178129>
2019-04-28 17:35:02 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121195815>
2019-04-28 17:35:02 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121177356>
2019-04-28 17:35:02 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121183420>
2019-04-28 17:35:02 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/4/>
2019-04-28 17:35:02 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121140722>
2019-04-28 17:35:02 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/3/>
2019-04-28 17:35:02 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121178129>
2019-04-28 17:35:03 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121220205>
2019-04-28 17:35:03 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/2/>
2019-04-28 17:35:03 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121206563>
2019-04-28 17:35:03 downloader.py[line:26] INFO: <200 https://www.douban.com/>
2019-04-28 17:35:03 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121140722>
2019-04-28 17:35:03 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/13/>
2019-04-28 17:35:03 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121186379>
2019-04-28 17:35:03 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/9/>
2019-04-28 17:35:03 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121221680>
2019-04-28 17:35:03 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121195323>
2019-04-28 17:35:03 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121212672>
2019-04-28 17:35:03 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/7/>
2019-04-28 17:35:03 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121186328>
2019-04-28 17:35:03 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/6/>
2019-04-28 17:35:03 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121177356>
2019-04-28 17:35:03 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121206563>
2019-04-28 17:35:03 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121143665>
2019-04-28 17:35:03 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/8/>
2019-04-28 17:35:03 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121221680>
2019-04-28 17:35:03 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121183420>
2019-04-28 17:35:03 downloader.py[line:26] INFO: <200 http://www.baidu.com/>
2019-04-28 17:35:03 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121186328>
2019-04-28 17:35:03 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/1/>
2019-04-28 17:35:03 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121195323>
2019-04-28 17:35:03 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/10/>
2019-04-28 17:35:03 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121220205>
2019-04-28 17:35:03 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121186379>
2019-04-28 17:35:03 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/11/>
2019-04-28 17:35:04 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121143665>
2019-04-28 17:35:04 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/5/>
2019-04-28 17:35:04 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121212672>
2019-04-28 17:35:04 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/12/>
2019-04-28 17:35:04 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121195815>
2019-04-28 17:35:04 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121178129>
2019-04-28 17:38:15 engine.py[line:81] INFO: 爬虫启动: 2019-04-28 17:38:15.213574
2019-04-28 17:38:15 engine.py[line:82] INFO: 当前启动的爬虫: ['spiders.baidu.BaiduSpider', 'spiders.qiubai.QiubaiSpider']
2019-04-28 17:38:15 engine.py[line:83] INFO: 当前开启的管道: ['pipelines.BaiduPipeline', 'pipelines.QiubaiPipeline']
2019-04-28 17:38:15 engine.py[line:84] INFO: 当前开启的下载器中间件: ['spider_middlewares.TestSpiderMiddleware1']
2019-04-28 17:38:15 engine.py[line:85] INFO: 当前开启的爬虫中间件: ['downloader_middlewares.TestDownloaderMiddleware2']
2019-04-28 17:38:17 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/3/>
2019-04-28 17:38:17 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/2/>
2019-04-28 17:38:17 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121220205>
2019-04-28 17:38:17 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/4/>
2019-04-28 17:38:17 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121140722>
2019-04-28 17:38:18 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121178129>
2019-04-28 17:38:18 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121206563>
2019-04-28 17:38:18 scheduler.py[line:109] INFO: 发现重复的请求：<GET http://www.douban.com>
2019-04-28 17:38:18 scheduler.py[line:109] INFO: 发现重复的请求：<GET http://www.douban.com>
2019-04-28 17:38:18 scheduler.py[line:109] INFO: 发现重复的请求：<GET http://www.baidu.com>
2019-04-28 17:38:18 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121140722>
2019-04-28 17:38:18 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/1/>
2019-04-28 17:38:18 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/2/>
2019-04-28 17:38:18 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/3/>
2019-04-28 17:38:18 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/4/>
2019-04-28 17:38:18 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/5/>
2019-04-28 17:38:18 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/6/>
2019-04-28 17:38:18 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/7/>
2019-04-28 17:38:18 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/8/>
2019-04-28 17:38:18 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/9/>
2019-04-28 17:38:18 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/10/>
2019-04-28 17:38:18 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/11/>
2019-04-28 17:38:18 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/12/>
2019-04-28 17:38:18 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/13/>
2019-04-28 17:38:18 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/13/>
2019-04-28 17:38:18 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/9/>
2019-04-28 17:38:18 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121186379>
2019-04-28 17:38:18 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121195323>
2019-04-28 17:38:18 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121221680>
2019-04-28 17:38:18 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/7/>
2019-04-28 17:38:18 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121186328>
2019-04-28 17:38:18 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121212672>
2019-04-28 17:38:19 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/6/>
2019-04-28 17:38:19 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121177356>
2019-04-28 17:38:19 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121206563>
2019-04-28 17:38:19 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121143665>
2019-04-28 17:38:19 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/8/>
2019-04-28 17:38:19 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121183420>
2019-04-28 17:38:19 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121221680>
2019-04-28 17:38:19 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121186328>
2019-04-28 17:38:19 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/1/>
2019-04-28 17:38:19 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/10/>
2019-04-28 17:38:19 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121195323>
2019-04-28 17:38:19 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121220205>
2019-04-28 17:38:19 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121186379>
2019-04-28 17:38:19 downloader.py[line:26] INFO: <200 http://www.baidu.com/>
2019-04-28 17:38:19 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/11/>
2019-04-28 17:38:19 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/12/>
2019-04-28 17:38:19 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121143665>
2019-04-28 17:38:19 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121195815>
2019-04-28 17:38:19 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/5/>
2019-04-28 17:38:19 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121212672>
2019-04-28 17:38:19 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121178129>
2019-04-28 17:38:19 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121195815>
2019-04-28 17:38:19 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121177356>
2019-04-28 17:38:19 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121183420>
2019-04-28 17:38:19 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/4/>
2019-04-28 17:38:19 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/3/>
2019-04-28 17:38:19 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121140722>
2019-04-28 17:38:19 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121178129>
2019-04-28 17:38:20 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/2/>
2019-04-28 17:38:20 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121206563>
2019-04-28 17:38:20 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121220205>
2019-04-28 17:38:20 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/13/>
2019-04-28 17:38:20 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121186379>
2019-04-28 17:38:20 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121140722>
2019-04-28 17:38:20 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/9/>
2019-04-28 17:38:20 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121195323>
2019-04-28 17:38:20 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121221680>
2019-04-28 17:38:20 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/7/>
2019-04-28 17:38:20 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121212672>
2019-04-28 17:38:20 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121186328>
2019-04-28 17:38:20 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/6/>
2019-04-28 17:38:20 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121177356>
2019-04-28 17:38:20 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121206563>
2019-04-28 17:38:20 downloader.py[line:26] INFO: <200 https://www.douban.com/>
2019-04-28 17:38:20 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121143665>
2019-04-28 17:38:20 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/8/>
2019-04-28 17:38:20 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121183420>
2019-04-28 17:38:20 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/1/>
2019-04-28 17:38:20 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121195323>
2019-04-28 17:38:20 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121186328>
2019-04-28 17:38:20 downloader.py[line:26] INFO: <200 http://www.baidu.com/>
2019-04-28 17:38:21 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/10/>
2019-04-28 17:38:21 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121220205>
2019-04-28 17:38:21 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121186379>
2019-04-28 17:38:21 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/11/>
2019-04-28 17:38:21 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121143665>
2019-04-28 17:38:21 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/5/>
2019-04-28 17:38:21 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121212672>
2019-04-28 17:38:21 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/12/>
2019-04-28 17:38:21 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121221680>
2019-04-28 17:38:21 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121195815>
2019-04-28 17:38:21 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121178129>
2019-04-28 17:38:21 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121195815>
2019-04-28 17:38:21 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121177356>
2019-04-28 17:38:21 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121183420>
2019-04-28 17:38:21 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/4/>
2019-04-28 17:38:21 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121140722>
2019-04-28 17:38:21 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/3/>
2019-04-28 17:38:21 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121178129>
2019-04-28 17:38:21 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121220205>
2019-04-28 17:38:21 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/2/>
2019-04-28 17:38:21 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121206563>
2019-04-28 17:38:21 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/13/>
2019-04-28 17:38:21 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121186379>
2019-04-28 17:38:21 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/9/>
2019-04-28 17:38:21 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121221680>
2019-04-28 17:38:21 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121140722>
2019-04-28 17:38:22 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121195323>
2019-04-28 17:38:22 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121212672>
2019-04-28 17:38:22 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/7/>
2019-04-28 17:38:22 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121186328>
2019-04-28 17:38:22 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/6/>
2019-04-28 17:38:22 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121177356>
2019-04-28 17:38:22 downloader.py[line:26] INFO: <200 https://www.douban.com/>
2019-04-28 17:38:22 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121206563>
2019-04-28 17:38:22 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121143665>
2019-04-28 17:38:22 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121221680>
2019-04-28 17:38:22 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/8/>
2019-04-28 17:38:22 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121183420>
2019-04-28 17:38:22 downloader.py[line:26] INFO: <200 http://www.baidu.com/>
2019-04-28 17:38:22 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121186328>
2019-04-28 17:38:22 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/1/>
2019-04-28 17:38:22 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121195323>
2019-04-28 17:38:22 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/10/>
2019-04-28 17:38:22 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121220205>
2019-04-28 17:38:22 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121186379>
2019-04-28 17:38:22 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/11/>
2019-04-28 17:38:22 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121143665>
2019-04-28 17:38:22 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/5/>
2019-04-28 17:38:22 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121212672>
2019-04-28 17:38:22 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/12/>
2019-04-28 17:38:22 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121195815>
2019-04-28 17:38:23 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121178129>
2019-04-28 17:38:23 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121195815>
2019-04-28 17:38:23 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121183420>
2019-04-28 17:38:23 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121177356>
2019-04-28 17:38:23 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/4/>
2019-04-28 17:38:23 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121140722>
2019-04-28 17:38:23 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/3/>
2019-04-28 17:38:23 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121178129>
2019-04-28 17:38:23 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121220205>
2019-04-28 17:38:23 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/2/>
2019-04-28 17:38:23 scheduler.py[line:109] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121206563>
2019-04-28 17:38:23 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121140722>
2019-04-28 17:51:36 engine.py[line:81] INFO: 爬虫启动: 2019-04-28 17:51:36.149156
2019-04-28 17:51:36 engine.py[line:82] INFO: 当前启动的爬虫: ['spiders.baidu.BaiduSpider', 'spiders.qiubai.QiubaiSpider']
2019-04-28 17:51:36 engine.py[line:83] INFO: 当前开启的管道: ['pipelines.BaiduPipeline', 'pipelines.QiubaiPipeline']
2019-04-28 17:51:36 engine.py[line:84] INFO: 当前开启的下载器中间件: ['spider_middlewares.TestSpiderMiddleware1']
2019-04-28 17:51:36 engine.py[line:85] INFO: 当前开启的爬虫中间件: ['downloader_middlewares.TestDownloaderMiddleware2']
2019-04-28 17:51:38 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/6/>
2019-04-28 17:51:38 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/7/>
2019-04-28 17:51:38 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121206563>
2019-04-28 17:51:38 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121212672>
2019-04-28 17:51:38 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121143665>
2019-04-28 17:51:38 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121221680>
2019-04-28 17:51:39 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/8/>
2019-04-28 17:51:39 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121135027>
2019-04-28 17:51:39 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121160484>
2019-04-28 17:51:39 scheduler.py[line:111] INFO: 发现重复的请求：<GET http://www.douban.com>
2019-04-28 17:51:39 scheduler.py[line:111] INFO: 发现重复的请求：<GET http://www.douban.com>
2019-04-28 17:51:39 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/1/>
2019-04-28 17:51:39 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/2/>
2019-04-28 17:51:39 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/3/>
2019-04-28 17:51:39 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/4/>
2019-04-28 17:51:39 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/5/>
2019-04-28 17:51:39 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/6/>
2019-04-28 17:51:39 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/7/>
2019-04-28 17:51:39 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/8/>
2019-04-28 17:51:39 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/9/>
2019-04-28 17:51:39 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/10/>
2019-04-28 17:51:39 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/11/>
2019-04-28 17:51:39 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/12/>
2019-04-28 17:51:39 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/13/>
2019-04-28 17:51:39 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/1/>
2019-04-28 17:51:39 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121186328>
2019-04-28 17:51:39 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121194436>
2019-04-28 17:51:39 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/10/>
2019-04-28 17:51:39 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121225464>
2019-04-28 17:51:39 downloader.py[line:26] INFO: <200 http://www.baidu.com/>
2019-04-28 17:51:39 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121186379>
2019-04-28 17:51:40 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/11/>
2019-04-28 17:51:40 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/5/>
2019-04-28 17:51:40 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121183719>
2019-04-28 17:51:40 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121179194>
2019-04-28 17:51:40 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121226615>
2019-04-28 17:51:40 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/12/>
2019-04-28 17:51:40 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121167571>
2019-04-28 17:51:40 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121178129>
2019-04-28 17:51:40 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121195815>
2019-04-28 17:51:40 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121177356>
2019-04-28 17:51:40 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121183420>
2019-04-28 17:51:40 scheduler.py[line:111] INFO: 发现重复的请求：<GET http://www.baidu.com>
2019-04-28 17:51:40 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/4/>
2019-04-28 17:51:40 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121173384>
2019-04-28 17:51:40 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/2/>
2019-04-28 17:51:40 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121156222>
2019-04-28 17:51:40 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121220205>
2019-04-28 17:51:40 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121140722>
2019-04-28 17:51:40 downloader.py[line:26] INFO: <200 https://www.douban.com/>
2019-04-28 17:51:40 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/3/>
2019-04-28 17:51:40 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121191126>
2019-04-28 17:51:41 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/13/>
2019-04-28 17:51:41 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121140578>
2019-04-28 17:51:41 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/9/>
2019-04-28 17:51:41 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121181536>
2019-04-28 17:51:41 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121212672>
2019-04-28 17:51:41 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121195323>
2019-04-28 17:51:41 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/7/>
2019-04-28 17:51:41 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121160484>
2019-04-28 17:51:41 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/6/>
2019-04-28 17:51:41 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121135027>
2019-04-28 17:51:41 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121206563>
2019-04-28 17:51:41 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121143665>
2019-04-28 17:51:41 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/8/>
2019-04-28 17:51:41 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121226615>
2019-04-28 17:51:41 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121221680>
2019-04-28 17:51:41 downloader.py[line:26] INFO: <200 http://www.baidu.com/>
2019-04-28 17:51:41 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121186328>
2019-04-28 17:51:41 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/1/>
2019-04-28 17:51:41 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121194436>
2019-04-28 17:51:41 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/10/>
2019-04-28 17:51:41 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121225464>
2019-04-28 17:51:41 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121186379>
2019-04-28 17:51:41 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/11/>
2019-04-28 17:51:41 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121183719>
2019-04-28 17:51:41 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/5/>
2019-04-28 17:51:41 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121179194>
2019-04-28 17:51:41 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/12/>
2019-04-28 17:51:41 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121167571>
2019-04-28 17:51:41 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121178129>
2019-04-28 17:51:41 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121195815>
2019-04-28 17:51:41 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121177356>
2019-04-28 17:51:41 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121183420>
2019-04-28 17:51:42 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/4/>
2019-04-28 17:51:42 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121173384>
2019-04-28 17:51:42 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/3/>
2019-04-28 17:51:42 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121191126>
2019-04-28 17:51:42 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121220205>
2019-04-28 17:51:42 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/2/>
2019-04-28 17:51:42 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121156222>
2019-04-28 17:51:42 downloader.py[line:26] INFO: <200 https://www.douban.com/>
2019-04-28 17:51:42 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121140722>
2019-04-28 17:51:42 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/13/>
2019-04-28 17:51:42 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121140578>
2019-04-28 17:51:42 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/9/>
2019-04-28 17:51:42 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121181536>
2019-04-28 17:51:42 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121195323>
2019-04-28 17:51:42 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121212672>
2019-04-28 17:51:42 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/7/>
2019-04-28 17:51:42 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121160484>
2019-04-28 17:51:42 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/6/>
2019-04-28 17:51:42 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121135027>
2019-04-28 17:51:42 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121206563>
2019-04-28 17:51:42 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121221680>
2019-04-28 17:51:42 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121143665>
2019-04-28 17:51:42 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/8/>
2019-04-28 17:51:42 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121186328>
2019-04-28 17:51:42 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121226615>
2019-04-28 17:51:42 downloader.py[line:26] INFO: <200 http://www.baidu.com/>
2019-04-28 17:51:42 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/1/>
2019-04-28 17:51:42 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121194436>
2019-04-28 17:51:43 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/10/>
2019-04-28 17:51:43 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121225464>
2019-04-28 17:51:43 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121186379>
2019-04-28 17:51:43 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/11/>
2019-04-28 17:51:43 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121183719>
2019-04-28 17:51:43 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/5/>
2019-04-28 17:51:43 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121179194>
2019-04-28 17:51:43 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/12/>
2019-04-28 17:51:43 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121167571>
2019-04-28 17:51:43 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121178129>
2019-04-28 17:51:43 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121195815>
2019-04-28 17:51:43 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121177356>
2019-04-28 17:51:43 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121183420>
2019-04-28 17:51:43 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/4/>
2019-04-28 17:51:43 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121173384>
2019-04-28 17:51:43 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/3/>
2019-04-28 17:51:43 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121191126>
2019-04-28 17:51:43 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121220205>
2019-04-28 17:51:43 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/2/>
2019-04-28 17:51:43 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121156222>
2019-04-28 17:51:43 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121140722>
2019-04-28 17:51:43 downloader.py[line:26] INFO: <200 https://www.douban.com/>
2019-04-28 17:51:43 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/13/>
2019-04-28 17:51:43 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121140578>
2019-04-28 17:51:43 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/9/>
2019-04-28 17:51:43 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121181536>
2019-04-28 17:51:43 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121195323>
2019-04-28 17:51:43 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121212672>
2019-04-28 17:51:43 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/7/>
2019-04-28 17:51:43 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121160484>
2019-04-28 17:51:43 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/6/>
2019-04-28 17:51:43 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121135027>
2019-04-28 17:51:44 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121206563>
2019-04-28 17:51:44 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121143665>
2019-04-28 17:51:44 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121221680>
2019-04-28 17:51:44 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/8/>
2019-04-28 17:51:44 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121226615>
2019-04-28 17:51:44 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121186328>
2019-04-28 17:51:44 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/1/>
2019-04-28 17:51:44 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121194436>
2019-04-28 17:51:44 downloader.py[line:26] INFO: <200 http://www.baidu.com/>
2019-04-28 17:51:44 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/10/>
2019-04-28 17:51:44 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121225464>
2019-04-28 17:51:44 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121186379>
2019-04-28 17:51:44 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/11/>
2019-04-28 17:51:44 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121183719>
2019-04-28 17:51:44 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/5/>
2019-04-28 17:51:44 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121179194>
2019-04-28 17:51:44 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/12/>
2019-04-28 17:51:44 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121167571>
2019-04-28 17:51:44 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121178129>
2019-04-28 17:51:44 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121177356>
2019-04-28 17:51:44 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121195815>
2019-04-28 17:52:11 engine.py[line:81] INFO: 爬虫启动: 2019-04-28 17:52:11.716158
2019-04-28 17:52:11 engine.py[line:82] INFO: 当前启动的爬虫: ['spiders.baidu.BaiduSpider', 'spiders.qiubai.QiubaiSpider']
2019-04-28 17:52:11 engine.py[line:83] INFO: 当前开启的管道: ['pipelines.BaiduPipeline', 'pipelines.QiubaiPipeline']
2019-04-28 17:52:11 engine.py[line:84] INFO: 当前开启的下载器中间件: ['spider_middlewares.TestSpiderMiddleware1']
2019-04-28 17:52:11 engine.py[line:85] INFO: 当前开启的爬虫中间件: ['downloader_middlewares.TestDownloaderMiddleware2']
2019-04-28 17:52:14 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/9/>
2019-04-28 17:52:14 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/13/>
2019-04-28 17:52:14 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121140722>
2019-04-28 17:52:14 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/2/>
2019-04-28 17:52:14 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121195323>
2019-04-28 17:52:15 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121181536>
2019-04-28 17:52:15 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/1/>
2019-04-28 17:52:15 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/2/>
2019-04-28 17:52:15 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/3/>
2019-04-28 17:52:15 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/4/>
2019-04-28 17:52:15 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/5/>
2019-04-28 17:52:15 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/6/>
2019-04-28 17:52:15 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/7/>
2019-04-28 17:52:15 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/8/>
2019-04-28 17:52:15 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/9/>
2019-04-28 17:52:15 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/10/>
2019-04-28 17:52:15 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/11/>
2019-04-28 17:52:15 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/12/>
2019-04-28 17:52:15 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/13/>
2019-04-28 17:52:15 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121140578>
2019-04-28 17:52:15 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121156222>
2019-04-28 17:52:15 scheduler.py[line:111] INFO: 发现重复的请求：<GET http://www.douban.com>
2019-04-28 17:52:15 scheduler.py[line:111] INFO: 发现重复的请求：<GET http://www.douban.com>
2019-04-28 17:52:15 scheduler.py[line:111] INFO: 发现重复的请求：<GET http://www.baidu.com>
2019-04-28 17:52:15 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121212672>
2019-04-28 17:52:15 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/7/>
2019-04-28 17:52:15 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121160484>
2019-04-28 17:52:15 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121206563>
2019-04-28 17:52:15 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/6/>
2019-04-28 17:52:15 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121135027>
2019-04-28 17:52:15 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121143665>
2019-04-28 17:52:15 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/8/>
2019-04-28 17:52:15 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121226615>
2019-04-28 17:52:15 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/1/>
2019-04-28 17:52:15 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121194436>
2019-04-28 17:52:15 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121221680>
2019-04-28 17:52:15 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121186328>
2019-04-28 17:52:15 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/10/>
2019-04-28 17:52:15 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121225464>
2019-04-28 17:52:15 downloader.py[line:26] INFO: <200 http://www.baidu.com/>
2019-04-28 17:52:15 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/11/>
2019-04-28 17:52:15 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121183719>
2019-04-28 17:52:15 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121186379>
2019-04-28 17:52:15 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/5/>
2019-04-28 17:52:15 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121179194>
2019-04-28 17:52:15 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/12/>
2019-04-28 17:52:15 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121167571>
2019-04-28 17:52:15 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121178129>
2019-04-28 17:52:16 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121195815>
2019-04-28 17:52:16 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121177356>
2019-04-28 17:52:16 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/4/>
2019-04-28 17:52:16 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121173384>
2019-04-28 17:52:16 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121183420>
2019-04-28 17:52:16 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/3/>
2019-04-28 17:52:16 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121191126>
2019-04-28 17:52:16 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121220205>
2019-04-28 17:52:16 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/2/>
2019-04-28 17:52:16 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121156222>
2019-04-28 17:52:16 downloader.py[line:26] INFO: <200 https://www.douban.com/>
2019-04-28 17:52:16 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121140722>
2019-04-28 17:52:16 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/13/>
2019-04-28 17:52:16 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121140578>
2019-04-28 17:52:16 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/9/>
2019-04-28 17:52:16 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121181536>
2019-04-28 17:52:16 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121195323>
2019-04-28 17:52:16 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121212672>
2019-04-28 17:52:16 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/7/>
2019-04-28 17:52:16 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121160484>
2019-04-28 17:52:16 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/6/>
2019-04-28 17:52:16 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121135027>
2019-04-28 17:52:16 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121206563>
2019-04-28 17:52:16 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121143665>
2019-04-28 17:52:16 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/8/>
2019-04-28 17:52:16 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121221680>
2019-04-28 17:52:16 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121226615>
2019-04-28 17:52:17 downloader.py[line:26] INFO: <200 http://www.baidu.com/>
2019-04-28 17:52:17 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/1/>
2019-04-28 17:52:17 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121194436>
2019-04-28 17:52:17 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121186328>
2019-04-28 17:52:17 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/10/>
2019-04-28 17:52:17 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121225464>
2019-04-28 17:52:17 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121186379>
2019-04-28 17:52:17 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/11/>
2019-04-28 17:52:17 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121183719>
2019-04-28 17:52:17 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/5/>
2019-04-28 17:52:17 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121179194>
2019-04-28 17:52:17 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/12/>
2019-04-28 17:52:17 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121167571>
2019-04-28 17:52:17 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121178129>
2019-04-28 17:52:17 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121195815>
2019-04-28 17:52:17 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121177356>
2019-04-28 17:52:17 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121183420>
2019-04-28 17:52:17 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/4/>
2019-04-28 17:52:17 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121173384>
2019-04-28 17:52:17 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/3/>
2019-04-28 17:52:17 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121191126>
2019-04-28 17:52:18 downloader.py[line:26] INFO: <200 https://www.douban.com/>
2019-04-28 17:52:18 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121220205>
2019-04-28 17:52:18 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/9/>
2019-04-28 17:52:18 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121181536>
2019-04-28 17:52:18 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/2/>
2019-04-28 17:52:18 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121156222>
2019-04-28 17:52:18 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121140722>
2019-04-28 17:52:18 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121195323>
2019-04-28 17:52:18 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/13/>
2019-04-28 17:52:18 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121140578>
2019-04-28 17:52:19 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121206563>
2019-04-28 17:52:19 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/7/>
2019-04-28 17:52:19 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/6/>
2019-04-28 17:52:19 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121160484>
2019-04-28 17:52:19 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121143665>
2019-04-28 17:52:19 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121135027>
2019-04-28 17:52:19 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121212672>
2019-04-28 17:52:19 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121221680>
2019-04-28 17:52:19 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121186328>
2019-04-28 17:52:19 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/8/>
2019-04-28 17:52:19 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121226615>
2019-04-28 17:52:19 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/10/>
2019-04-28 17:52:19 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121225464>
2019-04-28 17:52:19 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/1/>
2019-04-28 17:52:19 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121194436>
2019-04-28 17:53:19 engine.py[line:81] INFO: 爬虫启动: 2019-04-28 17:53:19.099164
2019-04-28 17:53:19 engine.py[line:82] INFO: 当前启动的爬虫: ['spiders.baidu.BaiduSpider', 'spiders.qiubai.QiubaiSpider']
2019-04-28 17:53:19 engine.py[line:83] INFO: 当前开启的管道: ['pipelines.BaiduPipeline', 'pipelines.QiubaiPipeline']
2019-04-28 17:53:19 engine.py[line:84] INFO: 当前开启的下载器中间件: ['spider_middlewares.TestSpiderMiddleware1']
2019-04-28 17:53:19 engine.py[line:85] INFO: 当前开启的爬虫中间件: ['downloader_middlewares.TestDownloaderMiddleware2']
2019-04-28 17:53:21 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121183420>
2019-04-28 17:53:21 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121178129>
2019-04-28 17:53:21 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121177356>
2019-04-28 17:53:21 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121195815>
2019-04-28 17:53:21 downloader.py[line:26] INFO: <200 https://www.douban.com/>
2019-04-28 17:53:21 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/4/>
2019-04-28 17:53:21 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/3/>
2019-04-28 17:53:22 scheduler.py[line:111] INFO: 发现重复的请求：<GET http://www.douban.com>
2019-04-28 17:53:22 scheduler.py[line:111] INFO: 发现重复的请求：<GET http://www.douban.com>
2019-04-28 17:53:22 scheduler.py[line:111] INFO: 发现重复的请求：<GET http://www.baidu.com>
2019-04-28 17:53:22 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/1/>
2019-04-28 17:53:22 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/2/>
2019-04-28 17:53:22 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/3/>
2019-04-28 17:53:22 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/4/>
2019-04-28 17:53:22 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/5/>
2019-04-28 17:53:22 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/6/>
2019-04-28 17:53:22 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/7/>
2019-04-28 17:53:22 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/8/>
2019-04-28 17:53:22 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/9/>
2019-04-28 17:53:22 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/10/>
2019-04-28 17:53:22 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/11/>
2019-04-28 17:53:22 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/12/>
2019-04-28 17:53:22 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/13/>
2019-04-28 17:53:22 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121220205>
2019-04-28 17:53:22 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/2/>
2019-04-28 17:53:22 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121156222>
2019-04-28 17:53:22 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121140722>
2019-04-28 17:53:22 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121173384>
2019-04-28 17:53:22 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/13/>
2019-04-28 17:53:22 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121140578>
2019-04-28 17:53:22 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/9/>
2019-04-28 17:53:22 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121181536>
2019-04-28 17:53:23 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121191126>
2019-04-28 17:53:23 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121195323>
2019-04-28 17:53:23 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121212672>
2019-04-28 17:53:23 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/6/>
2019-04-28 17:53:23 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/7/>
2019-04-28 17:53:23 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121135027>
2019-04-28 17:53:23 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121160484>
2019-04-28 17:53:23 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121206563>
2019-04-28 17:53:23 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121143665>
2019-04-28 17:53:23 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121221680>
2019-04-28 17:53:23 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/8/>
2019-04-28 17:53:23 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121226615>
2019-04-28 17:53:23 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121186328>
2019-04-28 17:53:23 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/1/>
2019-04-28 17:53:23 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121194436>
2019-04-28 17:53:23 downloader.py[line:26] INFO: <200 http://www.baidu.com/>
2019-04-28 17:53:23 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/10/>
2019-04-28 17:53:23 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121225464>
2019-04-28 17:53:23 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121186379>
2019-04-28 17:53:23 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/11/>
2019-04-28 17:53:23 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121183719>
2019-04-28 17:53:23 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/12/>
2019-04-28 17:53:23 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121167571>
2019-04-28 17:53:23 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/5/>
2019-04-28 17:53:23 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121179194>
2019-04-28 17:53:23 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121178129>
2019-04-28 17:53:23 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121195815>
2019-04-28 17:53:24 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121177356>
2019-04-28 17:53:24 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121183420>
2019-04-28 17:53:24 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/4/>
2019-04-28 17:53:24 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121173384>
2019-04-28 17:53:24 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/3/>
2019-04-28 17:53:24 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121191126>
2019-04-28 17:53:24 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121220205>
2019-04-28 17:53:24 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121140722>
2019-04-28 17:53:24 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/2/>
2019-04-28 17:53:24 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121156222>
2019-04-28 17:53:24 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/13/>
2019-04-28 17:53:24 downloader.py[line:26] INFO: <200 https://www.douban.com/>
2019-04-28 17:53:24 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121140578>
2019-04-28 17:53:24 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/9/>
2019-04-28 17:53:24 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121181536>
2019-04-28 17:53:24 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121195323>
2019-04-28 17:53:24 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/6/>
2019-04-28 17:53:24 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121135027>
2019-04-28 17:53:24 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/7/>
2019-04-28 17:53:24 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121212672>
2019-04-28 17:53:24 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121160484>
2019-04-28 17:53:24 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121206563>
2019-04-28 17:53:24 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121143665>
2019-04-28 17:53:24 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/8/>
2019-04-28 17:53:24 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121226615>
2019-04-28 17:53:24 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121221680>
2019-04-28 17:53:24 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121186328>
2019-04-28 17:53:24 downloader.py[line:26] INFO: <200 http://www.baidu.com/>
2019-04-28 17:53:25 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/1/>
2019-04-28 17:53:25 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121194436>
2019-04-28 17:53:25 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/10/>
2019-04-28 17:53:25 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121225464>
2019-04-28 17:53:25 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121186379>
2019-04-28 17:53:25 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/11/>
2019-04-28 17:53:25 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121183719>
2019-04-28 17:53:25 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/5/>
2019-04-28 17:53:25 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121179194>
2019-04-28 17:53:25 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/12/>
2019-04-28 17:53:25 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121167571>
2019-04-28 17:53:25 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121178129>
2019-04-28 17:53:25 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121195815>
2019-04-28 17:53:25 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121177356>
2019-04-28 17:53:25 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121183420>
2019-04-28 17:53:25 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/4/>
2019-04-28 17:53:25 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121173384>
2019-04-28 17:53:25 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/3/>
2019-04-28 17:53:25 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121191126>
2019-04-28 17:53:25 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121220205>
2019-04-28 17:53:25 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/2/>
2019-04-28 17:53:25 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121156222>
2019-04-28 17:53:25 downloader.py[line:26] INFO: <200 https://www.douban.com/>
2019-04-28 17:53:25 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121140722>
2019-04-28 17:53:25 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/13/>
2019-04-28 17:53:25 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121140578>
2019-04-28 17:53:25 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/9/>
2019-04-28 17:53:25 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121181536>
2019-04-28 17:53:25 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121195323>
2019-04-28 17:53:26 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/7/>
2019-04-28 17:53:26 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121160484>
2019-04-28 17:53:26 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/6/>
2019-04-28 17:53:26 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121135027>
2019-04-28 17:53:26 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121212672>
2019-04-28 17:53:26 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121206563>
2019-04-28 17:53:26 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/8/>
2019-04-28 17:53:26 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121226615>
2019-04-28 17:53:26 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121221680>
2019-04-28 17:53:26 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/1/>
2019-04-28 17:53:26 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121194436>
2019-04-28 17:53:26 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121186328>
2019-04-28 17:53:26 downloader.py[line:26] INFO: <200 http://www.baidu.com/>
2019-04-28 17:53:26 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121143665>
2019-04-28 17:53:26 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/10/>
2019-04-28 17:53:26 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121225464>
2019-04-28 17:53:26 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121186379>
2019-04-28 17:53:26 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/11/>
2019-04-28 17:53:26 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121183719>
2019-04-28 17:53:26 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/5/>
2019-04-28 17:53:26 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121179194>
2019-04-28 17:53:26 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/12/>
2019-04-28 17:53:26 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121167571>
2019-04-28 17:53:26 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121178129>
2019-04-28 17:53:26 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121195815>
2019-04-28 17:53:26 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121177356>
2019-04-28 17:53:27 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/4/>
2019-04-28 17:53:27 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121173384>
2019-04-28 17:53:27 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/3/>
2019-04-28 17:53:27 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121191126>
2019-04-28 17:53:27 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121220205>
2019-04-28 17:53:27 downloader.py[line:26] INFO: <200 https://www.douban.com/>
2019-04-28 17:53:27 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121183420>
2019-04-28 17:53:27 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/2/>
2019-04-28 17:53:27 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/article/121156222>
2019-04-28 17:53:27 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121140722>
2019-04-29 14:15:28 engine.py[line:81] INFO: 爬虫启动: 2019-04-29 14:15:28.641252
2019-04-29 14:15:28 engine.py[line:82] INFO: 当前启动的爬虫: ['spiders.baidu.BaiduSpider', 'spiders.qiubai.QiubaiSpider']
2019-04-29 14:15:28 engine.py[line:83] INFO: 当前开启的管道: ['pipelines.BaiduPipeline', 'pipelines.QiubaiPipeline']
2019-04-29 14:15:28 engine.py[line:84] INFO: 当前开启的下载器中间件: ['spider_middlewares.TestSpiderMiddleware1']
2019-04-29 14:15:28 engine.py[line:85] INFO: 当前开启的爬虫中间件: ['downloader_middlewares.TestDownloaderMiddleware2']
2019-04-29 14:15:30 scheduler.py[line:106] INFO: 添加新的请求: <http://www.douban.com>
2019-04-29 14:15:30 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/1/>
2019-04-29 14:15:31 scheduler.py[line:111] INFO: 发现重复的请求：<GET http://www.douban.com>
2019-04-29 14:15:31 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/2/>
2019-04-29 14:15:31 scheduler.py[line:106] INFO: 添加新的请求: <http://www.baidu.com>
2019-04-29 14:15:31 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/3/>
2019-04-29 14:15:31 downloader.py[line:26] INFO: <200 http://www.baidu.com/>
2019-04-29 14:15:31 engine.py[line:202] ERROR: 'RedisBackupRequest' object has no attribute 'get_length'
Traceback (most recent call last):
  File "D:\David\Desktop\spider_plus_fw\spider_plus\core\engine.py", line 200, in _error_callback
    raise exception  # 抛出异常后, 才能被日志进行完整记录下来
  File "c:\python36\Lib\multiprocessing\pool.py", line 119, in worker
    result = (True, func(*args, **kwds))
  File "D:\David\Desktop\spider_plus_fw\spider_plus\core\engine.py", line 195, in _execute_request_response_item
    print(self.scheduler._backup_request.get_length())
AttributeError: 'RedisBackupRequest' object has no attribute 'get_length'
2019-04-29 14:15:32 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/2/>
2019-04-29 14:15:32 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/1/>
2019-04-29 14:15:32 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121181004>
2019-04-29 14:15:32 engine.py[line:202] ERROR: 'RedisBackupRequest' object has no attribute 'get_length'
Traceback (most recent call last):
  File "D:\David\Desktop\spider_plus_fw\spider_plus\core\engine.py", line 200, in _error_callback
    raise exception  # 抛出异常后, 才能被日志进行完整记录下来
  File "c:\python36\Lib\multiprocessing\pool.py", line 119, in worker
    result = (True, func(*args, **kwds))
  File "D:\David\Desktop\spider_plus_fw\spider_plus\core\engine.py", line 195, in _execute_request_response_item
    print(self.scheduler._backup_request.get_length())
AttributeError: 'RedisBackupRequest' object has no attribute 'get_length'
2019-04-29 14:15:32 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121163025>
2019-04-29 14:15:32 engine.py[line:202] ERROR: 'RedisBackupRequest' object has no attribute 'get_length'
Traceback (most recent call last):
  File "D:\David\Desktop\spider_plus_fw\spider_plus\core\engine.py", line 200, in _error_callback
    raise exception  # 抛出异常后, 才能被日志进行完整记录下来
  File "c:\python36\Lib\multiprocessing\pool.py", line 119, in worker
    result = (True, func(*args, **kwds))
  File "D:\David\Desktop\spider_plus_fw\spider_plus\core\engine.py", line 195, in _execute_request_response_item
    print(self.scheduler._backup_request.get_length())
AttributeError: 'RedisBackupRequest' object has no attribute 'get_length'
2019-04-29 14:15:32 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/3/>
2019-04-29 14:15:32 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121190259>
2019-04-29 14:15:32 engine.py[line:202] ERROR: 'RedisBackupRequest' object has no attribute 'get_length'
Traceback (most recent call last):
  File "D:\David\Desktop\spider_plus_fw\spider_plus\core\engine.py", line 200, in _error_callback
    raise exception  # 抛出异常后, 才能被日志进行完整记录下来
  File "c:\python36\Lib\multiprocessing\pool.py", line 119, in worker
    result = (True, func(*args, **kwds))
  File "D:\David\Desktop\spider_plus_fw\spider_plus\core\engine.py", line 195, in _execute_request_response_item
    print(self.scheduler._backup_request.get_length())
AttributeError: 'RedisBackupRequest' object has no attribute 'get_length'
2019-04-29 14:15:32 downloader.py[line:26] INFO: <200 https://www.douban.com/>
2019-04-29 14:15:32 engine.py[line:202] ERROR: 'RedisBackupRequest' object has no attribute 'get_length'
Traceback (most recent call last):
  File "D:\David\Desktop\spider_plus_fw\spider_plus\core\engine.py", line 200, in _error_callback
    raise exception  # 抛出异常后, 才能被日志进行完整记录下来
  File "c:\python36\Lib\multiprocessing\pool.py", line 119, in worker
    result = (True, func(*args, **kwds))
  File "D:\David\Desktop\spider_plus_fw\spider_plus\core\engine.py", line 195, in _execute_request_response_item
    print(self.scheduler._backup_request.get_length())
AttributeError: 'RedisBackupRequest' object has no attribute 'get_length'
2019-04-29 14:15:32 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/4/>
2019-04-29 14:15:32 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/5/>
2019-04-29 14:15:32 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/6/>
2019-04-29 14:15:32 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/7/>
2019-04-29 14:15:32 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/8/>
2019-04-29 14:15:32 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/9/>
2019-04-29 14:15:32 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/10/>
2019-04-29 14:15:32 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/11/>
2019-04-29 14:15:32 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/12/>
2019-04-29 14:15:32 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/13/>
2019-04-29 14:16:30 engine.py[line:81] INFO: 爬虫启动: 2019-04-29 14:16:30.718248
2019-04-29 14:16:30 engine.py[line:82] INFO: 当前启动的爬虫: ['spiders.baidu.BaiduSpider', 'spiders.qiubai.QiubaiSpider']
2019-04-29 14:16:30 engine.py[line:83] INFO: 当前开启的管道: ['pipelines.BaiduPipeline', 'pipelines.QiubaiPipeline']
2019-04-29 14:16:30 engine.py[line:84] INFO: 当前开启的下载器中间件: ['spider_middlewares.TestSpiderMiddleware1']
2019-04-29 14:16:30 engine.py[line:85] INFO: 当前开启的爬虫中间件: ['downloader_middlewares.TestDownloaderMiddleware2']
2019-04-29 14:16:32 scheduler.py[line:106] INFO: 添加新的请求: <http://www.douban.com>
2019-04-29 14:16:32 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/1/>
2019-04-29 14:16:33 scheduler.py[line:111] INFO: 发现重复的请求：<GET http://www.douban.com>
2019-04-29 14:16:33 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/2/>
2019-04-29 14:16:34 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/1/>
2019-04-29 14:16:34 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/2/>
2019-04-29 14:16:34 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121163025>
2019-04-29 14:16:34 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121181004>
2019-04-29 14:16:34 downloader.py[line:26] INFO: <200 https://www.douban.com/>
2019-04-29 14:16:34 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121181004>
2019-04-29 14:16:34 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121163025>
2019-04-29 14:16:34 scheduler.py[line:106] INFO: 添加新的请求: <http://www.baidu.com>
2019-04-29 14:16:34 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/3/>
2019-04-29 14:16:34 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/4/>
2019-04-29 14:16:34 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/5/>
2019-04-29 14:16:34 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/6/>
2019-04-29 14:16:34 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/7/>
2019-04-29 14:16:34 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/8/>
2019-04-29 14:16:34 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/9/>
2019-04-29 14:16:34 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/10/>
2019-04-29 14:16:34 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/11/>
2019-04-29 14:16:34 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/12/>
2019-04-29 14:16:34 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/13/>
2019-04-29 14:16:34 downloader.py[line:26] INFO: <200 http://www.baidu.com/>
2019-04-29 14:16:35 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/3/>
2019-04-29 14:16:35 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121190259>
2019-04-29 14:16:35 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/4/>
2019-04-29 14:16:35 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/5/>
2019-04-29 14:16:35 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121214356>
2019-04-29 14:16:35 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/6/>
2019-04-29 14:16:35 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121189565>
2019-04-29 14:16:35 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121196548>
2019-04-29 14:16:35 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/7/>
2019-04-29 14:16:35 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121201777>
2019-04-29 14:16:35 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/8/>
2019-04-29 14:16:35 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121200112>
2019-04-29 14:16:35 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/10/>
2019-04-29 14:16:35 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121215744>
2019-04-29 14:16:35 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/11/>
2019-04-29 14:16:35 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/9/>
2019-04-29 14:16:35 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121179223>
2019-04-29 14:16:35 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121219452>
2019-04-29 14:16:35 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/12/>
2019-04-29 14:16:35 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121173890>
2019-04-29 14:16:35 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/13/>
2019-04-29 14:16:35 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121225237>
2019-04-29 14:16:35 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121190259>
2019-04-29 14:16:35 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121189565>
2019-04-29 14:16:35 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121196548>
2019-04-29 14:16:35 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121214356>
2019-04-29 14:16:35 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121201777>
2019-04-29 14:16:35 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121200112>
2019-04-29 14:16:35 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121215744>
2019-04-29 14:16:35 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121219452>
2019-04-29 14:16:35 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121179223>
2019-04-29 14:16:36 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121173890>
2019-04-29 14:16:36 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121225237>
2019-04-29 14:17:12 engine.py[line:81] INFO: 爬虫启动: 2019-04-29 14:17:12.222245
2019-04-29 14:17:12 engine.py[line:82] INFO: 当前启动的爬虫: ['spiders.baidu.BaiduSpider', 'spiders.qiubai.QiubaiSpider']
2019-04-29 14:17:12 engine.py[line:83] INFO: 当前开启的管道: ['pipelines.BaiduPipeline', 'pipelines.QiubaiPipeline']
2019-04-29 14:17:12 engine.py[line:84] INFO: 当前开启的下载器中间件: ['spider_middlewares.TestSpiderMiddleware1']
2019-04-29 14:17:12 engine.py[line:85] INFO: 当前开启的爬虫中间件: ['downloader_middlewares.TestDownloaderMiddleware2']
2019-04-29 14:17:14 scheduler.py[line:106] INFO: 添加新的请求: <http://www.douban.com>
2019-04-29 14:17:14 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/1/>
2019-04-29 14:17:15 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/2/>
2019-04-29 14:17:15 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/3/>
2019-04-29 14:17:15 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/4/>
2019-04-29 14:17:15 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/5/>
2019-04-29 14:17:15 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/6/>
2019-04-29 14:17:15 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/7/>
2019-04-29 14:17:15 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/8/>
2019-04-29 14:17:15 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/9/>
2019-04-29 14:17:15 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/10/>
2019-04-29 14:17:15 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/11/>
2019-04-29 14:17:15 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/12/>
2019-04-29 14:17:15 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/13/>
2019-04-29 14:17:15 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/3/>
2019-04-29 14:17:15 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121190259>
2019-04-29 14:17:15 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/1/>
2019-04-29 14:17:15 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/2/>
2019-04-29 14:17:15 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121163025>
2019-04-29 14:17:15 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121181004>
2019-04-29 14:17:15 downloader.py[line:26] INFO: <200 https://www.douban.com/>
2019-04-29 14:17:15 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/4/>
2019-04-29 14:17:15 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121214356>
2019-04-29 14:17:15 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/6/>
2019-04-29 14:17:15 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/5/>
2019-04-29 14:17:15 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121196548>
2019-04-29 14:17:15 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121189565>
2019-04-29 14:17:16 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/7/>
2019-04-29 14:17:16 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121201777>
2019-04-29 14:17:16 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/8/>
2019-04-29 14:17:16 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121200112>
2019-04-29 14:17:16 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/9/>
2019-04-29 14:17:16 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121219452>
2019-04-29 14:17:16 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/10/>
2019-04-29 14:17:16 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121215744>
2019-04-29 14:17:16 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/11/>
2019-04-29 14:17:16 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121179223>
2019-04-29 14:17:16 scheduler.py[line:111] INFO: 发现重复的请求：<GET http://www.douban.com>
2019-04-29 14:17:16 scheduler.py[line:106] INFO: 添加新的请求: <http://www.baidu.com>
2019-04-29 14:17:16 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/12/>
2019-04-29 14:17:16 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121173890>
2019-04-29 14:17:16 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/13/>
2019-04-29 14:17:16 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121225237>
2019-04-29 14:17:16 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121190259>
2019-04-29 14:17:16 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121163025>
2019-04-29 14:17:16 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121181004>
2019-04-29 14:17:16 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121214356>
2019-04-29 14:17:16 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121196548>
2019-04-29 14:17:16 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121189565>
2019-04-29 14:17:16 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121201777>
2019-04-29 14:17:16 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121200112>
2019-04-29 14:17:16 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121219452>
2019-04-29 14:17:16 downloader.py[line:26] INFO: <200 http://www.baidu.com/>
2019-04-29 14:17:16 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121215744>
2019-04-29 14:17:16 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121179223>
2019-04-29 14:17:17 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121173890>
2019-04-29 14:17:17 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121225237>
2019-04-29 14:17:49 engine.py[line:81] INFO: 爬虫启动: 2019-04-29 14:17:49.633252
2019-04-29 14:17:49 engine.py[line:82] INFO: 当前启动的爬虫: ['spiders.baidu.BaiduSpider', 'spiders.qiubai.QiubaiSpider']
2019-04-29 14:17:49 engine.py[line:83] INFO: 当前开启的管道: ['pipelines.BaiduPipeline', 'pipelines.QiubaiPipeline']
2019-04-29 14:17:49 engine.py[line:84] INFO: 当前开启的下载器中间件: ['spider_middlewares.TestSpiderMiddleware1']
2019-04-29 14:17:49 engine.py[line:85] INFO: 当前开启的爬虫中间件: ['downloader_middlewares.TestDownloaderMiddleware2']
2019-04-29 14:17:51 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/1/>
2019-04-29 14:17:51 scheduler.py[line:106] INFO: 添加新的请求: <http://www.douban.com>
2019-04-29 14:17:52 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/2/>
2019-04-29 14:17:52 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/3/>
2019-04-29 14:17:52 scheduler.py[line:111] INFO: 发现重复的请求：<GET http://www.douban.com>
2019-04-29 14:17:52 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/4/>
2019-04-29 14:17:52 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/5/>
2019-04-29 14:17:52 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/6/>
2019-04-29 14:17:52 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/7/>
2019-04-29 14:17:52 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/8/>
2019-04-29 14:17:52 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/9/>
2019-04-29 14:17:52 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/10/>
2019-04-29 14:17:52 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/11/>
2019-04-29 14:17:52 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/12/>
2019-04-29 14:17:52 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/13/>
2019-04-29 14:17:52 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/2/>
2019-04-29 14:17:52 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121181004>
2019-04-29 14:17:52 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/1/>
2019-04-29 14:17:52 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121163025>
2019-04-29 14:17:52 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/3/>
2019-04-29 14:17:52 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121190259>
2019-04-29 14:17:53 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/5/>
2019-04-29 14:17:53 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121189565>
2019-04-29 14:17:53 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/4/>
2019-04-29 14:17:53 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121214356>
2019-04-29 14:17:53 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/6/>
2019-04-29 14:17:53 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121196548>
2019-04-29 14:17:53 downloader.py[line:26] INFO: <200 https://www.douban.com/>
2019-04-29 14:17:53 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/7/>
2019-04-29 14:17:53 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/8/>
2019-04-29 14:17:53 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121201777>
2019-04-29 14:17:53 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121200112>
2019-04-29 14:17:53 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/9/>
2019-04-29 14:17:53 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121219452>
2019-04-29 14:17:53 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/10/>
2019-04-29 14:17:53 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121215744>
2019-04-29 14:17:53 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/12/>
2019-04-29 14:17:53 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/11/>
2019-04-29 14:17:53 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121173890>
2019-04-29 14:17:53 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121179223>
2019-04-29 14:17:53 scheduler.py[line:106] INFO: 添加新的请求: <http://www.baidu.com>
2019-04-29 14:17:53 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/13/>
2019-04-29 14:17:53 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121225237>
2019-04-29 14:17:53 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121181004>
2019-04-29 14:17:53 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121163025>
2019-04-29 14:17:53 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121189565>
2019-04-29 14:17:53 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121190259>
2019-04-29 14:17:54 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121214356>
2019-04-29 14:17:54 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121196548>
2019-04-29 14:17:54 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121201777>
2019-04-29 14:17:54 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121200112>
2019-04-29 14:17:54 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121219452>
2019-04-29 14:17:54 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121215744>
2019-04-29 14:17:54 downloader.py[line:26] INFO: <200 http://www.baidu.com/>
2019-04-29 14:17:54 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121173890>
2019-04-29 14:17:54 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121179223>
2019-04-29 14:17:54 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121225237>
2019-04-29 14:17:54 engine.py[line:88] INFO: 爬虫结束: 2019-04-29 14:17:54.683245
2019-04-29 14:17:54 engine.py[line:89] INFO: 爬虫运行时间: 5.049993
2019-04-29 14:17:54 engine.py[line:92] INFO: 总的请求数量: 29个
2019-04-29 14:17:54 engine.py[line:94] INFO: 总的响应数量: 28个
2019-04-29 14:17:54 engine.py[line:96] INFO: 总的重复数量: 1个
2019-04-29 14:17:54 engine.py[line:98] INFO: 总的 start_requests 数量: 2个
2019-04-29 14:19:16 engine.py[line:81] INFO: 爬虫启动: 2019-04-29 14:19:16.196249
2019-04-29 14:19:16 engine.py[line:82] INFO: 当前启动的爬虫: ['spiders.baidu.BaiduSpider', 'spiders.qiubai.QiubaiSpider']
2019-04-29 14:19:16 engine.py[line:83] INFO: 当前开启的管道: ['pipelines.BaiduPipeline', 'pipelines.QiubaiPipeline']
2019-04-29 14:19:16 engine.py[line:84] INFO: 当前开启的下载器中间件: ['spider_middlewares.TestSpiderMiddleware1']
2019-04-29 14:19:16 engine.py[line:85] INFO: 当前开启的爬虫中间件: ['downloader_middlewares.TestDownloaderMiddleware2']
2019-04-29 14:19:18 scheduler.py[line:106] INFO: 添加新的请求: <http://www.douban.com>
2019-04-29 14:19:18 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/1/>
2019-04-29 14:19:19 scheduler.py[line:111] INFO: 发现重复的请求：<GET http://www.douban.com>
2019-04-29 14:19:19 scheduler.py[line:106] INFO: 添加新的请求: <http://www.baidu.com>
2019-04-29 14:19:19 scheduler.py[line:106] INFO: 添加新的请求: <https://www.google.com>
2019-04-29 14:19:19 downloader.py[line:26] INFO: <200 http://www.baidu.com/>
2019-04-29 14:19:19 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/1/>
2019-04-29 14:19:19 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121163025>
2019-04-29 14:19:19 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121163025>
2019-04-29 14:19:19 downloader.py[line:26] INFO: <200 https://www.douban.com/>
2019-04-29 14:19:20 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/2/>
2019-04-29 14:19:20 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/3/>
2019-04-29 14:19:20 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/4/>
2019-04-29 14:19:20 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/5/>
2019-04-29 14:19:20 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/6/>
2019-04-29 14:19:20 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/7/>
2019-04-29 14:19:20 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/8/>
2019-04-29 14:19:20 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/9/>
2019-04-29 14:19:20 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/10/>
2019-04-29 14:19:20 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/11/>
2019-04-29 14:19:20 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/12/>
2019-04-29 14:19:20 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/13/>
2019-04-29 14:19:20 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/2/>
2019-04-29 14:19:20 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121181004>
2019-04-29 14:19:20 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/4/>
2019-04-29 14:19:20 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/3/>
2019-04-29 14:19:20 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121214356>
2019-04-29 14:19:20 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/5/>
2019-04-29 14:19:20 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121190259>
2019-04-29 14:19:20 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121189565>
2019-04-29 14:19:20 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/6/>
2019-04-29 14:19:20 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121196548>
2019-04-29 14:19:20 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/8/>
2019-04-29 14:19:20 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/7/>
2019-04-29 14:19:20 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121200112>
2019-04-29 14:19:20 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121201777>
2019-04-29 14:19:20 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/9/>
2019-04-29 14:19:20 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121219452>
2019-04-29 14:19:20 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/10/>
2019-04-29 14:19:20 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121215744>
2019-04-29 14:19:21 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/11/>
2019-04-29 14:19:21 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121179223>
2019-04-29 14:19:21 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/12/>
2019-04-29 14:19:21 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121173890>
2019-04-29 14:19:21 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/13/>
2019-04-29 14:19:21 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121225237>
2019-04-29 14:19:21 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121181004>
2019-04-29 14:19:21 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121190259>
2019-04-29 14:19:21 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121214356>
2019-04-29 14:19:21 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121189565>
2019-04-29 14:19:21 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121196548>
2019-04-29 14:19:21 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121200112>
2019-04-29 14:19:21 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121201777>
2019-04-29 14:19:21 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121219452>
2019-04-29 14:19:21 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121215744>
2019-04-29 14:19:21 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121179223>
2019-04-29 14:19:21 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121173890>
2019-04-29 14:19:21 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121225237>
2019-04-29 14:19:40 engine.py[line:202] ERROR: HTTPSConnectionPool(host='www.google.com', port=443): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x00000196D08EF4E0>: Failed to establish a new connection: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond',))
Traceback (most recent call last):
  File "C:\Users\David\Envs\python3_spider\lib\site-packages\urllib3\connection.py", line 141, in _new_conn
    (self.host, self.port), self.timeout, **extra_kw)
  File "C:\Users\David\Envs\python3_spider\lib\site-packages\urllib3\util\connection.py", line 83, in create_connection
    raise err
  File "C:\Users\David\Envs\python3_spider\lib\site-packages\urllib3\util\connection.py", line 73, in create_connection
    sock.connect(sa)
TimeoutError: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\David\Envs\python3_spider\lib\site-packages\urllib3\connectionpool.py", line 601, in urlopen
    chunked=chunked)
  File "C:\Users\David\Envs\python3_spider\lib\site-packages\urllib3\connectionpool.py", line 346, in _make_request
    self._validate_conn(conn)
  File "C:\Users\David\Envs\python3_spider\lib\site-packages\urllib3\connectionpool.py", line 850, in _validate_conn
    conn.connect()
  File "C:\Users\David\Envs\python3_spider\lib\site-packages\urllib3\connection.py", line 284, in connect
    conn = self._new_conn()
  File "C:\Users\David\Envs\python3_spider\lib\site-packages\urllib3\connection.py", line 150, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.VerifiedHTTPSConnection object at 0x00000196D08EF4E0>: Failed to establish a new connection: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\David\Envs\python3_spider\lib\site-packages\requests\adapters.py", line 440, in send
    timeout=timeout
  File "C:\Users\David\Envs\python3_spider\lib\site-packages\urllib3\connectionpool.py", line 639, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "C:\Users\David\Envs\python3_spider\lib\site-packages\urllib3\util\retry.py", line 388, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='www.google.com', port=443): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x00000196D08EF4E0>: Failed to establish a new connection: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond',))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\David\Desktop\spider_plus_fw\spider_plus\core\engine.py", line 200, in _error_callback
    raise exception  # 抛出异常后, 才能被日志进行完整记录下来
  File "c:\python36\Lib\multiprocessing\pool.py", line 119, in worker
    result = (True, func(*args, **kwds))
  File "D:\David\Desktop\spider_plus_fw\spider_plus\core\engine.py", line 144, in _execute_request_response_item
    response = self.downloader.get_response(request)
  File "D:\David\Desktop\spider_plus_fw\spider_plus\core\downloader.py", line 19, in get_response
    resp = requests.get(request.url, headers=request.headers, params=request.params)
  File "C:\Users\David\Envs\python3_spider\lib\site-packages\requests\api.py", line 72, in get
    return request('get', url, params=params, **kwargs)
  File "C:\Users\David\Envs\python3_spider\lib\site-packages\requests\api.py", line 58, in request
    return session.request(method=method, url=url, **kwargs)
  File "C:\Users\David\Envs\python3_spider\lib\site-packages\requests\sessions.py", line 508, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\David\Envs\python3_spider\lib\site-packages\requests\sessions.py", line 618, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\David\Envs\python3_spider\lib\site-packages\requests\adapters.py", line 508, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPSConnectionPool(host='www.google.com', port=443): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x00000196D08EF4E0>: Failed to establish a new connection: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond',))
2019-04-29 14:21:57 engine.py[line:81] INFO: 爬虫启动: 2019-04-29 14:21:57.141244
2019-04-29 14:21:57 engine.py[line:82] INFO: 当前启动的爬虫: ['spiders.baidu.BaiduSpider', 'spiders.qiubai.QiubaiSpider']
2019-04-29 14:21:57 engine.py[line:83] INFO: 当前开启的管道: ['pipelines.BaiduPipeline', 'pipelines.QiubaiPipeline']
2019-04-29 14:21:57 engine.py[line:84] INFO: 当前开启的下载器中间件: ['spider_middlewares.TestSpiderMiddleware1']
2019-04-29 14:21:57 engine.py[line:85] INFO: 当前开启的爬虫中间件: ['downloader_middlewares.TestDownloaderMiddleware2']
2019-04-29 14:21:59 scheduler.py[line:106] INFO: 添加新的请求: <http://www.douban.com>
2019-04-29 14:21:59 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/1/>
2019-04-29 14:22:00 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/2/>
2019-04-29 14:22:00 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/3/>
2019-04-29 14:22:00 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/4/>
2019-04-29 14:22:00 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/5/>
2019-04-29 14:22:00 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/6/>
2019-04-29 14:22:00 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/7/>
2019-04-29 14:22:00 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/8/>
2019-04-29 14:22:00 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/9/>
2019-04-29 14:22:00 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/10/>
2019-04-29 14:22:00 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/11/>
2019-04-29 14:22:00 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/12/>
2019-04-29 14:22:00 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/13/>
2019-04-29 14:22:00 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/2/>
2019-04-29 14:22:00 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121219729>
2019-04-29 14:22:00 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/1/>
2019-04-29 14:22:00 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121178592>
2019-04-29 14:22:00 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/3/>
2019-04-29 14:22:00 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121189462>
2019-04-29 14:22:00 downloader.py[line:26] INFO: <200 https://www.douban.com/>
2019-04-29 14:22:00 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/4/>
2019-04-29 14:22:00 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121225263>
2019-04-29 14:22:00 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/5/>
2019-04-29 14:22:00 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121183666>
2019-04-29 14:22:00 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/6/>
2019-04-29 14:22:00 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121129223>
2019-04-29 14:22:01 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/7/>
2019-04-29 14:22:01 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/9/>
2019-04-29 14:22:01 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121196802>
2019-04-29 14:22:01 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/8/>
2019-04-29 14:22:01 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121123913>
2019-04-29 14:22:01 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121197180>
2019-04-29 14:22:01 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/10/>
2019-04-29 14:22:01 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121185262>
2019-04-29 14:22:01 scheduler.py[line:111] INFO: 发现重复的请求：<GET http://www.douban.com>
2019-04-29 14:22:01 scheduler.py[line:106] INFO: 添加新的请求: <http://www.baidu.com>
2019-04-29 14:22:01 scheduler.py[line:106] INFO: 添加新的请求: <https://www.google.com>
2019-04-29 14:22:01 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/11/>
2019-04-29 14:22:01 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121186350>
2019-04-29 14:22:01 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/12/>
2019-04-29 14:22:01 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121194954>
2019-04-29 14:22:01 downloader.py[line:26] INFO: <503 https://www.qiushibaike.com/article/121219729>
2019-04-29 14:22:01 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/13/>
2019-04-29 14:22:01 engine.py[line:202] ERROR: list index out of range
Traceback (most recent call last):
  File "D:\David\Desktop\spider_plus_fw\spider_plus\core\engine.py", line 200, in _error_callback
    raise exception  # 抛出异常后, 才能被日志进行完整记录下来
  File "c:\python36\Lib\multiprocessing\pool.py", line 119, in worker
    result = (True, func(*args, **kwds))
  File "D:\David\Desktop\spider_plus_fw\spider_plus\core\engine.py", line 164, in _execute_request_response_item
    for result in parse(response):
  File "D:\David\Desktop\spider_plus_fw\spider_project\spiders\qiubai.py", line 36, in parse_detail
    item["pub_time"] = response.xpath('//span[@class="stats-time"]/text()')[0].strip()
IndexError: list index out of range
2019-04-29 14:22:01 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121150456>
2019-04-29 14:22:01 downloader.py[line:26] INFO: <503 https://www.qiushibaike.com/article/121178592>
2019-04-29 14:22:01 engine.py[line:202] ERROR: list index out of range
Traceback (most recent call last):
  File "D:\David\Desktop\spider_plus_fw\spider_plus\core\engine.py", line 200, in _error_callback
    raise exception  # 抛出异常后, 才能被日志进行完整记录下来
  File "c:\python36\Lib\multiprocessing\pool.py", line 119, in worker
    result = (True, func(*args, **kwds))
  File "D:\David\Desktop\spider_plus_fw\spider_plus\core\engine.py", line 164, in _execute_request_response_item
    for result in parse(response):
  File "D:\David\Desktop\spider_plus_fw\spider_project\spiders\qiubai.py", line 36, in parse_detail
    item["pub_time"] = response.xpath('//span[@class="stats-time"]/text()')[0].strip()
IndexError: list index out of range
2019-04-29 14:22:01 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121189462>
2019-04-29 14:22:01 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121225263>
2019-04-29 14:22:01 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121183666>
2019-04-29 14:22:01 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121129223>
2019-04-29 14:22:01 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121196802>
2019-04-29 14:22:02 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121123913>
2019-04-29 14:22:02 downloader.py[line:26] INFO: <200 http://www.baidu.com/>
2019-04-29 14:22:02 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121197180>
2019-04-29 14:22:02 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121185262>
2019-04-29 14:22:02 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121186350>
2019-04-29 14:22:02 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121194954>
2019-04-29 14:22:02 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121150456>
2019-04-29 14:22:12 engine.py[line:202] ERROR: HTTPSConnectionPool(host='www.google.com', port=443): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.VerifiedHTTPSConnection object at 0x0000021442704320>, 'Connection to www.google.com timed out. (connect timeout=10)'))
Traceback (most recent call last):
  File "C:\Users\David\Envs\python3_spider\lib\site-packages\urllib3\connection.py", line 141, in _new_conn
    (self.host, self.port), self.timeout, **extra_kw)
  File "C:\Users\David\Envs\python3_spider\lib\site-packages\urllib3\util\connection.py", line 83, in create_connection
    raise err
  File "C:\Users\David\Envs\python3_spider\lib\site-packages\urllib3\util\connection.py", line 73, in create_connection
    sock.connect(sa)
socket.timeout: timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\David\Envs\python3_spider\lib\site-packages\urllib3\connectionpool.py", line 601, in urlopen
    chunked=chunked)
  File "C:\Users\David\Envs\python3_spider\lib\site-packages\urllib3\connectionpool.py", line 346, in _make_request
    self._validate_conn(conn)
  File "C:\Users\David\Envs\python3_spider\lib\site-packages\urllib3\connectionpool.py", line 850, in _validate_conn
    conn.connect()
  File "C:\Users\David\Envs\python3_spider\lib\site-packages\urllib3\connection.py", line 284, in connect
    conn = self._new_conn()
  File "C:\Users\David\Envs\python3_spider\lib\site-packages\urllib3\connection.py", line 146, in _new_conn
    (self.host, self.timeout))
urllib3.exceptions.ConnectTimeoutError: (<urllib3.connection.VerifiedHTTPSConnection object at 0x0000021442704320>, 'Connection to www.google.com timed out. (connect timeout=10)')

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\David\Envs\python3_spider\lib\site-packages\requests\adapters.py", line 440, in send
    timeout=timeout
  File "C:\Users\David\Envs\python3_spider\lib\site-packages\urllib3\connectionpool.py", line 639, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "C:\Users\David\Envs\python3_spider\lib\site-packages\urllib3\util\retry.py", line 388, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='www.google.com', port=443): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.VerifiedHTTPSConnection object at 0x0000021442704320>, 'Connection to www.google.com timed out. (connect timeout=10)'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\David\Desktop\spider_plus_fw\spider_plus\core\engine.py", line 200, in _error_callback
    raise exception  # 抛出异常后, 才能被日志进行完整记录下来
  File "c:\python36\Lib\multiprocessing\pool.py", line 119, in worker
    result = (True, func(*args, **kwds))
  File "D:\David\Desktop\spider_plus_fw\spider_plus\core\engine.py", line 144, in _execute_request_response_item
    response = self.downloader.get_response(request)
  File "D:\David\Desktop\spider_plus_fw\spider_plus\core\downloader.py", line 19, in get_response
    resp = requests.get(request.url, headers=request.headers, params=request.params, timeout=10)
  File "C:\Users\David\Envs\python3_spider\lib\site-packages\requests\api.py", line 72, in get
    return request('get', url, params=params, **kwargs)
  File "C:\Users\David\Envs\python3_spider\lib\site-packages\requests\api.py", line 58, in request
    return session.request(method=method, url=url, **kwargs)
  File "C:\Users\David\Envs\python3_spider\lib\site-packages\requests\sessions.py", line 508, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\David\Envs\python3_spider\lib\site-packages\requests\sessions.py", line 618, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\David\Envs\python3_spider\lib\site-packages\requests\adapters.py", line 496, in send
    raise ConnectTimeout(e, request=request)
requests.exceptions.ConnectTimeout: HTTPSConnectionPool(host='www.google.com', port=443): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.VerifiedHTTPSConnection object at 0x0000021442704320>, 'Connection to www.google.com timed out. (connect timeout=10)'))
2019-04-29 14:23:23 engine.py[line:81] INFO: 爬虫启动: 2019-04-29 14:23:23.935243
2019-04-29 14:23:23 engine.py[line:82] INFO: 当前启动的爬虫: ['spiders.baidu.BaiduSpider', 'spiders.qiubai.QiubaiSpider']
2019-04-29 14:23:23 engine.py[line:83] INFO: 当前开启的管道: ['pipelines.BaiduPipeline', 'pipelines.QiubaiPipeline']
2019-04-29 14:23:23 engine.py[line:84] INFO: 当前开启的下载器中间件: ['spider_middlewares.TestSpiderMiddleware1']
2019-04-29 14:23:23 engine.py[line:85] INFO: 当前开启的爬虫中间件: ['downloader_middlewares.TestDownloaderMiddleware2']
2019-04-29 14:23:25 scheduler.py[line:106] INFO: 添加新的请求: <http://www.douban.com>
2019-04-29 14:23:25 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/1/>
2019-04-29 14:23:27 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/2/>
2019-04-29 14:23:27 scheduler.py[line:111] INFO: 发现重复的请求：<GET http://www.douban.com>
2019-04-29 14:23:27 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/2/>
2019-04-29 14:23:27 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121219729>
2019-04-29 14:23:27 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/1/>
2019-04-29 14:23:27 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121178592>
2019-04-29 14:23:27 downloader.py[line:26] INFO: <200 https://www.douban.com/>
2019-04-29 14:23:27 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121219729>
2019-04-29 14:23:27 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121178592>
2019-04-29 14:23:28 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/3/>
2019-04-29 14:23:28 scheduler.py[line:106] INFO: 添加新的请求: <http://www.baidu.com>
2019-04-29 14:23:28 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/4/>
2019-04-29 14:23:28 scheduler.py[line:106] INFO: 添加新的请求: <https://www.google.com>
2019-04-29 14:23:28 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/5/>
2019-04-29 14:23:28 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/6/>
2019-04-29 14:23:28 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/7/>
2019-04-29 14:23:28 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/8/>
2019-04-29 14:23:28 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/9/>
2019-04-29 14:23:28 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/10/>
2019-04-29 14:23:28 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/11/>
2019-04-29 14:23:28 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/12/>
2019-04-29 14:23:28 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/13/>
2019-04-29 14:23:28 downloader.py[line:26] INFO: <200 http://www.baidu.com/>
2019-04-29 14:23:28 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/3/>
2019-04-29 14:23:28 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/4/>
2019-04-29 14:23:28 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/5/>
2019-04-29 14:23:28 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121189462>
2019-04-29 14:23:28 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121225263>
2019-04-29 14:23:28 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121183666>
2019-04-29 14:23:28 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/6/>
2019-04-29 14:23:28 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121129223>
2019-04-29 14:23:28 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/7/>
2019-04-29 14:23:28 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121196802>
2019-04-29 14:23:28 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/9/>
2019-04-29 14:23:28 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121123913>
2019-04-29 14:23:28 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/8/>
2019-04-29 14:23:28 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121197180>
2019-04-29 14:23:28 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/10/>
2019-04-29 14:23:28 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121185262>
2019-04-29 14:23:28 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/12/>
2019-04-29 14:23:28 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/11/>
2019-04-29 14:23:28 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121194954>
2019-04-29 14:23:28 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121186350>
2019-04-29 14:23:28 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/8hr/page/13/>
2019-04-29 14:23:28 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121150456>
2019-04-29 14:23:28 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121189462>
2019-04-29 14:23:29 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121225263>
2019-04-29 14:23:29 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121183666>
2019-04-29 14:23:29 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121129223>
2019-04-29 14:23:29 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121196802>
2019-04-29 14:23:29 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121123913>
2019-04-29 14:23:29 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121197180>
2019-04-29 14:23:29 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121185262>
2019-04-29 14:23:29 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121194954>
2019-04-29 14:23:29 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121186350>
2019-04-29 14:23:29 downloader.py[line:26] INFO: <200 https://www.qiushibaike.com/article/121150456>
2019-04-29 14:23:38 engine.py[line:202] ERROR: HTTPSConnectionPool(host='www.google.com', port=443): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.VerifiedHTTPSConnection object at 0x0000016C8034CCF8>, 'Connection to www.google.com timed out. (connect timeout=10)'))
Traceback (most recent call last):
  File "C:\Users\David\Envs\python3_spider\lib\site-packages\urllib3\connection.py", line 141, in _new_conn
    (self.host, self.port), self.timeout, **extra_kw)
  File "C:\Users\David\Envs\python3_spider\lib\site-packages\urllib3\util\connection.py", line 83, in create_connection
    raise err
  File "C:\Users\David\Envs\python3_spider\lib\site-packages\urllib3\util\connection.py", line 73, in create_connection
    sock.connect(sa)
socket.timeout: timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\David\Envs\python3_spider\lib\site-packages\urllib3\connectionpool.py", line 601, in urlopen
    chunked=chunked)
  File "C:\Users\David\Envs\python3_spider\lib\site-packages\urllib3\connectionpool.py", line 346, in _make_request
    self._validate_conn(conn)
  File "C:\Users\David\Envs\python3_spider\lib\site-packages\urllib3\connectionpool.py", line 850, in _validate_conn
    conn.connect()
  File "C:\Users\David\Envs\python3_spider\lib\site-packages\urllib3\connection.py", line 284, in connect
    conn = self._new_conn()
  File "C:\Users\David\Envs\python3_spider\lib\site-packages\urllib3\connection.py", line 146, in _new_conn
    (self.host, self.timeout))
urllib3.exceptions.ConnectTimeoutError: (<urllib3.connection.VerifiedHTTPSConnection object at 0x0000016C8034CCF8>, 'Connection to www.google.com timed out. (connect timeout=10)')

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\David\Envs\python3_spider\lib\site-packages\requests\adapters.py", line 440, in send
    timeout=timeout
  File "C:\Users\David\Envs\python3_spider\lib\site-packages\urllib3\connectionpool.py", line 639, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "C:\Users\David\Envs\python3_spider\lib\site-packages\urllib3\util\retry.py", line 388, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='www.google.com', port=443): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.VerifiedHTTPSConnection object at 0x0000016C8034CCF8>, 'Connection to www.google.com timed out. (connect timeout=10)'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\David\Desktop\spider_plus_fw\spider_plus\core\engine.py", line 200, in _error_callback
    raise exception  # 抛出异常后, 才能被日志进行完整记录下来
  File "c:\python36\Lib\multiprocessing\pool.py", line 119, in worker
    result = (True, func(*args, **kwds))
  File "D:\David\Desktop\spider_plus_fw\spider_plus\core\engine.py", line 144, in _execute_request_response_item
    response = self.downloader.get_response(request)
  File "D:\David\Desktop\spider_plus_fw\spider_plus\core\downloader.py", line 19, in get_response
    resp = requests.get(request.url, headers=request.headers, params=request.params, timeout=10)
  File "C:\Users\David\Envs\python3_spider\lib\site-packages\requests\api.py", line 72, in get
    return request('get', url, params=params, **kwargs)
  File "C:\Users\David\Envs\python3_spider\lib\site-packages\requests\api.py", line 58, in request
    return session.request(method=method, url=url, **kwargs)
  File "C:\Users\David\Envs\python3_spider\lib\site-packages\requests\sessions.py", line 508, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\David\Envs\python3_spider\lib\site-packages\requests\sessions.py", line 618, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\David\Envs\python3_spider\lib\site-packages\requests\adapters.py", line 496, in send
    raise ConnectTimeout(e, request=request)
requests.exceptions.ConnectTimeout: HTTPSConnectionPool(host='www.google.com', port=443): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.VerifiedHTTPSConnection object at 0x0000016C8034CCF8>, 'Connection to www.google.com timed out. (connect timeout=10)'))
2019-04-29 14:26:25 engine.py[line:81] INFO: 爬虫启动: 2019-04-29 14:26:25.809245
2019-04-29 14:26:25 engine.py[line:82] INFO: 当前启动的爬虫: ['spiders.baidu.BaiduSpider', 'spiders.qiubai.QiubaiSpider']
2019-04-29 14:26:25 engine.py[line:83] INFO: 当前开启的管道: ['pipelines.BaiduPipeline', 'pipelines.QiubaiPipeline']
2019-04-29 14:26:25 engine.py[line:84] INFO: 当前开启的下载器中间件: ['spider_middlewares.TestSpiderMiddleware1']
2019-04-29 14:26:25 engine.py[line:85] INFO: 当前开启的爬虫中间件: ['downloader_middlewares.TestDownloaderMiddleware2']
2019-04-29 14:26:27 scheduler.py[line:106] INFO: 添加新的请求: <http://www.douban.com>
2019-04-29 14:26:27 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/1/>
2019-04-29 14:26:28 scheduler.py[line:111] INFO: 发现重复的请求：<GET http://www.douban.com>
2019-04-29 14:26:28 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/2/>
2019-04-29 14:26:28 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/3/>
2019-04-29 14:26:28 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/4/>
2019-04-29 14:26:28 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/5/>
2019-04-29 14:26:29 downloader.py[line:29] INFO: <200 https://www.qiushibaike.com/8hr/page/2/>
2019-04-29 14:26:29 downloader.py[line:29] INFO: <200 https://www.qiushibaike.com/8hr/page/1/>
2019-04-29 14:26:29 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121219729>
2019-04-29 14:26:29 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121178592>
2019-04-29 14:26:29 downloader.py[line:29] INFO: <200 https://www.qiushibaike.com/8hr/page/3/>
2019-04-29 14:26:29 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121189462>
2019-04-29 14:26:29 downloader.py[line:29] INFO: <200 https://www.douban.com/>
2019-04-29 14:26:29 downloader.py[line:29] INFO: <200 https://www.qiushibaike.com/8hr/page/4/>
2019-04-29 14:26:29 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121225263>
2019-04-29 14:26:29 downloader.py[line:29] INFO: <200 https://www.qiushibaike.com/8hr/page/5/>
2019-04-29 14:26:29 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121183666>
2019-04-29 14:26:29 scheduler.py[line:106] INFO: 添加新的请求: <http://www.baidu.com>
2019-04-29 14:26:29 scheduler.py[line:106] INFO: 添加新的请求: <https://www.google.com>
2019-04-29 14:26:29 downloader.py[line:29] INFO: <200 https://www.qiushibaike.com/article/121219729>
2019-04-29 14:26:29 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/6/>
2019-04-29 14:26:29 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/7/>
2019-04-29 14:26:29 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/8/>
2019-04-29 14:26:29 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/9/>
2019-04-29 14:26:29 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/10/>
2019-04-29 14:26:29 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/11/>
2019-04-29 14:26:29 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/12/>
2019-04-29 14:26:29 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/13/>
2019-04-29 14:26:29 downloader.py[line:29] INFO: <200 https://www.qiushibaike.com/article/121178592>
2019-04-29 14:26:30 downloader.py[line:29] INFO: <200 http://www.baidu.com/>
2019-04-29 14:26:30 downloader.py[line:29] INFO: <200 https://www.qiushibaike.com/article/121225263>
2019-04-29 14:26:30 downloader.py[line:29] INFO: <200 https://www.qiushibaike.com/article/121183666>
2019-04-29 14:26:30 downloader.py[line:29] INFO: <200 https://www.qiushibaike.com/8hr/page/6/>
2019-04-29 14:26:30 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121129223>
2019-04-29 14:26:30 downloader.py[line:29] INFO: <200 https://www.qiushibaike.com/8hr/page/7/>
2019-04-29 14:26:30 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121196802>
2019-04-29 14:26:30 downloader.py[line:29] INFO: <200 https://www.qiushibaike.com/article/121189462>
2019-04-29 14:26:30 downloader.py[line:29] INFO: <200 https://www.qiushibaike.com/8hr/page/8/>
2019-04-29 14:26:30 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121197180>
2019-04-29 14:26:30 downloader.py[line:29] INFO: <200 https://www.qiushibaike.com/8hr/page/9/>
2019-04-29 14:26:30 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121123913>
2019-04-29 14:26:30 downloader.py[line:29] INFO: <200 https://www.qiushibaike.com/8hr/page/10/>
2019-04-29 14:26:30 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121185262>
2019-04-29 14:26:30 downloader.py[line:29] INFO: <200 https://www.qiushibaike.com/8hr/page/12/>
2019-04-29 14:26:30 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121194954>
2019-04-29 14:26:30 downloader.py[line:29] INFO: <200 https://www.qiushibaike.com/8hr/page/11/>
2019-04-29 14:26:30 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121186350>
2019-04-29 14:26:30 downloader.py[line:29] INFO: <200 https://www.qiushibaike.com/8hr/page/13/>
2019-04-29 14:26:30 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121150456>
2019-04-29 14:26:30 downloader.py[line:29] INFO: <200 https://www.qiushibaike.com/article/121129223>
2019-04-29 14:26:30 downloader.py[line:29] INFO: <200 https://www.qiushibaike.com/article/121196802>
2019-04-29 14:26:31 downloader.py[line:29] INFO: <200 https://www.qiushibaike.com/article/121197180>
2019-04-29 14:26:31 downloader.py[line:29] INFO: <200 https://www.qiushibaike.com/article/121123913>
2019-04-29 14:26:31 downloader.py[line:29] INFO: <200 https://www.qiushibaike.com/article/121185262>
2019-04-29 14:26:31 downloader.py[line:29] INFO: <200 https://www.qiushibaike.com/article/121194954>
2019-04-29 14:26:31 downloader.py[line:29] INFO: <200 https://www.qiushibaike.com/article/121186350>
2019-04-29 14:26:31 downloader.py[line:29] INFO: <200 https://www.qiushibaike.com/article/121150456>
2019-04-29 14:26:40 downloader.py[line:22] ERROR: 请求出错: <https://www.google.com GET HTTPSConnectionPool(host='www.google.com', port=443): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.VerifiedHTTPSConnection object at 0x0000027C2A27C5F8>, 'Connection to www.google.com timed out. (connect timeout=10)'))>
Traceback (most recent call last):
  File "C:\Users\David\Envs\python3_spider\lib\site-packages\urllib3\connection.py", line 141, in _new_conn
    (self.host, self.port), self.timeout, **extra_kw)
  File "C:\Users\David\Envs\python3_spider\lib\site-packages\urllib3\util\connection.py", line 83, in create_connection
    raise err
  File "C:\Users\David\Envs\python3_spider\lib\site-packages\urllib3\util\connection.py", line 73, in create_connection
    sock.connect(sa)
socket.timeout: timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\David\Envs\python3_spider\lib\site-packages\urllib3\connectionpool.py", line 601, in urlopen
    chunked=chunked)
  File "C:\Users\David\Envs\python3_spider\lib\site-packages\urllib3\connectionpool.py", line 346, in _make_request
    self._validate_conn(conn)
  File "C:\Users\David\Envs\python3_spider\lib\site-packages\urllib3\connectionpool.py", line 850, in _validate_conn
    conn.connect()
  File "C:\Users\David\Envs\python3_spider\lib\site-packages\urllib3\connection.py", line 284, in connect
    conn = self._new_conn()
  File "C:\Users\David\Envs\python3_spider\lib\site-packages\urllib3\connection.py", line 146, in _new_conn
    (self.host, self.timeout))
urllib3.exceptions.ConnectTimeoutError: (<urllib3.connection.VerifiedHTTPSConnection object at 0x0000027C2A27C5F8>, 'Connection to www.google.com timed out. (connect timeout=10)')

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\David\Envs\python3_spider\lib\site-packages\requests\adapters.py", line 440, in send
    timeout=timeout
  File "C:\Users\David\Envs\python3_spider\lib\site-packages\urllib3\connectionpool.py", line 639, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "C:\Users\David\Envs\python3_spider\lib\site-packages\urllib3\util\retry.py", line 388, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='www.google.com', port=443): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.VerifiedHTTPSConnection object at 0x0000027C2A27C5F8>, 'Connection to www.google.com timed out. (connect timeout=10)'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\David\Desktop\spider_plus_fw\spider_plus\core\downloader.py", line 20, in get_response
    resp = requests.get(request.url, headers=request.headers, params=request.params, timeout=10)
  File "C:\Users\David\Envs\python3_spider\lib\site-packages\requests\api.py", line 72, in get
    return request('get', url, params=params, **kwargs)
  File "C:\Users\David\Envs\python3_spider\lib\site-packages\requests\api.py", line 58, in request
    return session.request(method=method, url=url, **kwargs)
  File "C:\Users\David\Envs\python3_spider\lib\site-packages\requests\sessions.py", line 508, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\David\Envs\python3_spider\lib\site-packages\requests\sessions.py", line 618, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\David\Envs\python3_spider\lib\site-packages\requests\adapters.py", line 496, in send
    raise ConnectTimeout(e, request=request)
requests.exceptions.ConnectTimeout: HTTPSConnectionPool(host='www.google.com', port=443): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.VerifiedHTTPSConnection object at 0x0000027C2A27C5F8>, 'Connection to www.google.com timed out. (connect timeout=10)'))
2019-04-29 14:26:40 engine.py[line:202] ERROR: local variable 'resp' referenced before assignment
Traceback (most recent call last):
  File "D:\David\Desktop\spider_plus_fw\spider_plus\core\engine.py", line 200, in _error_callback
    raise exception  # 抛出异常后, 才能被日志进行完整记录下来
  File "c:\python36\Lib\multiprocessing\pool.py", line 119, in worker
    result = (True, func(*args, **kwds))
  File "D:\David\Desktop\spider_plus_fw\spider_plus\core\engine.py", line 144, in _execute_request_response_item
    response = self.downloader.get_response(request)
  File "D:\David\Desktop\spider_plus_fw\spider_plus\core\downloader.py", line 29, in get_response
    logger.info("<{} {}>".format(resp.status_code, resp.request.url))
UnboundLocalError: local variable 'resp' referenced before assignment
2019-04-29 14:27:23 engine.py[line:81] INFO: 爬虫启动: 2019-04-29 14:27:23.820248
2019-04-29 14:27:23 engine.py[line:82] INFO: 当前启动的爬虫: ['spiders.baidu.BaiduSpider', 'spiders.qiubai.QiubaiSpider']
2019-04-29 14:27:23 engine.py[line:83] INFO: 当前开启的管道: ['pipelines.BaiduPipeline', 'pipelines.QiubaiPipeline']
2019-04-29 14:27:23 engine.py[line:84] INFO: 当前开启的下载器中间件: ['spider_middlewares.TestSpiderMiddleware1']
2019-04-29 14:27:23 engine.py[line:85] INFO: 当前开启的爬虫中间件: ['downloader_middlewares.TestDownloaderMiddleware2']
2019-04-29 14:27:25 scheduler.py[line:106] INFO: 添加新的请求: <http://www.douban.com>
2019-04-29 14:27:25 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/1/>
2019-04-29 14:27:26 scheduler.py[line:111] INFO: 发现重复的请求：<GET http://www.douban.com>
2019-04-29 14:27:26 scheduler.py[line:106] INFO: 添加新的请求: <http://www.baidu.com>
2019-04-29 14:27:26 scheduler.py[line:106] INFO: 添加新的请求: <https://www.google.com>
2019-04-29 14:27:26 engine.py[line:202] ERROR: 'Request' object has no attribute 'status_code'
Traceback (most recent call last):
  File "D:\David\Desktop\spider_plus_fw\spider_plus\core\engine.py", line 200, in _error_callback
    raise exception  # 抛出异常后, 才能被日志进行完整记录下来
  File "c:\python36\Lib\multiprocessing\pool.py", line 119, in worker
    result = (True, func(*args, **kwds))
  File "D:\David\Desktop\spider_plus_fw\spider_plus\core\engine.py", line 144, in _execute_request_response_item
    response = self.downloader.get_response(request)
  File "D:\David\Desktop\spider_plus_fw\spider_plus\core\downloader.py", line 29, in get_response
    logger.info("<{} {}>".format(request.status_code, request.request.url))
AttributeError: 'Request' object has no attribute 'status_code'
2019-04-29 14:27:27 engine.py[line:202] ERROR: 'Request' object has no attribute 'status_code'
Traceback (most recent call last):
  File "D:\David\Desktop\spider_plus_fw\spider_plus\core\engine.py", line 200, in _error_callback
    raise exception  # 抛出异常后, 才能被日志进行完整记录下来
  File "c:\python36\Lib\multiprocessing\pool.py", line 119, in worker
    result = (True, func(*args, **kwds))
  File "D:\David\Desktop\spider_plus_fw\spider_plus\core\engine.py", line 144, in _execute_request_response_item
    response = self.downloader.get_response(request)
  File "D:\David\Desktop\spider_plus_fw\spider_plus\core\downloader.py", line 29, in get_response
    logger.info("<{} {}>".format(request.status_code, request.request.url))
AttributeError: 'Request' object has no attribute 'status_code'
2019-04-29 14:27:27 engine.py[line:202] ERROR: 'Request' object has no attribute 'status_code'
Traceback (most recent call last):
  File "D:\David\Desktop\spider_plus_fw\spider_plus\core\engine.py", line 200, in _error_callback
    raise exception  # 抛出异常后, 才能被日志进行完整记录下来
  File "c:\python36\Lib\multiprocessing\pool.py", line 119, in worker
    result = (True, func(*args, **kwds))
  File "D:\David\Desktop\spider_plus_fw\spider_plus\core\engine.py", line 144, in _execute_request_response_item
    response = self.downloader.get_response(request)
  File "D:\David\Desktop\spider_plus_fw\spider_plus\core\downloader.py", line 29, in get_response
    logger.info("<{} {}>".format(request.status_code, request.request.url))
AttributeError: 'Request' object has no attribute 'status_code'
2019-04-29 14:27:27 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/2/>
2019-04-29 14:27:27 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/3/>
2019-04-29 14:27:27 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/4/>
2019-04-29 14:27:27 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/5/>
2019-04-29 14:27:27 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/6/>
2019-04-29 14:27:27 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/7/>
2019-04-29 14:27:27 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/8/>
2019-04-29 14:27:27 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/9/>
2019-04-29 14:27:27 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/10/>
2019-04-29 14:27:27 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/11/>
2019-04-29 14:27:27 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/12/>
2019-04-29 14:27:27 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/13/>
2019-04-29 14:27:28 engine.py[line:202] ERROR: 'Request' object has no attribute 'status_code'
Traceback (most recent call last):
  File "D:\David\Desktop\spider_plus_fw\spider_plus\core\engine.py", line 200, in _error_callback
    raise exception  # 抛出异常后, 才能被日志进行完整记录下来
  File "c:\python36\Lib\multiprocessing\pool.py", line 119, in worker
    result = (True, func(*args, **kwds))
  File "D:\David\Desktop\spider_plus_fw\spider_plus\core\engine.py", line 144, in _execute_request_response_item
    response = self.downloader.get_response(request)
  File "D:\David\Desktop\spider_plus_fw\spider_plus\core\downloader.py", line 29, in get_response
    logger.info("<{} {}>".format(request.status_code, request.request.url))
AttributeError: 'Request' object has no attribute 'status_code'
2019-04-29 14:27:36 downloader.py[line:22] ERROR: 请求出错: <https://www.google.com GET HTTPSConnectionPool(host='www.google.com', port=443): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.VerifiedHTTPSConnection object at 0x000002943F0CD5F8>, 'Connection to www.google.com timed out. (connect timeout=10)'))>
Traceback (most recent call last):
  File "C:\Users\David\Envs\python3_spider\lib\site-packages\urllib3\connection.py", line 141, in _new_conn
    (self.host, self.port), self.timeout, **extra_kw)
  File "C:\Users\David\Envs\python3_spider\lib\site-packages\urllib3\util\connection.py", line 83, in create_connection
    raise err
  File "C:\Users\David\Envs\python3_spider\lib\site-packages\urllib3\util\connection.py", line 73, in create_connection
    sock.connect(sa)
socket.timeout: timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\David\Envs\python3_spider\lib\site-packages\urllib3\connectionpool.py", line 601, in urlopen
    chunked=chunked)
  File "C:\Users\David\Envs\python3_spider\lib\site-packages\urllib3\connectionpool.py", line 346, in _make_request
    self._validate_conn(conn)
  File "C:\Users\David\Envs\python3_spider\lib\site-packages\urllib3\connectionpool.py", line 850, in _validate_conn
    conn.connect()
  File "C:\Users\David\Envs\python3_spider\lib\site-packages\urllib3\connection.py", line 284, in connect
    conn = self._new_conn()
  File "C:\Users\David\Envs\python3_spider\lib\site-packages\urllib3\connection.py", line 146, in _new_conn
    (self.host, self.timeout))
urllib3.exceptions.ConnectTimeoutError: (<urllib3.connection.VerifiedHTTPSConnection object at 0x000002943F0CD5F8>, 'Connection to www.google.com timed out. (connect timeout=10)')

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\David\Envs\python3_spider\lib\site-packages\requests\adapters.py", line 440, in send
    timeout=timeout
  File "C:\Users\David\Envs\python3_spider\lib\site-packages\urllib3\connectionpool.py", line 639, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "C:\Users\David\Envs\python3_spider\lib\site-packages\urllib3\util\retry.py", line 388, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='www.google.com', port=443): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.VerifiedHTTPSConnection object at 0x000002943F0CD5F8>, 'Connection to www.google.com timed out. (connect timeout=10)'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\David\Desktop\spider_plus_fw\spider_plus\core\downloader.py", line 20, in get_response
    resp = requests.get(request.url, headers=request.headers, params=request.params, timeout=10)
  File "C:\Users\David\Envs\python3_spider\lib\site-packages\requests\api.py", line 72, in get
    return request('get', url, params=params, **kwargs)
  File "C:\Users\David\Envs\python3_spider\lib\site-packages\requests\api.py", line 58, in request
    return session.request(method=method, url=url, **kwargs)
  File "C:\Users\David\Envs\python3_spider\lib\site-packages\requests\sessions.py", line 508, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\David\Envs\python3_spider\lib\site-packages\requests\sessions.py", line 618, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\David\Envs\python3_spider\lib\site-packages\requests\adapters.py", line 496, in send
    raise ConnectTimeout(e, request=request)
requests.exceptions.ConnectTimeout: HTTPSConnectionPool(host='www.google.com', port=443): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.VerifiedHTTPSConnection object at 0x000002943F0CD5F8>, 'Connection to www.google.com timed out. (connect timeout=10)'))
2019-04-29 14:27:36 engine.py[line:202] ERROR: 'Request' object has no attribute 'status_code'
Traceback (most recent call last):
  File "D:\David\Desktop\spider_plus_fw\spider_plus\core\engine.py", line 200, in _error_callback
    raise exception  # 抛出异常后, 才能被日志进行完整记录下来
  File "c:\python36\Lib\multiprocessing\pool.py", line 119, in worker
    result = (True, func(*args, **kwds))
  File "D:\David\Desktop\spider_plus_fw\spider_plus\core\engine.py", line 144, in _execute_request_response_item
    response = self.downloader.get_response(request)
  File "D:\David\Desktop\spider_plus_fw\spider_plus\core\downloader.py", line 29, in get_response
    logger.info("<{} {}>".format(request.status_code, request.request.url))
AttributeError: 'Request' object has no attribute 'status_code'
2019-04-29 14:30:00 engine.py[line:88] INFO: 爬虫结束: 2019-04-29 14:30:00.067246
2019-04-29 14:30:00 engine.py[line:89] INFO: 爬虫运行时间: 156.246998
2019-04-29 14:30:00 engine.py[line:92] INFO: 总的请求数量: 0个
2019-04-29 14:30:00 engine.py[line:94] INFO: 总的响应数量: 0个
2019-04-29 14:30:00 engine.py[line:96] INFO: 总的重复数量: 0个
2019-04-29 14:30:00 engine.py[line:98] INFO: 总的 start_requests 数量: 0个
2019-04-29 14:30:04 engine.py[line:81] INFO: 爬虫启动: 2019-04-29 14:30:04.631248
2019-04-29 14:30:04 engine.py[line:82] INFO: 当前启动的爬虫: ['spiders.baidu.BaiduSpider', 'spiders.qiubai.QiubaiSpider']
2019-04-29 14:30:04 engine.py[line:83] INFO: 当前开启的管道: ['pipelines.BaiduPipeline', 'pipelines.QiubaiPipeline']
2019-04-29 14:30:04 engine.py[line:84] INFO: 当前开启的下载器中间件: ['spider_middlewares.TestSpiderMiddleware1']
2019-04-29 14:30:04 engine.py[line:85] INFO: 当前开启的爬虫中间件: ['downloader_middlewares.TestDownloaderMiddleware2']
2019-04-29 14:30:06 scheduler.py[line:106] INFO: 添加新的请求: <http://www.douban.com>
2019-04-29 14:30:06 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/1/>
2019-04-29 14:30:07 scheduler.py[line:111] INFO: 发现重复的请求：<GET http://www.douban.com>
2019-04-29 14:30:07 scheduler.py[line:106] INFO: 添加新的请求: <http://www.baidu.com>
2019-04-29 14:30:07 scheduler.py[line:106] INFO: 添加新的请求: <https://www.google.com>
2019-04-29 14:30:07 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/2/>
2019-04-29 14:30:07 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/3/>
2019-04-29 14:30:07 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/4/>
2019-04-29 14:30:07 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/5/>
2019-04-29 14:30:07 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/6/>
2019-04-29 14:30:07 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/7/>
2019-04-29 14:30:07 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/8/>
2019-04-29 14:30:07 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/9/>
2019-04-29 14:30:07 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/10/>
2019-04-29 14:30:07 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/11/>
2019-04-29 14:30:07 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/12/>
2019-04-29 14:30:07 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/13/>
2019-04-29 14:30:07 downloader.py[line:27] INFO: <200 http://www.baidu.com/>
2019-04-29 14:30:08 downloader.py[line:27] INFO: <200 https://www.qiushibaike.com/8hr/page/1/>
2019-04-29 14:30:08 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121178592>
2019-04-29 14:30:08 downloader.py[line:27] INFO: <200 https://www.qiushibaike.com/8hr/page/2/>
2019-04-29 14:30:08 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121219729>
2019-04-29 14:30:08 downloader.py[line:27] INFO: <200 https://www.douban.com/>
2019-04-29 14:30:08 downloader.py[line:27] INFO: <200 https://www.qiushibaike.com/8hr/page/4/>
2019-04-29 14:30:08 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121225263>
2019-04-29 14:30:08 downloader.py[line:27] INFO: <200 https://www.qiushibaike.com/8hr/page/3/>
2019-04-29 14:30:08 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121189462>
2019-04-29 14:30:08 downloader.py[line:27] INFO: <200 https://www.qiushibaike.com/8hr/page/5/>
2019-04-29 14:30:08 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121183666>
2019-04-29 14:30:08 downloader.py[line:27] INFO: <200 https://www.qiushibaike.com/8hr/page/6/>
2019-04-29 14:30:08 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121129223>
2019-04-29 14:30:08 downloader.py[line:27] INFO: <200 https://www.qiushibaike.com/8hr/page/7/>
2019-04-29 14:30:08 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121196802>
2019-04-29 14:30:08 downloader.py[line:27] INFO: <200 https://www.qiushibaike.com/8hr/page/8/>
2019-04-29 14:30:08 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121197180>
2019-04-29 14:30:08 downloader.py[line:27] INFO: <200 https://www.qiushibaike.com/8hr/page/10/>
2019-04-29 14:30:08 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121185262>
2019-04-29 14:30:08 downloader.py[line:27] INFO: <200 https://www.qiushibaike.com/8hr/page/9/>
2019-04-29 14:30:08 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121123913>
2019-04-29 14:30:08 downloader.py[line:27] INFO: <200 https://www.qiushibaike.com/8hr/page/11/>
2019-04-29 14:30:08 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121186350>
2019-04-29 14:30:08 downloader.py[line:27] INFO: <200 https://www.qiushibaike.com/8hr/page/12/>
2019-04-29 14:30:08 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121194954>
2019-04-29 14:30:09 downloader.py[line:27] INFO: <200 https://www.qiushibaike.com/8hr/page/13/>
2019-04-29 14:30:09 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121150456>
2019-04-29 14:30:09 downloader.py[line:27] INFO: <200 https://www.qiushibaike.com/article/121178592>
2019-04-29 14:30:09 downloader.py[line:27] INFO: <200 https://www.qiushibaike.com/article/121219729>
2019-04-29 14:30:09 downloader.py[line:27] INFO: <200 https://www.qiushibaike.com/article/121225263>
2019-04-29 14:30:09 downloader.py[line:27] INFO: <200 https://www.qiushibaike.com/article/121189462>
2019-04-29 14:30:09 downloader.py[line:27] INFO: <200 https://www.qiushibaike.com/article/121183666>
2019-04-29 14:30:09 downloader.py[line:27] INFO: <200 https://www.qiushibaike.com/article/121129223>
2019-04-29 14:30:09 downloader.py[line:27] INFO: <200 https://www.qiushibaike.com/article/121196802>
2019-04-29 14:30:09 downloader.py[line:27] INFO: <200 https://www.qiushibaike.com/article/121197180>
2019-04-29 14:30:09 downloader.py[line:27] INFO: <200 https://www.qiushibaike.com/article/121185262>
2019-04-29 14:30:09 downloader.py[line:27] INFO: <200 https://www.qiushibaike.com/article/121123913>
2019-04-29 14:30:09 downloader.py[line:27] INFO: <200 https://www.qiushibaike.com/article/121186350>
2019-04-29 14:30:09 downloader.py[line:27] INFO: <200 https://www.qiushibaike.com/article/121194954>
2019-04-29 14:30:09 downloader.py[line:27] INFO: <200 https://www.qiushibaike.com/article/121150456>
2019-04-29 14:30:17 downloader.py[line:31] ERROR: 请求出错: <https://www.google.com GET HTTPSConnectionPool(host='www.google.com', port=443): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.VerifiedHTTPSConnection object at 0x000001FF2A980A20>, 'Connection to www.google.com timed out. (connect timeout=10)'))>
Traceback (most recent call last):
  File "C:\Users\David\Envs\python3_spider\lib\site-packages\urllib3\connection.py", line 141, in _new_conn
    (self.host, self.port), self.timeout, **extra_kw)
  File "C:\Users\David\Envs\python3_spider\lib\site-packages\urllib3\util\connection.py", line 83, in create_connection
    raise err
  File "C:\Users\David\Envs\python3_spider\lib\site-packages\urllib3\util\connection.py", line 73, in create_connection
    sock.connect(sa)
socket.timeout: timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\David\Envs\python3_spider\lib\site-packages\urllib3\connectionpool.py", line 601, in urlopen
    chunked=chunked)
  File "C:\Users\David\Envs\python3_spider\lib\site-packages\urllib3\connectionpool.py", line 346, in _make_request
    self._validate_conn(conn)
  File "C:\Users\David\Envs\python3_spider\lib\site-packages\urllib3\connectionpool.py", line 850, in _validate_conn
    conn.connect()
  File "C:\Users\David\Envs\python3_spider\lib\site-packages\urllib3\connection.py", line 284, in connect
    conn = self._new_conn()
  File "C:\Users\David\Envs\python3_spider\lib\site-packages\urllib3\connection.py", line 146, in _new_conn
    (self.host, self.timeout))
urllib3.exceptions.ConnectTimeoutError: (<urllib3.connection.VerifiedHTTPSConnection object at 0x000001FF2A980A20>, 'Connection to www.google.com timed out. (connect timeout=10)')

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\David\Envs\python3_spider\lib\site-packages\requests\adapters.py", line 440, in send
    timeout=timeout
  File "C:\Users\David\Envs\python3_spider\lib\site-packages\urllib3\connectionpool.py", line 639, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "C:\Users\David\Envs\python3_spider\lib\site-packages\urllib3\util\retry.py", line 388, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='www.google.com', port=443): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.VerifiedHTTPSConnection object at 0x000001FF2A980A20>, 'Connection to www.google.com timed out. (connect timeout=10)'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\David\Desktop\spider_plus_fw\spider_plus\core\downloader.py", line 20, in get_response
    resp = requests.get(request.url, headers=request.headers, params=request.params, timeout=10)
  File "C:\Users\David\Envs\python3_spider\lib\site-packages\requests\api.py", line 72, in get
    return request('get', url, params=params, **kwargs)
  File "C:\Users\David\Envs\python3_spider\lib\site-packages\requests\api.py", line 58, in request
    return session.request(method=method, url=url, **kwargs)
  File "C:\Users\David\Envs\python3_spider\lib\site-packages\requests\sessions.py", line 508, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\David\Envs\python3_spider\lib\site-packages\requests\sessions.py", line 618, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\David\Envs\python3_spider\lib\site-packages\requests\adapters.py", line 496, in send
    raise ConnectTimeout(e, request=request)
requests.exceptions.ConnectTimeout: HTTPSConnectionPool(host='www.google.com', port=443): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.VerifiedHTTPSConnection object at 0x000001FF2A980A20>, 'Connection to www.google.com timed out. (connect timeout=10)'))
2019-04-29 14:30:17 engine.py[line:202] ERROR: 'NoneType' object has no attribute 'meta'
Traceback (most recent call last):
  File "D:\David\Desktop\spider_plus_fw\spider_plus\core\engine.py", line 200, in _error_callback
    raise exception  # 抛出异常后, 才能被日志进行完整记录下来
  File "c:\python36\Lib\multiprocessing\pool.py", line 119, in worker
    result = (True, func(*args, **kwds))
  File "D:\David\Desktop\spider_plus_fw\spider_plus\core\engine.py", line 147, in _execute_request_response_item
    response.meta = request.meta
AttributeError: 'NoneType' object has no attribute 'meta'
2019-04-29 14:32:51 engine.py[line:81] INFO: 爬虫启动: 2019-04-29 14:32:51.230248
2019-04-29 14:32:51 engine.py[line:82] INFO: 当前启动的爬虫: ['spiders.baidu.BaiduSpider', 'spiders.qiubai.QiubaiSpider']
2019-04-29 14:32:51 engine.py[line:83] INFO: 当前开启的管道: ['pipelines.BaiduPipeline', 'pipelines.QiubaiPipeline']
2019-04-29 14:32:51 engine.py[line:84] INFO: 当前开启的下载器中间件: ['spider_middlewares.TestSpiderMiddleware1']
2019-04-29 14:32:51 engine.py[line:85] INFO: 当前开启的爬虫中间件: ['downloader_middlewares.TestDownloaderMiddleware2']
2019-04-29 14:32:53 scheduler.py[line:106] INFO: 添加新的请求: <http://www.douban.com>
2019-04-29 14:32:53 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/1/>
2019-04-29 14:32:54 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/2/>
2019-04-29 14:32:54 downloader.py[line:27] INFO: <200 https://www.qiushibaike.com/8hr/page/1/>
2019-04-29 14:32:54 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121170510>
2019-04-29 14:32:54 downloader.py[line:27] INFO: <200 https://www.qiushibaike.com/8hr/page/2/>
2019-04-29 14:32:54 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121156877>
2019-04-29 14:32:54 downloader.py[line:27] INFO: <200 https://www.qiushibaike.com/article/121170510>
2019-04-29 14:32:54 downloader.py[line:27] INFO: <200 https://www.douban.com/>
2019-04-29 14:32:54 downloader.py[line:27] INFO: <200 https://www.qiushibaike.com/article/121156877>
2019-04-29 14:32:55 scheduler.py[line:111] INFO: 发现重复的请求：<GET http://www.douban.com>
2019-04-29 14:32:55 scheduler.py[line:106] INFO: 添加新的请求: <http://www.baidu.com>
2019-04-29 14:32:55 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/3/>
2019-04-29 14:32:55 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/4/>
2019-04-29 14:32:55 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/5/>
2019-04-29 14:32:55 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/6/>
2019-04-29 14:32:55 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/7/>
2019-04-29 14:32:55 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/8/>
2019-04-29 14:32:55 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/9/>
2019-04-29 14:32:55 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/10/>
2019-04-29 14:32:55 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/11/>
2019-04-29 14:32:55 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/12/>
2019-04-29 14:32:55 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/13/>
2019-04-29 14:32:55 downloader.py[line:27] INFO: <200 http://www.baidu.com/>
2019-04-29 14:32:55 downloader.py[line:27] INFO: <200 https://www.qiushibaike.com/8hr/page/3/>
2019-04-29 14:32:55 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121161730>
2019-04-29 14:32:55 downloader.py[line:27] INFO: <200 https://www.qiushibaike.com/8hr/page/4/>
2019-04-29 14:32:55 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121170902>
2019-04-29 14:32:55 downloader.py[line:27] INFO: <200 https://www.qiushibaike.com/8hr/page/5/>
2019-04-29 14:32:55 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121206294>
2019-04-29 14:32:55 downloader.py[line:27] INFO: <200 https://www.qiushibaike.com/8hr/page/6/>
2019-04-29 14:32:55 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121196924>
2019-04-29 14:32:55 downloader.py[line:27] INFO: <200 https://www.qiushibaike.com/8hr/page/7/>
2019-04-29 14:32:55 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121147967>
2019-04-29 14:32:55 downloader.py[line:27] INFO: <200 https://www.qiushibaike.com/8hr/page/8/>
2019-04-29 14:32:55 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121177576>
2019-04-29 14:32:55 downloader.py[line:27] INFO: <200 https://www.qiushibaike.com/8hr/page/10/>
2019-04-29 14:32:55 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121198645>
2019-04-29 14:32:55 downloader.py[line:27] INFO: <200 https://www.qiushibaike.com/8hr/page/9/>
2019-04-29 14:32:55 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121181407>
2019-04-29 14:32:56 downloader.py[line:27] INFO: <200 https://www.qiushibaike.com/8hr/page/11/>
2019-04-29 14:32:56 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121151043>
2019-04-29 14:32:56 downloader.py[line:27] INFO: <200 https://www.qiushibaike.com/8hr/page/12/>
2019-04-29 14:32:56 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121133296>
2019-04-29 14:32:56 downloader.py[line:27] INFO: <200 https://www.qiushibaike.com/8hr/page/13/>
2019-04-29 14:32:56 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121208349>
2019-04-29 14:32:56 downloader.py[line:27] INFO: <200 https://www.qiushibaike.com/article/121161730>
2019-04-29 14:32:56 downloader.py[line:27] INFO: <200 https://www.qiushibaike.com/article/121170902>
2019-04-29 14:32:56 downloader.py[line:27] INFO: <200 https://www.qiushibaike.com/article/121196924>
2019-04-29 14:32:56 downloader.py[line:27] INFO: <200 https://www.qiushibaike.com/article/121206294>
2019-04-29 14:32:56 downloader.py[line:27] INFO: <200 https://www.qiushibaike.com/article/121147967>
2019-04-29 14:32:56 downloader.py[line:27] INFO: <200 https://www.qiushibaike.com/article/121177576>
2019-04-29 14:32:56 downloader.py[line:27] INFO: <200 https://www.qiushibaike.com/article/121198645>
2019-04-29 14:32:56 downloader.py[line:27] INFO: <200 https://www.qiushibaike.com/article/121151043>
2019-04-29 14:32:56 downloader.py[line:27] INFO: <200 https://www.qiushibaike.com/article/121181407>
2019-04-29 14:32:56 downloader.py[line:27] INFO: <200 https://www.qiushibaike.com/article/121133296>
2019-04-29 14:32:56 downloader.py[line:27] INFO: <200 https://www.qiushibaike.com/article/121208349>
2019-04-29 14:32:56 engine.py[line:88] INFO: 爬虫结束: 2019-04-29 14:32:56.889247
2019-04-29 14:32:56 engine.py[line:89] INFO: 爬虫运行时间: 5.658999
2019-04-29 14:32:56 engine.py[line:92] INFO: 总的请求数量: 29个
2019-04-29 14:32:56 engine.py[line:94] INFO: 总的响应数量: 28个
2019-04-29 14:32:56 engine.py[line:96] INFO: 总的重复数量: 1个
2019-04-29 14:32:56 engine.py[line:98] INFO: 总的 start_requests 数量: 2个
2019-04-29 14:33:11 engine.py[line:81] INFO: 爬虫启动: 2019-04-29 14:33:11.825251
2019-04-29 14:33:11 engine.py[line:82] INFO: 当前启动的爬虫: ['spiders.baidu.BaiduSpider', 'spiders.qiubai.QiubaiSpider']
2019-04-29 14:33:11 engine.py[line:83] INFO: 当前开启的管道: ['pipelines.BaiduPipeline', 'pipelines.QiubaiPipeline']
2019-04-29 14:33:11 engine.py[line:84] INFO: 当前开启的下载器中间件: ['spider_middlewares.TestSpiderMiddleware1']
2019-04-29 14:33:11 engine.py[line:85] INFO: 当前开启的爬虫中间件: ['downloader_middlewares.TestDownloaderMiddleware2']
2019-04-29 14:33:13 scheduler.py[line:106] INFO: 添加新的请求: <http://www.douban.com>
2019-04-29 14:33:13 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/1/>
2019-04-29 14:33:14 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/2/>
2019-04-29 14:33:14 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/3/>
2019-04-29 14:33:14 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/4/>
2019-04-29 14:33:14 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/5/>
2019-04-29 14:33:14 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/6/>
2019-04-29 14:33:14 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/7/>
2019-04-29 14:33:14 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/8/>
2019-04-29 14:33:14 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/9/>
2019-04-29 14:33:14 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/10/>
2019-04-29 14:33:14 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/11/>
2019-04-29 14:33:14 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/12/>
2019-04-29 14:33:14 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/8hr/page/13/>
2019-04-29 14:33:15 downloader.py[line:27] INFO: <200 https://www.qiushibaike.com/8hr/page/2/>
2019-04-29 14:33:15 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121156877>
2019-04-29 14:33:15 downloader.py[line:27] INFO: <200 https://www.qiushibaike.com/8hr/page/3/>
2019-04-29 14:33:15 downloader.py[line:27] INFO: <200 https://www.qiushibaike.com/8hr/page/1/>
2019-04-29 14:33:15 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121161730>
2019-04-29 14:33:15 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121170510>
2019-04-29 14:33:15 downloader.py[line:27] INFO: <200 https://www.douban.com/>
2019-04-29 14:33:15 downloader.py[line:27] INFO: <200 https://www.qiushibaike.com/8hr/page/4/>
2019-04-29 14:33:15 downloader.py[line:27] INFO: <200 https://www.qiushibaike.com/8hr/page/5/>
2019-04-29 14:33:15 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121170902>
2019-04-29 14:33:15 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121206294>
2019-04-29 14:33:15 downloader.py[line:27] INFO: <200 https://www.qiushibaike.com/8hr/page/6/>
2019-04-29 14:33:15 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121196924>
2019-04-29 14:33:30 engine.py[line:81] INFO: 爬虫启动: 2019-04-29 14:33:30.055246
2019-04-29 14:33:30 engine.py[line:82] INFO: 当前启动的爬虫: ['spiders.baidu.BaiduSpider', 'spiders.qiubai.QiubaiSpider']
2019-04-29 14:33:30 engine.py[line:83] INFO: 当前开启的管道: ['pipelines.BaiduPipeline', 'pipelines.QiubaiPipeline']
2019-04-29 14:33:30 engine.py[line:84] INFO: 当前开启的下载器中间件: ['spider_middlewares.TestSpiderMiddleware1']
2019-04-29 14:33:30 engine.py[line:85] INFO: 当前开启的爬虫中间件: ['downloader_middlewares.TestDownloaderMiddleware2']
2019-04-29 14:33:32 downloader.py[line:27] INFO: <200 https://www.qiushibaike.com/8hr/page/12/>
2019-04-29 14:33:32 downloader.py[line:27] INFO: <200 https://www.qiushibaike.com/8hr/page/11/>
2019-04-29 14:33:32 downloader.py[line:27] INFO: <200 https://www.qiushibaike.com/8hr/page/13/>
2019-04-29 14:33:32 downloader.py[line:27] INFO: <200 https://www.qiushibaike.com/article/121156877>
2019-04-29 14:33:32 downloader.py[line:27] INFO: <200 https://www.qiushibaike.com/article/121161730>
2019-04-29 14:33:33 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121133296>
2019-04-29 14:33:33 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/1/>
2019-04-29 14:33:33 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/2/>
2019-04-29 14:33:33 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/3/>
2019-04-29 14:33:33 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/4/>
2019-04-29 14:33:33 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121151043>
2019-04-29 14:33:33 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/5/>
2019-04-29 14:33:33 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/6/>
2019-04-29 14:33:33 scheduler.py[line:106] INFO: 添加新的请求: <https://www.qiushibaike.com/article/121208349>
2019-04-29 14:33:33 scheduler.py[line:111] INFO: 发现重复的请求：<GET http://www.douban.com>
2019-04-29 14:33:33 scheduler.py[line:111] INFO: 发现重复的请求：<GET http://www.douban.com>
2019-04-29 14:33:33 scheduler.py[line:106] INFO: 添加新的请求: <http://www.baidu.com>
2019-04-29 14:33:33 downloader.py[line:27] INFO: <200 https://www.qiushibaike.com/article/121170510>
2019-04-29 14:33:33 downloader.py[line:27] INFO: <200 https://www.qiushibaike.com/article/121170902>
2019-04-29 14:33:33 downloader.py[line:27] INFO: <200 https://www.qiushibaike.com/article/121206294>
2019-04-29 14:33:33 downloader.py[line:27] INFO: <200 https://www.qiushibaike.com/article/121196924>
2019-04-29 14:33:33 downloader.py[line:27] INFO: <200 http://www.baidu.com/>
2019-04-29 14:33:33 downloader.py[line:27] INFO: <200 https://www.qiushibaike.com/article/121133296>
2019-04-29 14:33:34 downloader.py[line:27] INFO: <200 https://www.qiushibaike.com/article/121151043>
2019-04-29 14:33:34 downloader.py[line:27] INFO: <200 https://www.qiushibaike.com/article/121208349>
2019-04-29 14:33:34 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/7/>
2019-04-29 14:33:34 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/8/>
2019-04-29 14:33:34 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/9/>
2019-04-29 14:33:34 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/10/>
2019-04-29 14:33:34 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/11/>
2019-04-29 14:33:34 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/12/>
2019-04-29 14:33:34 scheduler.py[line:111] INFO: 发现重复的请求：<GET https://www.qiushibaike.com/8hr/page/13/>
